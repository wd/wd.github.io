<!doctype html><html lang=en><head><title>Make DNS Service in K8s Stable &ndash; wd and cc</title>
<meta name=description content="Good good study, day day up!"><meta name=viewport content="width=device-width,initial-scale=1"><meta charset=UTF-8><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css integrity="sha512-DTOQO9RWCH3ppGqcWaEA1BIZOC6xxalwEsw9c2QQeAIftl+Vegovlnee1c9QX4TctnWMn13TZye+giMm8e2LwA==" crossorigin=anonymous referrerpolicy=no-referrer><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.4/css/academicons.min.css integrity="sha512-IW0nhlW5MgNydsXJO40En2EoCkTTjZhI3yuODrZIc8cQ4h1XcF53PsqDHa09NqnkXuIe0Oiyyj171BqZFwISBw==" crossorigin=anonymous referrerpolicy=no-referrer><link rel=stylesheet href=https://wdicc.com/css/palettes/base16-dark.css><link rel=stylesheet href=https://wdicc.com/css/risotto.css><link rel=stylesheet href=https://wdicc.com/css/custom.css><link rel=icon href=https://wdicc.com/favicon.ico></head><body><div class=page><header class=page__header><nav class="page__nav main-nav"><ul><h1 class=page__logo><a href=https://wdicc.com/ class=page__logo-inner>wd and cc</a></h1><li class=main-nav__item><a class=nav-main-item href=https://wdicc.com/posts/ title>Posts</a></li><li class=main-nav__item><a class=nav-main-item href="https://www.google.com.hk/search?sitesearch=https%3A%2F%2Fwdicc.com%2F&amp;q=" title>Search</a></li><li class=main-nav__item><a class=nav-main-item href=https://wdicc.com/atom.xml title>subscribe</a></li></ul></nav></header><section class=page__body><header class=content__header><h1>Make DNS Service in K8s Stable</h1></header><div class=content__body><p>我们用的 k8s 是通过 rancher 管理的。rancher 又是使用 rke 这个 engine 来创建集群的。我们使用的 CNI 是 calico，DNS 是 coredns。按说 DNS 服务是核心服务，如果这个玩意不稳定或者有问题，那么整个集群都不安宁。coredns 按说挺有名气来，按说没问题。。吧？</p><p>轻量使用确实还好，但是当节点数量 pod 数量起来之后，一些边界情况下这个东西就不稳定了。当然随着规模的扩大，其实需要关心的不止 DNS 服务，例如 API server 的稳定性，一些 webhook 的性能，这些都是很关键的。正是那句话（原文忘记了，这个是大意）：你本来只有一个问题，为了解决这一个问题，引入了 k8s，那么现在好了，你有 8 个问题了。</p><p>rke 的 coredns 默认会搭配一个 coredns-autoscalar。这个其实就是 <a href=https://github.com/kubernetes-sigs/cluster-proportional-autoscaler>cluster-proportional-autoscaler</a>。这个软件也挺有意思，是一个通用的 scalar，提供了两个 scale 模式，一个是 linear 模式，一个是 ladder 模式。工作方式可以从名字看出来。rke 使用的是 linear 模式。当集群节点增减的时候，会自动增减 coredns 的 replica 数量。我们的集群使用了 cluster autoscalar，所以总是在不停的伸缩中。</p><p>随着 coredns pod 的新建和删除，慢慢问题就出现了。</p><p>第一个问题是 pod 新建的时候，会出现有的 coredns pod 标记为了 ready 但是其实并不通。这个目前基本认为是两个原因造成的。</p><ol><li>coredns 的 toleration 设置太宽松。</li><li>calico 工作比较慢。</li></ol><p>对于 1，rke 部署的 coredns 有如下设置。这样 coredns 早早就开始在 node 上面部署了。</p><div class="src src-yaml"><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>tolerations</span>:
</span></span><span style=display:flex><span>- <span style=color:#f92672>key</span>: <span style=color:#ae81ff>CriticalAddonsOnly</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>operator</span>: <span style=color:#ae81ff>Exists</span>
</span></span><span style=display:flex><span>- <span style=color:#f92672>effect</span>: <span style=color:#ae81ff>NoExecute</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>operator</span>: <span style=color:#ae81ff>Exists</span>
</span></span><span style=display:flex><span>- <span style=color:#f92672>effect</span>: <span style=color:#ae81ff>NoSchedule</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>operator</span>: <span style=color:#ae81ff>Exists</span></span></span></code></pre></div></div><p>并且因为 readiness 没有 delay，所以迅速就 ready 了。</p><div class="src src-yaml"><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>readinessProbe</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>failureThreshold</span>: <span style=color:#ae81ff>3</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>periodSeconds</span>: <span style=color:#ae81ff>10</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>successThreshold</span>: <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>timeoutSeconds</span>: <span style=color:#ae81ff>1</span></span></span></code></pre></div></div><p>另外一个方面 calico 需要和其他节点建立 BGP 连接并且配置路由，会稍微有点慢。这两个事情加起来，导致 coredns 新建的 pod 有一定几率是不能正常工作的。对于这个问题，可以尝试增加一个 initContainer 来减速，或者通过给 readiness 设置 initialDelaySeconds 来减慢。</p><p>第二个问题是 pod 被删除的时候，会出现已经删除的 pod 依然在某些节点的 iptables 里面。这个目前认为是因为删除 pod 通常伴随着 node 和其他应用 pod 的删除，会有大量的 API 请求。这个导致 kube proxy 不一定可以及时处理 iptables 的变更。这个时候发送给 cluster ip 的 dns 请求就有一定概率会遇到问题。</p><p>对于这个问题，解决思路是让 coredns 在收到 terminal signal 的时候再多运行一会。它本身的 health check 插件有一个 <a href=https://coredns.io/plugins/health/>lameduck</a> 参数，可以设置多等多久。</p><p>还可以做另外的优化，例如单独创建 node 来跑 coredns，关掉 coredns-autoscalar。这样就可以很大程度上面避免 coredns pod 创建和删除，上面问题也就没有了。不过即使独立 node 也无法完全避免不对 node 做维护工作，这个时候还是会发生 pod 删除创建操作的。所以上面提到的解决办法可能也还是会需要。</p></div><footer class=content__footer></footer></section><section class=page__aside><div class=aside__about><div class=aside__about><img class=about__logo src=https://wdicc.com/favicon.ico alt=Logo><h1 class=about__title>Happy every day!</h1><p class=about__description>Good good study, day day up!</p></div><ul class=aside__social-links><li><a href=https://github.com/wd rel=me aria-label=GitHub title=GitHub><i class="fa-brands fa-github" aria-hidden=true></i></a>&nbsp;</li></ul></div><hr><div class=aside__content><p>2022-11-23</p></div></section><footer class=page__footer><p><br><span class=active>$ echo $LANG<br><b>zh_CN</b></span><br></p><br><br><p class=copyright>wd © 2025</p><p class=advertisement>Powered by <a href=https://gohugo.io/>hugo</a> and <a href=https://github.com/joeroe/risotto>risotto</a>.</p></footer></div></body></html>