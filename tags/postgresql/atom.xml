<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Postgresql on wd and cc</title>
    <link>https://wdicc.com/tags/postgresql/atom/index.xml</link>
    <description>Recent content in Postgresql on wd and cc</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <atom:link href="https://wdicc.com/tags/postgresql/atom/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Bloat and Query Speed in PostgreSQL</title>
      <link>https://wdicc.com/Bloat-and-Query-Speed-in-PostgreSQL/</link>
      <pubDate>Fri, 09 Dec 2016 12:12:21 +0800</pubDate>
      
      <guid>https://wdicc.com/Bloat-and-Query-Speed-in-PostgreSQL/</guid>
      <description>&lt;p&gt;内容反义自 &lt;a href=&#34;https://www.citusdata.com/blog/2016/11/04/autovacuum-not-the-enemy/&#34;&gt;https://www.citusdata.com/blog/2016/11/04/autovacuum-not-the-enemy/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;pg 的 mvcc 会导致表索引的 bloat 就不多说了。说一下不合理处理这种 bloat 害处是啥。&lt;/p&gt;

&lt;p&gt;首先肯定是会浪费空间。然后也会影响查询速度。表和索引存储的时候都是 8kB 一个 page，如果一个查询一些行，数据库会加载这些 pages 到内存。一个 page 里面的 dead rows 越多，在加载的时候就越浪费 I/O。例如全表扫描会加载所有的 dead rows。&lt;/p&gt;

&lt;p&gt;Bloat 还会导致热门的查询会一下塞满内存。会导致相同的 live rows 需要更多 pages。This causes swapping and makes certain query plans and algorithms ineligible for execution.&lt;/p&gt;

&lt;p&gt;还有一个影响是，pg 的系统表也会有可能 bloat，因为他们也是表。导致这个的一种情况是频繁的创建和删除临时表。这个进一步会导致一些管理命令执行变慢，甚至比如 &lt;code&gt;\d&lt;/code&gt; 这种命令。&lt;/p&gt;

&lt;p&gt;索引也有可能会 bloat。索引是 tuple 标识和数据之间的一个映射。这些标识指向的是某个 page 里面的 offset。每个 tuple 都是一个独立的对象，需要自己的索引条目。更新一行的时候总是会创建这行的新的索引条目。&lt;/p&gt;

&lt;p&gt;索引的 bloat 的影响比 table 小一点。索引里面指向 dead tuple 的可以直接标记为 dead. 这会使得索引膨胀，但是不会导致不必要的堆查找。同时更新堆中的 tuples 不影响已经索引的列，使用一种叫做 HOT 的技术来把指向 dead tuples 的指针指向新的。这允许查询可以通过这些指针复用旧的索引条目。(Also updates to tuples in the heap that do not affect the indexed column(s) use a technique called HOT to provide pointers from the dead tuple to its replacement. This allows queries to reuses old index entries by following pointers across the heap.) (没太看明白.)&lt;/p&gt;

&lt;p&gt;索引 bloat 的问题还是应该需要重视。例如 btree 索引是由二叉树组成()。叶子节点包含值和 tuple 标识（应该是指在 data file 的 offset）。随机更新因为会重用 page，所以可以保持 btree 维持一个良好的形状。但是，如果是单侧更新，会导致大量的空页。&lt;/p&gt;

&lt;p&gt;The size considerations of index bloat are still significant. For instance a btree index consists of binary tree of pages (the same sized pages as you find holding tuples in the heap). The leaf node pages contain values and tuple identifiers. Uniform random table updates tend to keep a btree index in pretty good shape because it can reuse pages. However lopsided inserts/updates affecting one side of the tree while preserving a few straggling entries can lead to lots of mostly empty pages.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Full page write in PostgreSQL</title>
      <link>https://wdicc.com/Full-page-write-in-PostgreSQL/</link>
      <pubDate>Thu, 08 Dec 2016 18:02:14 +0800</pubDate>
      
      <guid>https://wdicc.com/Full-page-write-in-PostgreSQL/</guid>
      <description>

&lt;p&gt;读了一篇&lt;a href=&#34;http://blog.2ndquadrant.com/on-the-impact-of-full-page-writes/&#34;&gt;文章&lt;/a&gt;，简单翻译总结下。&lt;/p&gt;

&lt;h2 id=&#34;partial-writes-torn-pages&#34;&gt;Partial Writes / Torn Pages&lt;/h2&gt;

&lt;p&gt;pg 默认是 8kB 一个 page。linux 文件系统一般是 4kB（x86 里面最大是 4kB)，老设备驱动一般是 512B 一个扇区，新的设备有些支持 4kB 或者 8kB。&lt;/p&gt;

&lt;p&gt;当 pg 写入一个 page 8kB 的时候，系统的底层会拆分小一点块，这里涉及到写入的原子性。8kB 的 pg page，会被文件系统拆分成 4kB 的块，然后拆分成 512B 扇区大小。这个时候如果系统崩溃（比如停电，内核 bug）会发生什么？&lt;/p&gt;

&lt;p&gt;即使系统的存储有针对这种情况的设计（比如 SSD 自带电容器，RAID 控制器自带电池），内核那块也是会拆分成 4kB 的 page，所以还是有一定可能性，pg 写了 8kB，但是只有部分写入成功。&lt;/p&gt;

&lt;p&gt;这个时候你可能意识到这就是为啥我们要有事务日志（WAL）。所以当系统崩溃重启之后，数据库会读取 WAL（从最后一次 checkpoint），然后重新写入一遍，以保证数据文件是完整的。&lt;/p&gt;

&lt;p&gt;恢复的时候，在修改一个 page 之前，还是会读取一下。&lt;/p&gt;

&lt;p&gt;在 checkpoint 之后第一次修改一个 page 的时候，会把整个 page 写入 WAL。这是为了保证在恢复的时候，能保证这些被修改的 page 能完全恢复到他原有的样子。&lt;/p&gt;

&lt;h2 id=&#34;写放大&#34;&gt;写放大&lt;/h2&gt;

&lt;p&gt;如果打开 Full page write，很显然会导致 WAL 文件增加，因为就算修改一个字节，也会导致 8kB page 的写入。因为 Full page write 只发生在 checkpoint 之后的第一次写入，所以减少 checkpoint 的发生频率是可以减少写入的。&lt;/p&gt;

&lt;h2 id=&#34;uuid-vs-bigserial-主键&#34;&gt;UUID vs BIGSERIAL 主键&lt;/h2&gt;

&lt;p&gt;比较了一下使用 UUID 或者 bigserial 做主键对写入的影响。可以看原链接的图，会发现在 INSERT 语句的情况下 UUID 产生的 WAL 文件量比较多。主要原因是 Btree 索引的情况下，bigserial 是顺序的维护这个索引，UUID 是无顺序的，会导致维护索引产生的数据量不同。&lt;/p&gt;

&lt;p&gt;如果是使用 UPDATE 随机修改，那么会发现产生的 WAL 数量就差不多了。&lt;/p&gt;

&lt;h2 id=&#34;8kb-and-4kb-pages&#34;&gt;8kB and 4kB pages&lt;/h2&gt;

&lt;p&gt;如果减小 pg 的 page 的大小，可以减小 WAL 数量。从 8kB 减小到 4kB，上面 UUID 那个例子，可以减少大概 35% 的量。&lt;/p&gt;

&lt;h2 id=&#34;需要-full-page-write-吗&#34;&gt;需要 full-page write 吗？&lt;/h2&gt;

&lt;p&gt;首先，这个参数是 2005 年 pg 8.1 引入的，那么现代的文件系统是不是已经不用操心部分写入的情况了？作者尝试了一些测试没有测试出来部分写入的情况，当然这不表示不会存在。但是就算是存在，数据的一致性校验也会是有效的保护（虽然并不能修复这个问题，但是至少能让你知道有坏的 page）&lt;/p&gt;

&lt;p&gt;其次，现在很多系统都依赖于流式同步，并不会等着有问题的服务器在有硬件问题的时候重启，并且花费很多时间恢复，一般都直接切换到热备服务器上面了。这个时候部分写就不是什么问题了。但是如果我们都推荐这么做，那么「我也不知道为啥数据损坏了，我只是设置了 full_page_writes=off」这种会是 DBA 死前最常见的言论了。(类似于「这种蛇我之前在 reddit 看见过，无毒的」)&lt;/p&gt;

&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;

&lt;p&gt;对于 full-page write 你没法直接优化。大部分情况下，full-page write 都是发生在 checkpoint 之后，直到下一次 checkpoint。所以调整 checkpoint 的发生频率不要太频繁很重要。&lt;/p&gt;

&lt;p&gt;有些应用层的操作，可能会导致对表或者索引的随机写入的增加，例如上面的 UUID 的值就是随机的，会让简单的 INSERT 也会导致索引的随机 update。使用 Bigserial 做主键(让 UUID 做替代键)可以减少写放大。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Built in sharding in PostgreSQL</title>
      <link>https://wdicc.com/Built-in-sharding-in-PostgreSQL/</link>
      <pubDate>Wed, 07 Dec 2016 16:54:59 +0800</pubDate>
      
      <guid>https://wdicc.com/Built-in-sharding-in-PostgreSQL/</guid>
      <description>

&lt;p&gt;PostgreSQL 内建 sharding 支持，粗略翻译自 &lt;a href=&#34;https://wiki.postgresql.org/wiki/Built-in_Sharding&#34;&gt;https://wiki.postgresql.org/wiki/Built-in_Sharding&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;内建支持 sharding 最大的挑战是，如何用最小的代码修改实现。大部分社区的 sharding 修改支持都修改了很多 PostgreSQL 的代码，这也导致这些不能被 Postgres 社区那些不需要 sharding 的人接受。有了 FDW 之后，就有了在有限代码修改情况下实现内建 sharding 支持的可能。&lt;/p&gt;

&lt;p&gt;基于 FDW 的这种 sharding 设计，是基于 NTT 开发的 Postgres-XC，大概已经有 10 年了。Postgres-XL 是基于这个设计的一种更加灵活的实现。&lt;/p&gt;

&lt;h2 id=&#34;enhance-existing-features&#34;&gt;Enhance Existing Features&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;已完成？提升 FDW 的基础设计和 postgres_fdw。特别的，好的性能要求合理的把一些操作推送到子节点(foreign shards)。在 Postgres 9.6 中，join, sort, update, delete 都可以推送到字节点了。聚合的 pushdown 将在 Postgres 10 中支持。FDW 表已经可以作为继承表出现。&lt;/li&gt;
&lt;li&gt;提升分区支持有效提升 existence of shards。幸运的是，单节点的分区支持也需要重构才能提升性能和更多优化。例如，executor-based partition pruning.&lt;/li&gt;
&lt;li&gt;给 FDW 请求增加并行支持。这样能允许节点并行执行，这个可能会通过多个异步的链接来实现。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;new-subsystems&#34;&gt;New Subsystems&lt;/h2&gt;

&lt;p&gt;还需要开发一些子系统：
* 允许表可以复制到所有节点，以允许更多的 join pushdown。这个可以通过 trigger 或者逻辑复制来完成。
* 实现一个子模块，以使用新的分区系统表来提交符合提交的查询的 FDW 查询。
* 实现一个子模块收集 FDW 查询的结果返回给用户。
* 实现全局事务管理器以便更加高效的允许子节点原子的提交事务。这个可能会通过 prepared 的事务来实现，还有某种在 crash 之后清理那些 preapared 的事务的事务管理器。例如 XA。
* 实现全局快照管理器，以允许子节点可以看到一致性的快照。（是不是 serialisable 事务模式会避免跨节点快照冲突？pg_export_snapshot() 或者 hot_standby_feedback 是不是会有帮助？) 多节点的备份的一致性也需要这个支持。
* 实现支持 create, manage, report on shards 这些用户 API。&lt;/p&gt;

&lt;h2 id=&#34;use-cases&#34;&gt;Use Cases&lt;/h2&gt;

&lt;p&gt;有四种可能的用户案例和不同的需求:
* 跨节点在只读节点上面执行只读聚合查询，例如数据仓库
  这种是最简单的场景，不需要全局事务管理，全局快照管理，并且因为聚合，所以子节点返回的数据量也是最小的。
* 跨节点在只读节点上面执行只读非聚合查询
  这种会给调度节点压力，需要收集和处理很多子节点返回的数据。这种也能看到 FDW 传输机制等级。
* 跨节点在可读写节点执行只读查询
  这个需要全局快照管理来保证子节点返回数据的一致性
* 跨节点执行读写查询
  这个需要全局快照管理器和全局事务管理器&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>postgresql transaction isolation</title>
      <link>https://wdicc.com/postgresql-transaction-isolation/</link>
      <pubDate>Sun, 10 May 2015 23:20:49 +0800</pubDate>
      
      <guid>https://wdicc.com/postgresql-transaction-isolation/</guid>
      <description>

&lt;p&gt;翻译自 &lt;a href=&#34;http://www.postgresql.org/docs/current/static/transaction-iso.html，&#34;&gt;http://www.postgresql.org/docs/current/static/transaction-iso.html，&lt;/a&gt; 内容没翻译全，供参考。&lt;/p&gt;

&lt;h2 id=&#34;并发控制&#34;&gt;并发控制&lt;/h2&gt;

&lt;h3 id=&#34;13-2-事务隔离级别&#34;&gt;13.2 事务隔离级别&lt;/h3&gt;

&lt;p&gt;SQL 标准定义了四个事务隔离级别。最严格的就是串行化(Serializable)，根据标准定义，任何并发的串行化事务如果在相同的时间使用相同的顺序执行，那么需要有相同的执行结果。其他的三个隔离级别，都定义了在并发事务互相影响的情况下，在各隔离级别下不允许出现的一些现象。根据标准，这些现象都不允许出现在串行化这个级别。(这并不令人惊讶 &amp;ndash; 如果为了事务的结果一致只允许同时运行一个事务，那怎么可能会出现因为事务互相影响产生的现象)。&lt;/p&gt;

&lt;p&gt;在各级别禁止的一些现象如下：&lt;/p&gt;

&lt;p&gt;脏读(dirty read)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;一个事务读取到另一个并发的事务还没有提交的数据。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;不可重复读(nonrepeatable read)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;一个事务重复读取之前读过的数据的时候，发现数据已经被其他事务修改（就是在第一次读取之后做的提交)。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;幻读(phantom read)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;一个事务重新执行一个查找符合条件的数据的查询的时候，发现返回的数据因为这期间别的事务做了提交而发生了变化。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;四个事务隔离级别和对应的行为在表 13-1 中进行了描述。&lt;/p&gt;

&lt;p&gt;表 13-1 SQL 标准定义的事务隔离级别&lt;/p&gt;

&lt;p&gt;| 事务隔离级别               | 脏读   | 不可重复读 | 幻读   |
|&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-+&amp;mdash;&amp;mdash;&amp;ndash;+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;+&amp;mdash;&amp;mdash;&amp;ndash;|
| 读未提交(read uncommitted) | 可能   | 可能       | 可能   |
| 读已提交(read committed)   | 不可能 | 可能       | 可能   |
| 可重复读(repeatable read)  | 不可能 | 不可能     | 可能   |
| 串行化(serializable)       | 不可能 | 不可能     | 不可能 |&lt;/p&gt;

&lt;p&gt;（译者注：这个表格是个很大的迷惑，要注意他描述的只是标准定义的，而不是 PostgreSQL 里面的情况，在 PostgreSQL 中的实际情况和上面表格标记的不一致，下面的译文里面也多次会提到。）&lt;/p&gt;

&lt;p&gt;在 PostgreSQl 中，你可以使用任意的四个隔离级别。但是，在内部其实只有三个，分别对应到读已提交、可重复读和串行化。当使用读未提交这个级别的时候，实际上和读已提交是一样的，而幻读在 PostgresSQL 的可重复读级别是不可能出现的，所以在 PostgreSQL 中实际的隔离级别可能比你选的更加严格一点。这个是 SQL 标准允许的：标准里面的四个隔离级别只定义了哪种现象不能出现，没有定义哪种现象一定会出现。PostgreSQL 只提供了三个隔离级别，是因为这是唯一比较合理的把标准定义的隔离级别映射到多版本并发控制架构上面的办法。在下面的章节里面会详细讲解各个隔离级别。&lt;/p&gt;

&lt;p&gt;设置事务隔离级别的语句是 set transaction。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;重要提示：有些 PostgreSQL 的数据类型和函数在事务里面有特别的表现。特别的，对于序列(sequence)(以及定义为 serial 类型的列对应的序列)的修改会立刻对所有事务有效，并且在事务回滚的时候也不会被回滚。请参考 9.16 和 8.1.4。
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;13-2-1-读已提交事务隔离级别&#34;&gt;13.2.1 读已提交事务隔离级别&lt;/h4&gt;

&lt;p&gt;读已提交是 PostgreSQL 里面默认的事务隔离级别。当一个事务使用此级别的时候，一个 select 查询(不带 for update/share 字句)只可以查到当前查询开始前已经提交的数据，(在此查询执行的过程中)永远不会查到其他并发事务执行时的未提交数据和已提交的修改。事实上，一个 select 查询可以&amp;rdquo;看“到执行开始瞬间的数据库的一个快照。不过，select 查询可以”看“到当前事务里面已经完成更新的数据，即使他们还没有被提交。同时也要注意，如果有其他事务在一个事务的第一个 select 执行之后提交了修改，那么那个事务里面的前后成功的两个 select 查询也有可能得到不同的结果。&lt;/p&gt;

&lt;p&gt;update, delete, select for update, 和 select for share 这些语句在查找目标数据的时候的时候，表现和 select 是一样的：都是只能查找到在语句执行开始的时候就已经提交的数据。然而，这些目标数据可能就已经被其他并发事务修改（或者删除、加锁(locked))了。在这种情况下，即将执行更新的事务将会等待第一个执行了更新的事务的提交或者回滚（如果他仍然在执行中）。如果第一个更新事务执行了回滚，那么它的执行结果会取消，后续的更新事务会处理所有之前查找到的数据。如果第一个更新事务执行了提交，那么后续的更新事务会忽略第一个事务删除的行，然后针对已经更新过的数据上面执行它自己的操作。语句里面的查询条件（where 语句）会重新被执行来查看已经更新的数据是否还满足条件。如果满足，那后续的更新事务会在已经更新过的数据上面执行他自己的操作。如果执行的是 select for update 和 select for share 语句，那会返回或者锁定更新后的数据给客户端。&lt;/p&gt;

&lt;p&gt;基于以上规则，一个更新语句可能会得到一个“不稳定”的快照。它会“看”到其他并发事务对它将要更新的数据的修改，但是“看”不到其他并发事务对其他数据的修改。这个行为会导致读已提交事务隔离级别不适用于一些复杂的查询，只适用于简单的情况。例如，想象一下在事务里面更新银行账户余额：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-SQL&#34;&gt;BEGIN;
UPDATE accounts SET balance = balance + 100.00 WHERE acctnum = 12345;
UPDATE accounts SET balance = balance - 100.00 WHERE acctnum = 7534;
COMMIT;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果有两个类似的事务要更新 12345 这个帐号的余额，我们显然是希望第二个更新事务是基于第一个的结果来更新。因为每个语句都是更新既定的数据，所以只能“看”到更新的数据不会造成不一致。&lt;/p&gt;

&lt;p&gt;在读已提交事务隔离级别里面，复杂一点的情况可能会得到预期之外的结果。例如，想象一下一个 delete 语句操作的数据被其他语句从他的限制条件里面增加或者移除。例如，假设 website 是一个包含两行数据的表，其中 website.hits 字段分别等于 9 和 10。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-SQL&#34;&gt;BEGIN;
UPDATE website SET hits = hits + 1;
-- run from another session:  DELETE FROM website WHERE hits = 10;
COMMIT;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;虽然在执行 update 前后，都有 website.hits = 10 的数据，但是那个 delete 语句将没有任何效果。这是因为未执行成功 update 前，9 这行数据是被 delete 忽略的，当 update 执行完毕，delete 得到锁之后，新的数据的值已经不是 10 而是 11 了，已经不再符合 delete 的条件了。&lt;/p&gt;

&lt;p&gt;读已提交事务隔离级别在事务开始的时候会创建一个包含了在那个瞬间所有已提交的事务的数据的快照，同一个事务里面的后续语句会“看”到其他并发事务提交的数据。前面的问题的关键点是，单个语句是否可以得到一个持续一致的数据库。&lt;/p&gt;

&lt;p&gt;读已提交事务隔离级别对于很多程序来说就已经足够了，使用起来快速简单。显然，它并不适用于所有情况。对于使用了复杂查询和更新的程序，或许需要对数据一致性要求比读已提交更加严格的事务隔离级别。&lt;/p&gt;

&lt;h4 id=&#34;13-2-2-可重复读事务隔离级别&#34;&gt;13.2.2 可重复读事务隔离级别&lt;/h4&gt;

&lt;p&gt;可重复读事务隔离级别只能“看”到在事务开始前已经提交的数据，并且永远也“看”不到未提交的或者在事务执行期间被其他并发事务更新的数据。（当然，查询语句是可以“看”到在当前事务里面的已经执行的更新的，即使他们还没有被提交。）这么做比 SQL 标准里面针对这个隔离级别的要求严格，在表 13-1 里面表述的现象都不能发生。如前面所说，这么做标准是允许的，标准只描述了各隔离级别最低的要求。&lt;/p&gt;

&lt;p&gt;这个隔离级别不同于读已提交隔离级别，在可重复读事务隔离级别里面一个查询可以“看”到事务开始的时候的一个快照，不是当前事务里面当前查询开始的时候的快照。因此，一个事务里面成功执行的 select 语句会得到相同的结果，也就是说，他们都”看“不到在事务开始之后其他事务提交的修改。&lt;/p&gt;

&lt;p&gt;使用这个隔离级别的应用，应该在遇到序列化失败(serialization failures)的时候准备好重试。&lt;/p&gt;

&lt;p&gt;update, delete, select for update, 和 select for share 这些语句在查找目标数据的时候的时候，表现和 select 是一样的：都是只能查找到在事务执行开始的时候就已经提交的数据。然而，这些目标数据可能就已经被其他并发事务修改（或者删除、加锁(locked))了。在这种情况下，可重复读事务将会等待第一个执行了更新的事务的提交或者回滚（如果他仍然在执行中）。如果第一个更新事务执行了回滚，那么它的执行结果会取消，后续的更新事务会处理所有之前查找到的数据。如果第一个更新事务执行了提交（真的对数据执行了更新或者删除，不是只是加了锁），那么可重复读事务会执行回滚，并且报错&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ERROR:  could not serialize access due to concurrent update
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;因为可重复读事务在事务开始后不能对被其他事务做了修改的数据做修改或者锁定。&lt;/p&gt;

&lt;p&gt;当应用程序得到这个错误信息的时候，应该立刻中止当前事务，重新从事务开始再次执行。再次执行的时候，这个事务就可以”看“到之前被其他事务提交的修改了，所以使用新版本数据作为新事务的起点的时候，就不会再有逻辑冲突了。&lt;/p&gt;

&lt;p&gt;要注意只有有更新操作的事务才需要重试，只读的事务是永远不会有序列化冲突的。&lt;/p&gt;

&lt;p&gt;读已提交事务隔离机制严格保证了每个事务都得到一个完整稳定的数据库快照。However, this view will not necessarily always be consistent with some serial (one at a time) execution of concurrent transactions of the same level. For example, even a read only transaction at this level may see a control record updated to show that a batch has been completed but not see one of the detail records which is logically part of the batch because it read an earlier revision of the control record. Attempts to enforce business rules by transactions running at this isolation level are not likely to work correctly without careful use of explicit locks to block conflicting transactions.&lt;/p&gt;

&lt;p&gt;提示：在 PostgreSQL 9.1 以前，序列化事务隔离级别的情况和前面描述的信息是一样的。如果需要以前的序列化事务隔离级别，那可以使用现在的可重复读隔离级别。&lt;/p&gt;

&lt;h4 id=&#34;13-2-3-序列化隔离级别&#34;&gt;13.2.3 序列化隔离级别&lt;/h4&gt;

&lt;p&gt;序列化事务隔离级别是最严格的事务隔离级别。这个级别把所有已经提交的事务模为拟序列化执行，就像是事务执行完一个执行另一个，顺序的，而不是并发的。当然，类似于可重复读事务隔离级别，应用程序在序列化失败的情况下必须要准备好重试。事实上，这个级别和可重复读事务隔离级别是一模一样的，除了会监控 except that it monitors for conditions which could make execution of a concurrent set of serializable transactions behave in a manner inconsistent with all possible serial (one at a time) executions of those transactions. This monitoring does not introduce any blocking beyond that present in repeatable read, but there is some overhead to the monitoring, and detection of the conditions which could cause a serialization anomaly will trigger a serialization failure.&lt;/p&gt;

&lt;p&gt;举个例子，比如有表 mytab，初始的时候如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; class | value
-------+-------
     1 |    10
     1 |    20
     2 |   100
     2 |   200
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;假设在序列化事务 A 里面执行：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-SQL&#34;&gt;SELECT SUM(value) FROM mytab WHERE class = 1;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后把结果（30）作为 value 字段，class = 2 作为新行插入回去。同时，序列化事务 B 里面执行：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-SQL&#34;&gt;SELECT SUM(value) FROM mytab WHERE class = 2;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;得到结果 300,并把结果和 class = 1 作为新行插入回去。然后两个事务都尝试提交。如果任意事务执行在可重复读级别，那么两个事务都可以提交; but since there is no serial order of execution consistent with the result, 使用序列化事务隔离级别的话，会允许其中一个事务提交，而回滚另一个事务，并且报如下错误信息：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ERROR:  could not serialize access due to read/write dependencies among transactions
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这是因为如果 A 在 B 之前执行的话，B 的计算结果就会是 330 而不是 300,类似的，其他顺序会导致 A 得到不同的结果。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Postgresql 里面连接其他数据库</title>
      <link>https://wdicc.com/fdw-in-postgresql/</link>
      <pubDate>Sun, 06 May 2012 00:00:00 +0000</pubDate>
      
      <guid>https://wdicc.com/fdw-in-postgresql/</guid>
      <description>&lt;p&gt;PG 9.x 引入了 fdw，可以通过 pg 去连接其他 db，不仅限于其他 pg，还可以是 mysql，oracle，文件等。按照设计，fdw 还应该提供给查询规划器一些对方 db 的索引等信息，这样在查询过程中可以提升查询速度。&lt;br /&gt;
&lt;/p&gt;&lt;br /&gt;

&lt;div id=&#34;outline-container-1&#34; class=&#34;outline-3&#34;&gt;&lt;br /&gt;
&lt;h3 id=&#34;sec-1&#34;&gt;dbi_link&lt;/h3&gt;&lt;br /&gt;
&lt;div class=&#34;outline-text-3&#34; id=&#34;text-1&#34;&gt;&lt;br /&gt;


&lt;p&gt;&lt;br /&gt;
dbi 就是 perl 的 dbi，总的思想就是通过 plperl 写一些 function（所以也给了调试修改的便利），通过 dbi 去连接其他数据库，可以连接的 db 和 dbi 的支持一样。&lt;br /&gt;
&lt;/p&gt;&lt;br /&gt;
&lt;p&gt;&lt;br /&gt;
测试了一下，第一次连接的时候会 cache 对方 db 的信息，对于复杂库没测试成功，只有一个表的库连接成功，并且可以查询。查询的时候就和查询本地库没有区别。&lt;br /&gt;
&lt;/p&gt;&lt;br /&gt;
&lt;p&gt;&lt;br /&gt;
效率上面看，不是很高，每次查询都必然需要获取对方全部数据。就算是有 where 条件，也不会试用到对方 db 的索引。所以综合来看，只是提供了一个简单的方法来获取数据，最好是一次性的。&lt;br /&gt;
&lt;/p&gt;&lt;br /&gt;
&lt;/div&gt;&lt;br /&gt;

&lt;/div&gt;&lt;br /&gt;

&lt;div id=&#34;outline-container-2&#34; class=&#34;outline-3&#34;&gt;&lt;br /&gt;
&lt;h3 id=&#34;sec-2&#34;&gt;db_link&lt;/h3&gt;&lt;br /&gt;
&lt;div class=&#34;outline-text-3&#34; id=&#34;text-2&#34;&gt;&lt;br /&gt;


&lt;p&gt;&lt;br /&gt;
db_link 本身是 pg 自带的，contrib 里面的。db_link 只支持 pg，建立连接之后，后续查询可以只指定使用哪个连接即可。&lt;br /&gt;
&lt;/p&gt;&lt;br /&gt;
&lt;p&gt;&lt;br /&gt;
相对 dbi_link，使用起来稍微复杂一点，需要特定的格式。效率上面看，查全表数据比 dbi_link 快。&lt;br /&gt;
&lt;/p&gt;&lt;br /&gt;
&lt;p&gt;&lt;br /&gt;
他有个优势是每次查询对方库的时候都需要指定一个 sql，而如果只需要少量数据的时候，可以在 sql 里面直接使用 where 来过滤数据，这样就能使用对方 db 的索引了，速度快很多。不过就是稍微有点繁琐。&lt;br /&gt;
&lt;/p&gt;&lt;br /&gt;
&lt;/div&gt;&lt;br /&gt;

&lt;/div&gt;&lt;br /&gt;

&lt;div id=&#34;outline-container-3&#34; class=&#34;outline-3&#34;&gt;&lt;br /&gt;
&lt;h3 id=&#34;sec-3&#34;&gt;fdw&lt;/h3&gt;&lt;br /&gt;
&lt;div class=&#34;outline-text-3&#34; id=&#34;text-3&#34;&gt;&lt;br /&gt;


&lt;p&gt;&lt;br /&gt;
&lt;a href=&#34;http://www.postgresonline.com/journal/archives/250-File-FDW-Family-Part-1-file_fdw.html&#34;&gt;http://www.postgresonline.com/journal/archives/250-File-FDW-Family-Part-1-file\_fdw.html&lt;/a&gt; 这里有个链接，讲了 file fdw。其他 fdw 还没有试过。我理解 fdw 是否能使用对方 db 的索引，还需要看 fdw 的实现。file fdw 提供了类似 oracle 外部表一样的东西。实际上早年间 yahoo 的兄弟写过一个外部表的 pg 扩展的，不知道是不是这个 file fdw 就是从那来的。&lt;br /&gt;
&lt;/p&gt;&lt;/div&gt;&lt;br /&gt;
&lt;/div&gt;&lt;br /&gt;
</description>
    </item>
    
    <item>
      <title>postgresql 里面的 generate_series</title>
      <link>https://wdicc.com/generate_series-function-in-postgresql/</link>
      <pubDate>Fri, 14 Oct 2011 00:00:00 +0000</pubDate>
      
      <guid>https://wdicc.com/generate_series-function-in-postgresql/</guid>
      <description>&lt;p&gt;有个报表需要把几天的记录按照小时 join 起来，最开始的作法是通过 js 来 join 数据。后来遇到了问题，就是某天某个小时可能会没有记录，然后想破头了，在 js 里面循环的时候设置每天循环到的当前的小时。可崩溃的是还会出现有的是这两小时没有，有的是另外的，用 js 搞不定了，就尝试用 sql 搞定。&lt;br /&gt;
&lt;/p&gt;&lt;br /&gt;
&lt;p&gt;&lt;br /&gt;
sql 开始的方法是简单的使用 full join。然后发现没法保证主表在所有的小时都有记录。后来就发现了这个 generate_series 函数，发现很有意思。地址在这里 &lt;a href=&#34;http://www.postgresql.org/docs/9.0/static/functions-srf.html&#34;&gt;http://www.postgresql.org/docs/9.0/static/functions-srf.html&lt;/a&gt; 。这里还有个 generate_scripts 的函数，可以用来遍历数组产生一个表格的。&lt;br /&gt;
&lt;/p&gt;&lt;br /&gt;
</description>
    </item>
    
  </channel>
</rss>