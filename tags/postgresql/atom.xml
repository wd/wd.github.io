<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>postgresql on wd and cc</title><link>https://wdicc.com/tags/postgresql/</link><description>Recent content in postgresql on wd and cc</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><lastBuildDate>Sun, 02 Feb 2020 11:04:47 +0800</lastBuildDate><atom:link href="https://wdicc.com/tags/postgresql/atom.xml" rel="self" type="application/rss+xml"/><item><title>PostgreSQL at Low Level</title><link>https://wdicc.com/postgresql-at-low-level/</link><pubDate>Sun, 02 Feb 2020 11:04:47 +0800</pubDate><guid>https://wdicc.com/postgresql-at-low-level/</guid><description>总结一下这篇文章 PostgreSQL at low level: stay curious! Introduction 我们之前使用数据库的时候，生产环境都只在实体机上面使用，测试和开发为了资源复用会在虚拟机 vm 上面使用。 但是现在不少在 vm k8s 或者 aws 上面使用 db 数据库的，实际这里面可能有很多潜在的问题。以前是 pg - OS 这样两层结构，现在是 pg - os - cg - vm - k8s 这样多层结构，这里面任何一层出现问题实际都会导致你的查询变慢。我们以前虚拟机上面跑服务的时候，有时候就会被同物理机其他虚拟机上面的服务影响，例如突然的高 io。这样即使怎么看那个执行计划估计也没用，你必须去研究更底层可能的影响。 Shared memory docker 只给 /dev/shm 64MB 大小，所以是会遇到共享内存不足的问题啦。可以通过 strace 定位 1 2 3 4 5 6 7 8 9 10 11 12 # strace -k -p PID openat(AT_FDCWD, &amp;#34;/dev/shm/PostgreSQL.62223175&amp;#34; ftruncate(176, 50438144) = 0 fallocate(176, 0, 0, 50438144) = -1 ENOSPC &amp;gt; libc-2.</description></item><item><title>ST_Buffer in Postgis</title><link>https://wdicc.com/st_buffer_in_postgis/</link><pubDate>Wed, 04 Dec 2019 10:33:20 +0800</pubDate><guid>https://wdicc.com/st_buffer_in_postgis/</guid><description>Postgis 一直没仔细用过，总是临到用时看看文档，这不又遇到问题了，折腾半天。 我们最近有一个需求是，需要把一些原有的多边形范围扩大 50 公里，然后和其他的图形比较看是否有包含关系。是否有包含这个不用看也知道，gis 肯定有现成的函数，那么问题就在于怎么扩大一个多边形的范围。 主要查到几个函数， ST_Expand 和 ST_Buffer。st_expand 可以从 x,y,z 方向扩展，显然不适合我这里的情况，我这不是正南正北的多边形。那就只有 st_buffer 了。 ST_Buffer ST_Buffer 的语法如下 1 2 3 4 5 6 7 geometry ST_Buffer(geometry g1, float radius_of_buffer, text buffer_style_parameters=&amp;#39;&amp;#39;); geometry ST_Buffer(geometry g1, float radius_of_buffer, integer num_seg_quarter_circle); geography ST_Buffer(geography g1, float radius_of_buffer, text buffer_style_parameters); geography ST_Buffer(geography g1, float radius_of_buffer, integer num_seg_quarter_circle); 第一个参数是 geometry 或者 geography 类型的。这又是什么？找到一篇参考文章，下面会详细一点说。 第二个参数是 radius_of_buffer，就是扩大的范围了，但是单位是啥？然后文档里面的解释是 Units of radius are measured in units of the spatial reference system ，这又是啥意思呢，就是取决于你的投影系统是什么。 Geometry 和 Geography 地理坐标系不像是 Mercator（墨卡托）坐标系，不是笛卡尔坐标（就是我们常见的横竖轴 xy 坐标那种）。地理坐标系表达的是一个点在球体上面的位置，通过他和子午线（经度）以及赤道（纬度）的角度来表示。 地球毕竟不是一个完美的球体，所以就算是地理坐标系，也有不同的大地测量系统（Geodetic datum）,这样同一个位置，不通的测量系统下，坐标会有一些差别。所以给一个 GPS 坐标点还需要指定对应的测量体系。我们常见的就是 WGS84 (EPSG：4326)。 地理坐标系只能通过地球仪这样的数据展示，不是二维的。大家也不可能都抱着地球仪跑，所以就有了投影映射到平面的需求。 常见的平面投影方式就是 Mercator，也就是 EPSG:3857。球体映射到平面肯定会有地方有失真啦，具体问题可以参考投影方式的说明吧，我们日常使用一般可以忽略这个问题。 Postgis 里面两种类型 geometry 和 geography。一般使用 geometry, 4326 存数据，使用 geography 计算距离。 那么上面的 radius_of_buffer 来说，对于 geometry 数据，是度数。对于 geography 数据，是我们常见的距离（米）。 使用 ST_Buffer 扩展多边形 我们数据库里面存的数据是 GeometryField，所以一种方法如下，把数据 cast 成 Geography 类型的做计算。 1 st_buffer(gis_data::Geography, 50000, &amp;#39;endcap=round join=mitre mitre_limit=2&amp;#39;) 另一种方法如下，使用 st_transform 转成 3857 再做计算。 1 st_buffer(st_transform(gis_data, 3857), 50000, &amp;#39;endcap=round join=mitre mitre_limit=2&amp;#39;) 计算完毕得到的是 Geography 数据，如果想要存回去，还需要转成 Geometry，通过 cast 或者 st_transform 都可以完成。 参考文章 https://www.</description></item><item><title>Bloat and Query Speed in PostgreSQL</title><link>https://wdicc.com/bloat-and-query-speed-in-postgresql/</link><pubDate>Fri, 09 Dec 2016 12:12:21 +0800</pubDate><guid>https://wdicc.com/bloat-and-query-speed-in-postgresql/</guid><description>内容反义自 https://www.citusdata.com/blog/2016/11/04/autovacuum-not-the-enemy/
pg 的 mvcc 会导致表索引的 bloat 就不多说了。说一下不合理处理这种 bloat 害处是啥。
首先肯定是会浪费空间。然后也会影响查询速度。表和索引存储的时候都是 8kB 一个 page，如果一个查询一些行，数据库会加载这些 pages 到内存。一个 page 里面的 dead rows 越多，在加载的时候就越浪费 I/O。例如全表扫描会加载所有的 dead rows。
Bloat 还会导致热门的查询会一下塞满内存。会导致相同的 live rows 需要更多 pages。This causes swapping and makes certain query plans and algorithms ineligible for execution.
还有一个影响是，pg 的系统表也会有可能 bloat，因为他们也是表。导致这个的一种情况是频繁的创建和删除临时表。这个进一步会导致一些管理命令执行变慢，甚至比如 \d 这种命令。
索引也有可能会 bloat。索引是 tuple 标识和数据之间的一个映射。这些标识指向的是某个 page 里面的 offset。每个 tuple 都是一个独立的对象，需要自己的索引条目。更新一行的时候总是会创建这行的新的索引条目。
索引的 bloat 的影响比 table 小一点。索引里面指向 dead tuple 的可以直接标记为 dead. 这会使得索引膨胀，但是不会导致不必要的堆查找。同时更新堆中的 tuples 不影响已经索引的列，使用一种叫做 HOT 的技术来把指向 dead tuples 的指针指向新的。这允许查询可以通过这些指针复用旧的索引条目。(Also updates to tuples in the heap that do not affect the indexed column(s) use a technique called HOT to provide pointers from the dead tuple to its replacement.</description></item><item><title>Full page write in PostgreSQL</title><link>https://wdicc.com/full-page-write-in-postgresql/</link><pubDate>Thu, 08 Dec 2016 18:02:14 +0800</pubDate><guid>https://wdicc.com/full-page-write-in-postgresql/</guid><description>读了一篇文章，简单翻译总结下。
Partial Writes / Torn Pages pg 默认是 8kB 一个 page。linux 文件系统一般是 4kB（x86 里面最大是 4kB)，老设备驱动一般是 512B 一个扇区，新的设备有些支持 4kB 或者 8kB。
当 pg 写入一个 page 8kB 的时候，系统的底层会拆分小一点块，这里涉及到写入的原子性。8kB 的 pg page，会被文件系统拆分成 4kB 的块，然后拆分成 512B 扇区大小。这个时候如果系统崩溃（比如停电，内核 bug）会发生什么？
即使系统的存储有针对这种情况的设计（比如 SSD 自带电容器，RAID 控制器自带电池），内核那块也是会拆分成 4kB 的 page，所以还是有一定可能性，pg 写了 8kB，但是只有部分写入成功。
这个时候你可能意识到这就是为啥我们要有事务日志（WAL）。所以当系统崩溃重启之后，数据库会读取 WAL（从最后一次 checkpoint），然后重新写入一遍，以保证数据文件是完整的。
恢复的时候，在修改一个 page 之前，还是会读取一下。
在 checkpoint 之后第一次修改一个 page 的时候，会把整个 page 写入 WAL。这是为了保证在恢复的时候，能保证这些被修改的 page 能完全恢复到他原有的样子。
写放大 如果打开 Full page write，很显然会导致 WAL 文件增加，因为就算修改一个字节，也会导致 8kB page 的写入。因为 Full page write 只发生在 checkpoint 之后的第一次写入，所以减少 checkpoint 的发生频率是可以减少写入的。</description></item><item><title>Built in sharding in PostgreSQL</title><link>https://wdicc.com/built-in-sharding-in-postgresql/</link><pubDate>Wed, 07 Dec 2016 16:54:59 +0800</pubDate><guid>https://wdicc.com/built-in-sharding-in-postgresql/</guid><description>PostgreSQL 内建 sharding 支持，粗略翻译自 https://wiki.postgresql.org/wiki/Built-in_Sharding
Introduction 内建支持 sharding 最大的挑战是，如何用最小的代码修改实现。大部分社区的 sharding 修改支持都修改了很多 PostgreSQL 的代码，这也导致这些不能被 Postgres 社区那些不需要 sharding 的人接受。有了 FDW 之后，就有了在有限代码修改情况下实现内建 sharding 支持的可能。
基于 FDW 的这种 sharding 设计，是基于 NTT 开发的 Postgres-XC，大概已经有 10 年了。Postgres-XL 是基于这个设计的一种更加灵活的实现。
Enhance Existing Features 已完成？提升 FDW 的基础设计和 postgres_fdw。特别的，好的性能要求合理的把一些操作推送到子节点(foreign shards)。在 Postgres 9.6 中，join, sort, update, delete 都可以推送到字节点了。聚合的 pushdown 将在 Postgres 10 中支持。FDW 表已经可以作为继承表出现。 提升分区支持有效提升 existence of shards。幸运的是，单节点的分区支持也需要重构才能提升性能和更多优化。例如，executor-based partition pruning. 给 FDW 请求增加并行支持。这样能允许节点并行执行，这个可能会通过多个异步的链接来实现。 New Subsystems 还需要开发一些子系统：
允许表可以复制到所有节点，以允许更多的 join pushdown。这个可以通过 trigger 或者逻辑复制来完成。 实现一个子模块，以使用新的分区系统表来提交符合提交的查询的 FDW 查询。 实现一个子模块收集 FDW 查询的结果返回给用户。 实现全局事务管理器以便更加高效的允许子节点原子的提交事务。这个可能会通过 prepared 的事务来实现，还有某种在 crash 之后清理那些 preapared 的事务的事务管理器。例如 XA。 实现全局快照管理器，以允许子节点可以看到一致性的快照。（是不是 serialisable 事务模式会避免跨节点快照冲突？pg_export_snapshot() 或者 hot_standby_feedback 是不是会有帮助？) 多节点的备份的一致性也需要这个支持。 实现支持 create, manage, report on shards 这些用户 API。 Use Cases 有四种可能的用户案例和不同的需求:</description></item><item><title>postgresql transaction isolation</title><link>https://wdicc.com/postgresql-transaction-isolation/</link><pubDate>Sun, 10 May 2015 23:20:49 +0800</pubDate><guid>https://wdicc.com/postgresql-transaction-isolation/</guid><description>翻译自 http://www.postgresql.org/docs/current/static/transaction-iso.html， 内容没翻译全，供参考。
并发控制 13.2 事务隔离级别 SQL 标准定义了四个事务隔离级别。最严格的就是串行化(Serializable)，根据标准定义，任何并发的串行化事务如果在相同的时间使用相同的顺序执行，那么需要有相同的执行结果。其他的三个隔离级别，都定义了在并发事务互相影响的情况下，在各隔离级别下不允许出现的一些现象。根据标准，这些现象都不允许出现在串行化这个级别。(这并不令人惊讶 &amp;ndash; 如果为了事务的结果一致只允许同时运行一个事务，那怎么可能会出现因为事务互相影响产生的现象)。
在各级别禁止的一些现象如下：
脏读(dirty read)
一个事务读取到另一个并发的事务还没有提交的数据。 不可重复读(nonrepeatable read)
一个事务重复读取之前读过的数据的时候，发现数据已经被其他事务修改（就是在第一次读取之后做的提交)。 幻读(phantom read)
一个事务重新执行一个查找符合条件的数据的查询的时候，发现返回的数据因为这期间别的事务做了提交而发生了变化。 四个事务隔离级别和对应的行为在表 13-1 中进行了描述。
表 13-1 SQL 标准定义的事务隔离级别
| 事务隔离级别 | 脏读 | 不可重复读 | 幻读 | |&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-+&amp;mdash;&amp;mdash;&amp;ndash;+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;+&amp;mdash;&amp;mdash;&amp;ndash;| | 读未提交(read uncommitted) | 可能 | 可能 | 可能 | | 读已提交(read committed) | 不可能 | 可能 | 可能 | | 可重复读(repeatable read) | 不可能 | 不可能 | 可能 | | 串行化(serializable) | 不可能 | 不可能 | 不可能 |</description></item><item><title>Postgresql 里面连接其他数据库</title><link>https://wdicc.com/fdw-in-postgresql/</link><pubDate>Sun, 06 May 2012 00:00:00 +0000</pubDate><guid>https://wdicc.com/fdw-in-postgresql/</guid><description>PG 9.x 引入了 fdw，可以通过 pg 去连接其他 db，不仅限于其他 pg，还可以是 mysql，oracle，文件等。按照设计，fdw 还应该提供给查询规划器一些对方 db 的索引等信息，这样在查询过程中可以提升查询速度。
dbi_link
dbi 就是 perl 的 dbi，总的思想就是通过 plperl 写一些 function（所以也给了调试修改的便利），通过 dbi 去连接其他数据库，可以连接的 db 和 dbi 的支持一样。
测试了一下，第一次连接的时候会 cache 对方 db 的信息，对于复杂库没测试成功，只有一个表的库连接成功，并且可以查询。查询的时候就和查询本地库没有区别。
效率上面看，不是很高，每次查询都必然需要获取对方全部数据。就算是有 where 条件，也不会试用到对方 db 的索引。所以综合来看，只是提供了一个简单的方法来获取数据，最好是一次性的。
db_link
db_link 本身是 pg 自带的，contrib 里面的。db_link 只支持 pg，建立连接之后，后续查询可以只指定使用哪个连接即可。
相对 dbi_link，使用起来稍微复杂一点，需要特定的格式。效率上面看，查全表数据比 dbi_link 快。
他有个优势是每次查询对方库的时候都需要指定一个 sql，而如果只需要少量数据的时候，可以在 sql 里面直接使用 where 来过滤数据，这样就能使用对方 db 的索引了，速度快很多。不过就是稍微有点繁琐。
fdw</description></item><item><title>postgresql 里面的 generate_series</title><link>https://wdicc.com/generate_series-function-in-postgresql/</link><pubDate>Fri, 14 Oct 2011 00:00:00 +0000</pubDate><guid>https://wdicc.com/generate_series-function-in-postgresql/</guid><description>有个报表需要把几天的记录按照小时 join 起来，最开始的作法是通过 js 来 join 数据。后来遇到了问题，就是某天某个小时可能会没有记录，然后想破头了，在 js 里面循环的时候设置每天循环到的当前的小时。可崩溃的是还会出现有的是这两小时没有，有的是另外的，用 js 搞不定了，就尝试用 sql 搞定。
sql 开始的方法是简单的使用 full join。然后发现没法保证主表在所有的小时都有记录。后来就发现了这个 generate_series 函数，发现很有意思。地址在这里 http://www.postgresql.org/docs/9.0/static/functions-srf.html 。这里还有个 generate_scripts 的函数，可以用来遍历数组产生一个表格的。</description></item></channel></rss>