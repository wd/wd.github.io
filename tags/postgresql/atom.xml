<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>postgresql on wd and cc</title>
    <link>https://wdicc.com/tags/postgresql/</link>
    <description>Recent content in postgresql on wd and cc</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Fri, 09 Dec 2016 12:12:21 +0800</lastBuildDate>
    
	<atom:link href="https://wdicc.com/tags/postgresql/atom.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Bloat and Query Speed in PostgreSQL</title>
      <link>https://wdicc.com/bloat-and-query-speed-in-postgresql/</link>
      <pubDate>Fri, 09 Dec 2016 12:12:21 +0800</pubDate>
      
      <guid>https://wdicc.com/bloat-and-query-speed-in-postgresql/</guid>
      <description>内容反义自 https://www.citusdata.com/blog/2016/11/04/autovacuum-not-the-enemy/
pg 的 mvcc 会导致表索引的 bloat 就不多说了。说一下不合理处理这种 bloat 害处是啥。
首先肯定是会浪费空间。然后也会影响查询速度。表和索引存储的时候都是 8kB 一个 page，如果一个查询一些行，数据库会加载这些 pages 到内存。一个 page 里面的 dead rows 越多，在加载的时候就越浪费 I/O。例如全表扫描会加载所有的 dead rows。
Bloat 还会导致热门的查询会一下塞满内存。会导致相同的 live rows 需要更多 pages。This causes swapping and makes certain query plans and algorithms ineligible for execution.
还有一个影响是，pg 的系统表也会有可能 bloat，因为他们也是表。导致这个的一种情况是频繁的创建和删除临时表。这个进一步会导致一些管理命令执行变慢，甚至比如 \d 这种命令。
索引也有可能会 bloat。索引是 tuple 标识和数据之间的一个映射。这些标识指向的是某个 page 里面的 offset。每个 tuple 都是一个独立的对象，需要自己的索引条目。更新一行的时候总是会创建这行的新的索引条目。
索引的 bloat 的影响比 table 小一点。索引里面指向 dead tuple 的可以直接标记为 dead. 这会使得索引膨胀，但是不会导致不必要的堆查找。同时更新堆中的 tuples 不影响已经索引的列，使用一种叫做 HOT 的技术来把指向 dead tuples 的指针指向新的。这允许查询可以通过这些指针复用旧的索引条目。(Also updates to tuples in the heap that do not affect the indexed column(s) use a technique called HOT to provide pointers from the dead tuple to its replacement.</description>
    </item>
    
    <item>
      <title>Full page write in PostgreSQL</title>
      <link>https://wdicc.com/full-page-write-in-postgresql/</link>
      <pubDate>Thu, 08 Dec 2016 18:02:14 +0800</pubDate>
      
      <guid>https://wdicc.com/full-page-write-in-postgresql/</guid>
      <description>读了一篇文章，简单翻译总结下。
Partial Writes / Torn Pages pg 默认是 8kB 一个 page。linux 文件系统一般是 4kB（x86 里面最大是 4kB)，老设备驱动一般是 512B 一个扇区，新的设备有些支持 4kB 或者 8kB。
当 pg 写入一个 page 8kB 的时候，系统的底层会拆分小一点块，这里涉及到写入的原子性。8kB 的 pg page，会被文件系统拆分成 4kB 的块，然后拆分成 512B 扇区大小。这个时候如果系统崩溃（比如停电，内核 bug）会发生什么？
即使系统的存储有针对这种情况的设计（比如 SSD 自带电容器，RAID 控制器自带电池），内核那块也是会拆分成 4kB 的 page，所以还是有一定可能性，pg 写了 8kB，但是只有部分写入成功。
这个时候你可能意识到这就是为啥我们要有事务日志（WAL）。所以当系统崩溃重启之后，数据库会读取 WAL（从最后一次 checkpoint），然后重新写入一遍，以保证数据文件是完整的。
恢复的时候，在修改一个 page 之前，还是会读取一下。
在 checkpoint 之后第一次修改一个 page 的时候，会把整个 page 写入 WAL。这是为了保证在恢复的时候，能保证这些被修改的 page 能完全恢复到他原有的样子。
写放大 如果打开 Full page write，很显然会导致 WAL 文件增加，因为就算修改一个字节，也会导致 8kB page 的写入。因为 Full page write 只发生在 checkpoint 之后的第一次写入，所以减少 checkpoint 的发生频率是可以减少写入的。</description>
    </item>
    
    <item>
      <title>Built in sharding in PostgreSQL</title>
      <link>https://wdicc.com/built-in-sharding-in-postgresql/</link>
      <pubDate>Wed, 07 Dec 2016 16:54:59 +0800</pubDate>
      
      <guid>https://wdicc.com/built-in-sharding-in-postgresql/</guid>
      <description>PostgreSQL 内建 sharding 支持，粗略翻译自 https://wiki.postgresql.org/wiki/Built-in_Sharding
Introduction 内建支持 sharding 最大的挑战是，如何用最小的代码修改实现。大部分社区的 sharding 修改支持都修改了很多 PostgreSQL 的代码，这也导致这些不能被 Postgres 社区那些不需要 sharding 的人接受。有了 FDW 之后，就有了在有限代码修改情况下实现内建 sharding 支持的可能。
基于 FDW 的这种 sharding 设计，是基于 NTT 开发的 Postgres-XC，大概已经有 10 年了。Postgres-XL 是基于这个设计的一种更加灵活的实现。
Enhance Existing Features  已完成？提升 FDW 的基础设计和 postgres_fdw。特别的，好的性能要求合理的把一些操作推送到子节点(foreign shards)。在 Postgres 9.6 中，join, sort, update, delete 都可以推送到字节点了。聚合的 pushdown 将在 Postgres 10 中支持。FDW 表已经可以作为继承表出现。 提升分区支持有效提升 existence of shards。幸运的是，单节点的分区支持也需要重构才能提升性能和更多优化。例如，executor-based partition pruning. 给 FDW 请求增加并行支持。这样能允许节点并行执行，这个可能会通过多个异步的链接来实现。  New Subsystems 还需要开发一些子系统： * 允许表可以复制到所有节点，以允许更多的 join pushdown。这个可以通过 trigger 或者逻辑复制来完成。 * 实现一个子模块，以使用新的分区系统表来提交符合提交的查询的 FDW 查询。 * 实现一个子模块收集 FDW 查询的结果返回给用户。 * 实现全局事务管理器以便更加高效的允许子节点原子的提交事务。这个可能会通过 prepared 的事务来实现，还有某种在 crash 之后清理那些 preapared 的事务的事务管理器。例如 XA。 * 实现全局快照管理器，以允许子节点可以看到一致性的快照。（是不是 serialisable 事务模式会避免跨节点快照冲突？pg_export_snapshot() 或者 hot_standby_feedback 是不是会有帮助？) 多节点的备份的一致性也需要这个支持。 * 实现支持 create, manage, report on shards 这些用户 API。</description>
    </item>
    
    <item>
      <title>postgresql transaction isolation</title>
      <link>https://wdicc.com/postgresql-transaction-isolation/</link>
      <pubDate>Sun, 10 May 2015 23:20:49 +0800</pubDate>
      
      <guid>https://wdicc.com/postgresql-transaction-isolation/</guid>
      <description>翻译自 http://www.postgresql.org/docs/current/static/transaction-iso.html， 内容没翻译全，供参考。
并发控制 13.2 事务隔离级别 SQL 标准定义了四个事务隔离级别。最严格的就是串行化(Serializable)，根据标准定义，任何并发的串行化事务如果在相同的时间使用相同的顺序执行，那么需要有相同的执行结果。其他的三个隔离级别，都定义了在并发事务互相影响的情况下，在各隔离级别下不允许出现的一些现象。根据标准，这些现象都不允许出现在串行化这个级别。(这并不令人惊讶 &amp;ndash; 如果为了事务的结果一致只允许同时运行一个事务，那怎么可能会出现因为事务互相影响产生的现象)。
在各级别禁止的一些现象如下：
脏读(dirty read)
1  一个事务读取到另一个并发的事务还没有提交的数据。   不可重复读(nonrepeatable read)
1  一个事务重复读取之前读过的数据的时候，发现数据已经被其他事务修改（就是在第一次读取之后做的提交)。   幻读(phantom read)
1  一个事务重新执行一个查找符合条件的数据的查询的时候，发现返回的数据因为这期间别的事务做了提交而发生了变化。   四个事务隔离级别和对应的行为在表 13-1 中进行了描述。
表 13-1 SQL 标准定义的事务隔离级别
| 事务隔离级别 | 脏读 | 不可重复读 | 幻读 | |&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-+&amp;mdash;&amp;mdash;&amp;ndash;+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;+&amp;mdash;&amp;mdash;&amp;ndash;| | 读未提交(read uncommitted) | 可能 | 可能 | 可能 | | 读已提交(read committed) | 不可能 | 可能 | 可能 | | 可重复读(repeatable read) | 不可能 | 不可能 | 可能 | | 串行化(serializable) | 不可能 | 不可能 | 不可能 |</description>
    </item>
    
    <item>
      <title>Postgresql 里面连接其他数据库</title>
      <link>https://wdicc.com/fdw-in-postgresql/</link>
      <pubDate>Sun, 06 May 2012 00:00:00 +0000</pubDate>
      
      <guid>https://wdicc.com/fdw-in-postgresql/</guid>
      <description>PG 9.x 引入了 fdw，可以通过 pg 去连接其他 db，不仅限于其他 pg，还可以是 mysql，oracle，文件等。按照设计，fdw 还应该提供给查询规划器一些对方 db 的索引等信息，这样在查询过程中可以提升查询速度。
dbi_link

dbi 就是 perl 的 dbi，总的思想就是通过 plperl 写一些 function（所以也给了调试修改的便利），通过 dbi 去连接其他数据库，可以连接的 db 和 dbi 的支持一样。

测试了一下，第一次连接的时候会 cache 对方 db 的信息，对于复杂库没测试成功，只有一个表的库连接成功，并且可以查询。查询的时候就和查询本地库没有区别。

效率上面看，不是很高，每次查询都必然需要获取对方全部数据。就算是有 where 条件，也不会试用到对方 db 的索引。所以综合来看，只是提供了一个简单的方法来获取数据，最好是一次性的。


db_link

db_link 本身是 pg 自带的，contrib 里面的。db_link 只支持 pg，建立连接之后，后续查询可以只指定使用哪个连接即可。

相对 dbi_link，使用起来稍微复杂一点，需要特定的格式。效率上面看，查全表数据比 dbi_link 快。

他有个优势是每次查询对方库的时候都需要指定一个 sql，而如果只需要少量数据的时候，可以在 sql 里面直接使用 where 来过滤数据，这样就能使用对方 db 的索引了，速度快很多。不过就是稍微有点繁琐。


fdw</description>
    </item>
    
    <item>
      <title>postgresql 里面的 generate_series</title>
      <link>https://wdicc.com/generate_series-function-in-postgresql/</link>
      <pubDate>Fri, 14 Oct 2011 00:00:00 +0000</pubDate>
      
      <guid>https://wdicc.com/generate_series-function-in-postgresql/</guid>
      <description>有个报表需要把几天的记录按照小时 join 起来，最开始的作法是通过 js 来 join 数据。后来遇到了问题，就是某天某个小时可能会没有记录，然后想破头了，在 js 里面循环的时候设置每天循环到的当前的小时。可崩溃的是还会出现有的是这两小时没有，有的是另外的，用 js 搞不定了，就尝试用 sql 搞定。

sql 开始的方法是简单的使用 full join。然后发现没法保证主表在所有的小时都有记录。后来就发现了这个 generate_series 函数，发现很有意思。地址在这里 http://www.postgresql.org/docs/9.0/static/functions-srf.html 。这里还有个 generate_scripts 的函数，可以用来遍历数组产生一个表格的。</description>
    </item>
    
  </channel>
</rss>