<!doctype html><html lang=en><head><meta http-equiv=X-Clacks-Overhead content="GNU Terry Pratchett"><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><link rel="shortcut icon" href=https://wdicc.com/favicon.ico><title>LLD in zabbix | wd and cc</title><meta name=title content="LLD in zabbix"><meta name=description content="如果需要监控的内容比较多的时候，手动管理报警信息就已经不使用了，加一批机器就需要忙活一阵子。也不能体现我们充满智慧的大脑的作用。
zabbix 支持 LLD(low level discovery) 方式来自动产生监控项目，包括 item, trigger 这些都可以自动添加。大概讲解一下可以利用这个东西做什么事情。"><meta name=keywords content="zabbix,monitor,"><meta property="og:url" content="https://wdicc.com/lld-in-zabbix/"><meta property="og:site_name" content="wd and cc"><meta property="og:title" content="LLD in zabbix"><meta property="og:description" content="如果需要监控的内容比较多的时候，手动管理报警信息就已经不使用了，加一批机器就需要忙活一阵子。也不能体现我们充满智慧的大脑的作用。
zabbix 支持 LLD(low level discovery) 方式来自动产生监控项目，包括 item, trigger 这些都可以自动添加。大概讲解一下可以利用这个东西做什么事情。"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2016-07-30T14:09:58+08:00"><meta property="article:modified_time" content="2016-07-30T14:09:58+08:00"><meta property="article:tag" content="Zabbix"><meta property="article:tag" content="Monitor"><meta name=twitter:card content="summary"><meta name=twitter:title content="LLD in zabbix"><meta name=twitter:description content="如果需要监控的内容比较多的时候，手动管理报警信息就已经不使用了，加一批机器就需要忙活一阵子。也不能体现我们充满智慧的大脑的作用。
zabbix 支持 LLD(low level discovery) 方式来自动产生监控项目，包括 item, trigger 这些都可以自动添加。大概讲解一下可以利用这个东西做什么事情。"><meta itemprop=name content="LLD in zabbix"><meta itemprop=description content="如果需要监控的内容比较多的时候，手动管理报警信息就已经不使用了，加一批机器就需要忙活一阵子。也不能体现我们充满智慧的大脑的作用。
zabbix 支持 LLD(low level discovery) 方式来自动产生监控项目，包括 item, trigger 这些都可以自动添加。大概讲解一下可以利用这个东西做什么事情。"><meta itemprop=datePublished content="2016-07-30T14:09:58+08:00"><meta itemprop=dateModified content="2016-07-30T14:09:58+08:00"><meta itemprop=wordCount content="2937"><meta itemprop=keywords content="Zabbix,Monitor"><meta name=referrer content="no-referrer-when-downgrade"><style>:root{--width:720px;--font-main:Verdana, sans-serif;--font-secondary:Verdana, sans-serif;--font-scale:1em;--background-color:#fff;--heading-color:#222;--text-color:#444;--link-color:#3273dc;--visited-color:#8b6fcb;--code-background-color:#f2f2f2;--code-color:#222;--blockquote-color:#222}@media(prefers-color-scheme:dark){:root{--background-color:#01242e;--heading-color:#eee;--text-color:#ddd;--link-color:#8cc2dd;--visited-color:#8b6fcb;--code-background-color:#000;--code-color:#ddd;--blockquote-color:#ccc}}body{font-family:var(--font-secondary);font-size:var(--font-scale);margin:auto;padding:20px;max-width:var(--width);text-align:left;background-color:var(--background-color);word-wrap:break-word;overflow-wrap:break-word;line-height:1.5;color:var(--text-color)}h1,h2,h3,h4,h5,h6{font-family:var(--font-main);color:var(--heading-color)}a{color:var(--link-color);cursor:pointer;text-decoration:none}a:hover{text-decoration:underline}nav a{margin-right:8px}strong,b{color:var(--heading-color)}button{margin:0;cursor:pointer}time{font-family:monospace;font-style:normal;font-size:15px}main{line-height:1.6}table{width:100%}hr{border:0;border-top:1px dashed}img{max-width:100%}code{font-family:monospace;padding:2px;background-color:var(--code-background-color);color:var(--code-color);border-radius:3px}blockquote{border-left:1px solid #999;color:var(--code-color);padding-left:20px;font-style:italic}footer{padding:25px 0;text-align:center}.title:hover{text-decoration:none}.title h1{font-size:1.5em}.inline{width:auto !important}.highlight,.code{padding:1px 15px;background-color:var(--code-background-color);color:var(--code-color);border-radius:3px;margin-block-start:1em;margin-block-end:1em;overflow-x:auto}ul.blog-posts{list-style-type:none;padding:unset}ul.blog-posts li{display:flex}ul.blog-posts li span{flex:0 0 130px}ul.blog-posts li a:visited{color:var(--visited-color)}</style></head><body><header><a href=/ class=title><h2>wd and cc</h2></a><p>-- Good good study, day day up!</p><nav><a href=/>Home</a>
<a href=/posts/>Posts</a>
<a href="https://www.google.com.hk/search?sitesearch=https%3A%2F%2Fwdicc.com%2F&amp;q=">Search</a>
<a href=/tags/>Tags</a>
<a href=/atom.xml>subscribe</a></nav></header><main><h1>LLD in zabbix</h1><p><i><time datetime=2016-07-30>30 Jul, 2016
</time></i><a href=https://wdicc.com/tags/zabbix/>#Zabbix</a>
<a href=https://wdicc.com/tags/monitor/>#Monitor</a></p><content><p>如果需要监控的内容比较多的时候，手动管理报警信息就已经不使用了，加一批机器就需要忙活一阵子。也不能体现我们充满智慧的大脑的作用。</p><p>zabbix 支持 LLD(low level discovery) 方式来自动产生监控项目，包括 item, trigger 这些都可以自动添加。大概讲解一下可以利用这个东西做什么事情。</p><h2 id=zabbix-收集数据的方式>zabbix 收集数据的方式</h2><p>zabbix 有很多收集数据的方法，这里重点讲 2 个，一个是 <code>zabbix agent</code>，一个是 <code>zabbix traper</code>。这两个方式可以和 nagios 里面的 active 和 passive 方式做类比。traaper 方式对应的就是 passive，就是 client 主动发送数据给 server。</p><p>对于 zabbix agent 方式，我们可以自己定义一些 <code>userParameter</code> 来添加自定义监控，这些网上很多例子。如果使用 trapper 方式，那么原则上面可以不用做任何自定义，就可以通过 zabbix-sender 或者自己模拟 sender 的协议，通过比如 python，java 等发送自己的监控信息。通过 python 发送的例子网上也有。</p><h2 id=lld>LLD</h2><p>参考<a href=https://www.zabbix.com/documentation/3.2/manual/discovery/low_level_discovery>这里</a>，LLD 主要的思路就是给服务器端发送一个 json 数据格式。例如下面这个。</p><pre tabindex=0><code>{
  &#34;data&#34;:[
  
  { &#34;{#FSNAME}&#34;:&#34;/&#34;,                           &#34;{#FSTYPE}&#34;:&#34;rootfs&#34;   },
  { &#34;{#FSNAME}&#34;:&#34;/sys&#34;,                        &#34;{#FSTYPE}&#34;:&#34;sysfs&#34;    },
  { &#34;{#FSNAME}&#34;:&#34;/proc&#34;,                       &#34;{#FSTYPE}&#34;:&#34;proc&#34;     },
  { &#34;{#FSNAME}&#34;:&#34;/dev&#34;,                        &#34;{#FSTYPE}&#34;:&#34;devtmpfs&#34; },
  { &#34;{#FSNAME}&#34;:&#34;/dev/pts&#34;,                    &#34;{#FSTYPE}&#34;:&#34;devpts&#34;   },
  { &#34;{#FSNAME}&#34;:&#34;/lib/init/rw&#34;,                &#34;{#FSTYPE}&#34;:&#34;tmpfs&#34;    },
  { &#34;{#FSNAME}&#34;:&#34;/dev/shm&#34;,                    &#34;{#FSTYPE}&#34;:&#34;tmpfs&#34;    },
  { &#34;{#FSNAME}&#34;:&#34;/home&#34;,                       &#34;{#FSTYPE}&#34;:&#34;ext3&#34;     },
  { &#34;{#FSNAME}&#34;:&#34;/tmp&#34;,                        &#34;{#FSTYPE}&#34;:&#34;ext3&#34;     },
  { &#34;{#FSNAME}&#34;:&#34;/usr&#34;,                        &#34;{#FSTYPE}&#34;:&#34;ext3&#34;     },
  { &#34;{#FSNAME}&#34;:&#34;/var&#34;,                        &#34;{#FSTYPE}&#34;:&#34;ext3&#34;     },
  { &#34;{#FSNAME}&#34;:&#34;/sys/fs/fuse/connections&#34;,    &#34;{#FSTYPE}&#34;:&#34;fusectl&#34;  }
  
  ]
}
</code></pre><p>这个数据里面，data 是必须的，里面包含里面发现的可监控数据，这可以是任何数据。例子里面是发现了可以用来监控的磁盘分区。data 是个数组，每个可监控项是一个数组元素。还有类似下面这样的数据。</p><pre tabindex=0><code>{
    &#34;data&#34;: [
        {
            &#34;{#HOST}&#34;: &#34;Japan 1&#34;,
            &#34;{#COUNT}&#34;: &#34;5&#34;
        },
        {
            &#34;{#HOST}&#34;: &#34;Japan 2&#34;,
            &#34;{#COUNT}&#34;: &#34;12&#34;
        },
        {
            &#34;{#HOST}&#34;: &#34;Latvia&#34;,
            &#34;{#COUNT}&#34;: &#34;3&#34;
        }
    ]
}
</code></pre><p>这个是发现了一些可监控的 host。</p><p>理解没有？发现是发现可监控的服务，并不是发现监控项。比如我们可以通过发现这机器上面有没有启动 ssh，发现有启动之后，我们就可以通过服务器端配置 discovery 自动添加一些监控规则。</p><pre tabindex=0><code>{
    &#34;data&#34;: [
        { &#34;{#SSH_PORT}&#34;: &#34;22&#34; },
        { &#34;{#SSH_PORT}&#34;: &#34;8022&#34; }
    ]
}
</code></pre><p>比如上面这个，我们发现了 2 个 ssh 进程，一个是 22 端口，一个是 8022 端口。</p><p>所以重点是发现有什么可监控的服务，并不是发现监控项。</p><p>BUT，其实并不是不能发现监控项，也是可以的。不过是，这种被发现的监控项，除非对应的 trigger 也都是一样的，否则你会发现无法分别添加不同的 trigger 规则。</p><h2 id=发现监控项>发现监控项</h2><p>有了发现服务之后，就肯定需要对相应的服务的一些监控项做监控了。这个给 discovery 规则配置 item prototype 就可以了，不过这个里面有点坑需要填，后面会说，这里先不讲。</p><p>那么比如对于 ssh 服务，可以监控</p><ul><li>当前链接人数，conn.cnt</li><li>配置文件的 md5，conf.md5（配合 zabbix trigger 可以用来监控文件是不是被修改了）</li></ul><p>那监控数据就如下面</p><pre tabindex=0><code>{
    &#34;22.conn.cnt&#34;: 4,
    &#34;22.conf.md5&#34;: &#34;18492113fb263c9d0a33c9fea403eea1&#34;,
    &#34;8022.conn.cnt&#34;: 9,
    &#34;8022.conf.md5&#34;: &#34;6cab272daa07202ccb57c4064c0dcfb8&#34;
}
</code></pre><p>上面就是一个 discovery 项目，filter 是 {% raw %}{#SSH_PORT}{% endraw %}，和 2 个 item prototype，分别是 {% raw %}{#SSH_PORT}.cnn.cnt{% endraw %} 和 {% raw %}{#SSH_PORT}.conf.md5{% endraw %}。</p><h2 id=复杂一点的-lld>复杂一点的 LLD</h2><p>一个 LLD 还可以发现多个服务。比如下面这种。</p><pre tabindex=0><code>{
    &#34;data&#34;: [
        { &#34;{#SSH_PORT}&#34;: &#34;22&#34; },
        { &#34;{#SSH_PORT}&#34;: &#34;8022&#34; },
        { &#34;{#PG_PORT}&#34;: 5432 },
        { &#34;{#PG_PORT}&#34;: 6432 }
    ]
}
</code></pre><p>这个除了我们前面讲的 ssh 服务，还发现了两个 pg 的服务。在服务器端，只需要添加两个 discovery 规则就可以了，分别使用 {% raw %}{#SSH_PORT}{% endraw %} 和 {% raw %}{#PG_PORT}{% endraw %} 这两个宏来过滤数据。</p><pre tabindex=0><code>{
    &#34;data&#34;: [
        { &#34;{#SSH_PORT}&#34;: &#34;22&#34; },
        { &#34;{#SSH_PORT}&#34;: &#34;8022&#34; },
        { &#34;{#PG_PORT}&#34;: 5432 },
        { &#34;{#PG_PORT}&#34;: 6432 }
        { &#34;{#MASTER_DB_PORT}&#34;: 5432, &#34;{#SLAVE_DB}&#34;: &#34;host1&#34; },
        { &#34;{#MASTER_DB_PORT}&#34;: 5432, &#34;{#SLAVE_DB}&#34;: &#34;host2&#34; },
    ]
}
</code></pre><p>上面这个，除了有 2 个 db 之外，还有一个 db 是个 master，能看到他对应的 slave 有哪些。要注意，我们在新增加的这个发现项里面，不能再使用 {% raw %}{#PG_PORT}{% endraw %} 这个宏了，因为如果使用了这个宏，就会和第3，4个项目无法区分了。所以我们改了一下名字。</p><p>到此为止，只是我们的构思，想要告诉 zabbix 我们想要监控什么。真正使用还需要走一些路。</p><h2 id=如何发送数据>如何发送数据</h2><p>不管是 discovery 数据，还是 item 的监控数据，都可以通过 agent 和 trapper 方式发送。</p><p>对于 discovery 数据，使用 agent 发送就是上面讲的格式。</p><pre tabindex=0><code>{
    &#34;data&#34;: [
        { &#34;{#PG.OTHER}&#34;: &#34;0&#34; },
     ]
}
</code></pre><p>如果使用 trapper 方式发送，格式如下</p><pre tabindex=0><code>{
    &#34;data&#34;: [
        {
            &#34;host&#34;: &#34;HOST1&#34;,
            &#34;value&#34;: &#34;{\&#34;data\&#34;: [{\&#34;{#PG.OTHER}\&#34;: \&#34;0\&#34;}]}&#34;,
            &#34;key&#34;: &#34;pg.discover&#34;
        }
    ],
    &#34;request&#34;: &#34;sender data&#34;
}
</code></pre><p>上面这个数据里面，data 和 request 是 zabbix sender 的固定格式。data 里面，包含了 host, value, key 三个字段。host 是被监控的 host，和将来服务器端的 host 对应。value 是发送的监控内容，可以看到也就是我们使用 agent 发送的内容。key 就是对应的监控项，这个监控项也就是 agent 方式发送对应的那个 userParameter。</p><p>使用 trapper 方式发送里面，是可以伪造被监控的 host 的，所以 trapper 方式并不要求一定要在被监控机器上面执行。</p><p>对于 item 监控数据，使用 agent 发送是下面这种格式。</p><pre tabindex=0><code>{
    &#34;key1&#34;: 2,
    &#34;key2&#34;: &#34;ok&#34;
}
</code></pre><p>使用 trapper 方式发送，是下面的这种格式。</p><pre tabindex=0><code>{
    &#34;data&#34;: [
        {
            &#34;host&#34;: &#34;HOST1&#34;,
            &#34;value&#34;: 1,
            &#34;key&#34;: &#34;key1&#34;
        },
        {
            &#34;host&#34;: &#34;HOST1&#34;,
            &#34;value&#34;: &#34;ok&#34;,
            &#34;key&#34;: &#34;key2&#34;
        }
    ],
    &#34;request&#34;: &#34;sender data&#34;
}
</code></pre><h2 id=zabbix-里面的限制>zabbix 里面的限制</h2><p>上面的例子很完美，但实际上 zabbix 是有一些限制的。比如 item 定义。</p><p>假如对于发现的 pg 服务，有一个监控项是连接数，比如 {% raw %}{#PG_PORT}.conn.cnt{% endraw %}，此时你会发现在 zabbix 新建 item 的 <code>Key</code> 那个设置里面，这么写无法提交。需要使用假装类似 userParameter 的方式来写，比如 {% raw %}pg.[{#PG.PORT}.conn.cnt]{% endraw %}，假装那个 <code>pg.</code> 是个 userParameter 命令，{% raw %}[{#PG.PORT}.conn.cnt]{% endraw %} 里面的内容是他的参数。当然，这个 pg. 可以基本可以是任何字符串，比如 abc，你自己觉得有意义就好了。</p><p>那么这个时候对于发现那块，我们基本不用动，需要动的是被发送的服务的监控项的命名上面。</p><p>比如以那个 ssh 的监控为例，原来发送的数据如下</p><pre tabindex=0><code>{
    &#34;22.conn.cnt&#34;: 4,
    &#34;22.conf.md5&#34;: &#34;18492113fb263c9d0a33c9fea403eea1&#34;,
    &#34;8022.conn.cnt&#34;: 9,
    &#34;8022.conf.md5&#34;: &#34;6cab272daa07202ccb57c4064c0dcfb8&#34;
}
</code></pre><p>我们只需要修改成这样</p><pre tabindex=0><code>{
    &#34;ssh[22.conn.cnt]&#34;: 4,
    &#34;ssh[22.conf.md5]&#34;: &#34;18492113fb263c9d0a33c9fea403eea1&#34;,
    &#34;ssh[8022.conn.cnt]&#34;: 9,
    &#34;ssh[8022.conf.md5]&#34;: &#34;6cab272daa07202ccb57c4064c0dcfb8&#34;
}
</code></pre><p>对应的 2 个 item prototype，key 分别修改为 {% raw %}ssh[{#SSH_PORT}.cnn.cnt]{% endraw %} 和 {% raw %}ssh[{#SSH_PORT}.conf.md5]{% endraw %}。那个 ssh 可以随意起。并且其实并不一定就得是这种模式，比如叫做 {% raw %}ssh.conf.md5[{#SSH_PORT}]{% endraw %} 应该也可以，当然需要你发送的数据也做对应修改。</p><h2 id=如何发送监控数据>如何发送监控数据</h2><p>咦？好像说过一次了？这次和上面不一样，呵呵。</p><p>设计好并写好监控之后，选择什么方式发送监控数据呢。我选择的是 discovery 数据通过 agent 方式获取，也就是在各服务器上面定义相同的一个 key，然后执行这个 key 的时候发送发现的服务信息。</p><p>而对于监控项数据则通过 trapper 方式发送。通过 trapper 方式发送，需要定时执行，可以通过 crontab 发送。我选择的是建立了一个 agent 类型的 item，执行这个 item 的时候发送监控数据。这样一方面可以针对这个发送动作建立一个监控，另外一方面调整很方便，zabbix 界面修改就可以。并且我把这个 item 建立到了模板上面，只要修改应用模板就可以了。</p><p>监控数据也可以用 agent 方式发送，如果用 agent 方式发送，对于上面的 ssh 服务，就需要真的建立那个 ssh 的 userParameter 了，然后接受比如 <code>22.conf.md5</code> 这样的参数，去返回对应的监控数据。我没有用这种方式，是因为这样做等于有多少个 item 就需要在监控周期内执行多少次那个命令，给服务器增加负担（虽然没多少）。而使用 trapper 方式的话，就可以一次把所有的监控数据都发过去了，命令只需要执行一次。</p><h2 id=如何应对不同的部分>如何应对不同的部分</h2><p>到此为止，应该可以很完美的发现服务，并且监控了。但是会发现其实并不是所有服务器的服务都是一样的，比如对于 pgsql，slow query 的界定对于不同的业务可能不一样。而因为 trigger 也是自动发现添加的，这样也有可能需要不同的机器上面的服务有不同的阈值，怎么解决呢？</p><p>先说监控项的阈值。因为我的监控数据其实是通过建立一个 agent 类型的 item 定期发送 trapper 数据来实现的，所以只需要在调用那个 item 的时候传送不同的阈值就可以了。实际上面我的 itme key 定义是这样的 <code>pg.sendtrap[{$PG.DISCOVER.SETTINGS}]</code> 。那个 pg.sendtrap 是对应到一个 userParameter 的 <code>UserParameter=pg.sendtrap[*],/etc/zabbix/bin/zabbix_pg.py --check --sendtrap --settings $1</code>，在 zabbix_pg.py 里面，会处理 settings 参数。如果有阈值，那就定义好 <code>{$PG.DISCOVER.SETTINGS}</code> 这个宏就可以了。template 上面可以定义默认的阈值，当然默认阈值在程序里面定义也可以。然后不同 host 可以定义 host 的阈值，会覆盖模板的配置。</p><p>其实 trigger 的阈值和这个思路类似，也是 template 里面定义一个宏，trigger 里面使用这个宏就可以了。如果 host 有不同的阈值，那就定义一个 host 的宏覆盖他就可以了。</p><h2 id=目前的情况>目前的情况</h2><p>配合 zabbix 的 auto registration 这个 action，可以做到新机器只需要执行一个 saltstack state，安装好我们的 zabbix agent，就可以自动注册 host，自动添加监控报警。</p><p>相当完美。</p></content></main><footer>Made with <a href=https://github.com/janraasch/hugo-bearblog/>Hugo ʕ•ᴥ•ʔ Bear</a></footer></body></html>