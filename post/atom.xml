<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on wd and cc</title>
    <link>https://wdicc.com/post/</link>
    <description>Recent content in Posts on wd and cc</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Wed, 19 Jun 2019 15:38:56 +0800</lastBuildDate>
    
	<atom:link href="https://wdicc.com/post/atom.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Django Testing</title>
      <link>https://wdicc.com/django-testing/</link>
      <pubDate>Wed, 19 Jun 2019 15:38:56 +0800</pubDate>
      
      <guid>https://wdicc.com/django-testing/</guid>
      <description>Django 自己的 unittest 支持的挺好，一般只需要在 app 下面加一个 tests.py 在里面写 case 就可以了。case 对应的类继承 django.test.TestCase 就好。
每一个测试类里面，都可以有一个 setUp 方法，是在 case 方法执行前执行，例如一些准备工作，和一个 tearDown 方法，在 case 执行之后执行，例如一些清理工作。还可以有若干个使用 test 开头的测试用例。
case 我觉得一般可以分两种，方法测试，和接口测试。
方法测试指针对一些工具方法什么的测试，当然这个说法并不严谨，将就理解吧。我把这些归类为不涉及到数据库操作的测试。
接口测试，一般会涉及到数据库操作，需要验证登录啊，参数什么的。
Django 里面，每个测试用例之间是通过事务互相隔离的，所以不用担心互相之间会有影响。
接口测试可以通过 django.test.Client 来访问你的接口，然后比对返回结果，或者比对数据库的数据来验证。
有时候一些接口是依赖已有数据的，比如一个返回所有用户的接口，那测试的时候数据库是需要有用户才能返回的。这个可以通过 fixture 来 moke 数据。
fixture 就是一些 json 文件，里面放的是和 model 的数据，这样一个测试如果需要某几个 model 对应的表里面事先有数据，那可以把他们放到 fixture 文件里面，让 django 在运行之前先 load 到数据库就可以了。
这些 json 文件自己编写会死，Django 提供了 manage.py dumpdata --indent 4 [app_label[.ModelName] [app_label[.ModelName] 功能，可以方便你导出数据库里面已有的数据。不指定 app_label 和 modelname 就会导出全部的，一般只导出自己需要的就好。注意 json 文件是可以支持缩进的。
如果从比如开发库之类的倒数据，会觉得数据有点乱，从测试库倒数据似乎比较清净，因为每次测试都是一个空的数据库。有一个方法是在测试用例里面创建依赖的数据，但是测试执行完了再执行 manage.</description>
    </item>
    
    <item>
      <title>Add Disk for Aws</title>
      <link>https://wdicc.com/add-disk-for-aws/</link>
      <pubDate>Wed, 19 Jun 2019 15:29:33 +0800</pubDate>
      
      <guid>https://wdicc.com/add-disk-for-aws/</guid>
      <description>AWS 的 ec2 支持不停机扩展磁盘，体验还不错，记录一下操作。
先看看磁盘是不是支持，例如下面的 GPT 的是支持的
$ sudo gdisk -l /dev/xvda GPT fdisk (gdisk) version 0.8.10 Partition table scan: MBR: protective BSD: not present APM: not present GPT: present Found valid GPT with protective MBR; using GPT. Disk /dev/xvda: 20971520 sectors, 10.0 GiB Logical sector size: 512 bytes Disk identifier (GUID): 826F22DD-540A-4299-AB06-F03EE98F1CAF Partition table holds up to 128 entries First usable sector is 34, last usable sector is 20971486 Partitions will be aligned on 2048-sector boundaries Total free space is 2014 sectors (1007.</description>
    </item>
    
    <item>
      <title>Debuging Django</title>
      <link>https://wdicc.com/debuging-django/</link>
      <pubDate>Mon, 29 Apr 2019 14:41:12 +0800</pubDate>
      
      <guid>https://wdicc.com/debuging-django/</guid>
      <description>起初 hackernews 看到一个文章 PySnooper: Never use print for debugging again，觉得挺有意思的，结果把 hackernews 的讨论看了一下发现有意思东西更多一点，总结一下。
 [https://github.com/cool-RR/pysnooper][PySnooper]]: Never use print for debugging again，只需要给函数加一个装时期，就可以把函数执行的每一步的结果都打印出来。 [https://django-extensions.readthedocs.io/en/latest/runserver_plus.html][django-extensions]] 的 runserver-plus 配合 Werkzeug 可以实现在遇到异常的时候，支持在 web 上面调试代码，打印异常的时候的上下文内容什么的。 Python 自己的 breakpoint 函数，执行到的时候默认会进入 pdb.set_trace() 状态方便你进行上下文调试。 [https://github.com/gruns/icecream][icecream]] 提供了一个方便的 ic 函数，可以无感的加入到你的代码里面，不影响你的代码的执行结果，但是会打印传给它的参数和执行结果。 [https://github.com/robdmc/behold][Behold]]: A debugging tool for large Python projects，可以替代你写冗长的打印命令。不过感觉它自己的语法似乎也并不方便。。。 VS Code 提供的 Logpoints 和 Visual Studio 提供的 Break When Value Changes。 [https://github.com/cknd/stackprinter][stackprinter]] 可以让你的堆栈打印更友好，打印堆栈的时候还可以输出上下文的取值。 pdb, epdb，ipdb, 应该都是类似的东西，其中 pdb 是自带的。通过给代码增加 import ipdb ipdb.set_trace() 调试。 [https://github.com/tylerwince/pydbg][pydbg]] 替代 print 的。  </description>
    </item>
    
    <item>
      <title>How to Create an Index in Django Without Downtime</title>
      <link>https://wdicc.com/how-to-create-an-index-in-django-without-downtime/</link>
      <pubDate>Fri, 26 Apr 2019 11:46:27 +0800</pubDate>
      
      <guid>https://wdicc.com/how-to-create-an-index-in-django-without-downtime/</guid>
      <description>django 自己带了一个 ORM 实现，基本可以通过 ORM 管理数据库，这样用户可以在不会 SQL 的情况下使用数据库。在对 model 的属性（字段）做了修改之后，通过执行 makemigrations 可以生成一个 migrate 文件，然后执行 migrate 命令可以把这些修改应用到数据库。同时在数据库里面，也会记录当前 migrate 执行的状态，这样能保证数据库的状态和 django 自己认为的数据库的状态是一致的。
但是这里可能会有一个问题，我们有多个数据库环境，也有多个人一起开发，这样就会导致这个有点混乱，多个人修改 model 后都执行了 makemigrations 的话，可能会有冲突和问题（实际上 django 已经考虑过这个问题的，migrate 文件都是按照时间戳来命名的，冲突可能性也不大，但是为了避免新手加入弄不好，所以我们采取了另外一个方法做这个事情）。
下面的内容翻译自 https://realpython.com/create-django-index-without-downtime/ ，我们使用了里面提到的 sqlmigrate 的方式。
管理数据库变更在软件开发中是一个比较大的挑战。幸运的是，从 django 1.7 开始有了内置的数据库变更处理框架。这个框架对于处理数据库变更来说很强大很好用。但是为了保证框架提供的灵活性，有一些妥协在里面。为了理解 django 数据库变更框架的限制，我们将解决一个有名的问题：如何在不停机情况下通过 django 创建索引。
 在这个教程里面，你将学习到： django 是什么时候和如何产生数据库变更的 django 是如何执行变更的 如何按照需要编辑这些变更  这篇文章面向的是对 django 数据库变更（migrations）已经有所了解的人的。如果对这些还不了解，那可以先看看 Django Migrations: A Primer 。
在 django 里面创建索引存在的问题 一个常见的变更是当你的数据增加的时候会需要建索引。索引可以查询的速度和应用的响应速度。
大部分数据库里面增加索引需要在表上面加一个排它锁。当索引创建的时候，排它锁不允许进行数据修改（DML）操作，例如 UPDATE, INSERT, 和 DELETE 。
当数据库执行这些操作的时候，会立刻加锁。例如如果一个用户登录的时候，django 会更新 auth_user 表的 last_login 字段。为了执行这个操作，数据库会先请求一个行锁，如果这行被其他连接加了锁，那你可能会得到一个数据库异常。</description>
    </item>
    
    <item>
      <title>Readings</title>
      <link>https://wdicc.com/readings/</link>
      <pubDate>Fri, 19 Apr 2019 15:38:57 +0800</pubDate>
      
      <guid>https://wdicc.com/readings/</guid>
      <description>﻿1984 ([英] 乔治·奥威尔) 这书看完我觉得这根本就是一本恐怖小说，当里面的内容正在和将要发生的时候你就不会觉得里面的描述有点搞笑了。不过看到后面有译者的补充内容说和其他国家的朋友讨论的时候，大家都会有各种不同的带入感，觉得也挺有意思的。这可能是所谓的普世价值吧，大家都觉得不应该这样。
思想罪可是件要不得的事情，老兄，”他庄重地说，“它很阴险。你甚至还不知道发生了什么事，它就抓住了你。你知道它怎样抓住我的吗?在睡梦里!  这里是温斯顿一个朋友讲他怎么被抓的，因为说梦话说了一些不该说的，被女儿举报。。。
谁能控制过去就控制未来;谁能控制现在就控制过去  拗口么，控制了现在就可以（通过修改历史）控制过去。
不是!不光是要你们招供，也不光是要惩罚你们。你要我告诉你为什么把你们带到这里来吗?是为了给你们治病。是为了使你神志恢复健全! 温斯顿，你要知道，凡是我们带到这里来的人，没有一个不是治好走的。我们对你犯的那些愚蠢罪行并不感到兴趣。党对表面行为不感兴趣，我们关心的是思想。我们不单单要打败敌人，我们要改造他们。你懂得我的意思吗?“  犯了思想罪的人都病了，需要治。
党越有力量，就越不能容忍;反对力量越弱，专制暴政就越严。果尔德施坦因及其异端邪说将永远存在。  1Q84 (村上春树) 姑且礼貌的问问。可是希望得到回答的哟。嘴不利索的话，点头或者摇头。  这个书是看完上面的 1984 之后翻的，看了第二章感觉就有意思起来了，很会通过故事吸引人。不过这个书里面的隐喻实在好难懂啊，看别人的书评才能理解一些，可能作者厉害的地方就在这里吧。。。
伟大的博弈:华尔街金融帝国的崛起(1653～2011)(珍藏版) (约翰·S·戈登) 这本书几乎是从美国建国讲起，讲到后面华尔街兴起，以及美国的金融市场是怎么一步一步发展起来的，华尔街的起起落落，和看故事书一样。
作为新兴工业经济基石的钢铁也彻底改变了华尔街的外观。许多建于19世纪50年代的陈旧的6层小办公楼被一一推倒，让位给“摩天大楼”（skyscraper）——这个词在1883年才被创造出来。钢铁建材的出现和电梯的发明使摩天大楼成为可能，而纽约狭小的城市面积更使得摩天大楼的大量出现不可避免。纽约古老街区里窄窄的街道从此开始熟识摩天大楼巨大的投影和楼宇之间漏出的些许阳光。这种趋势引起了市民和市府官员们的警觉，当40层的“衡平保险公司大厦”（Equitable Building）在雪松大街和青松大街之间的百老汇上开始建造时，它严严实实地占据了整个街区，这直接导致美国第一部城市规划条例的颁布。就像快餐一样，城市规划条例也发源于华尔街。事实上，美国文化中很多与金钱无关的传统都与华尔街有关。  一些美国的文化据说是发源于华尔街，比如快餐是因为股价上下波动很快大家忙到没时间吃饭，所以有了快餐。。。城市规划是因为华尔街发展太快不得不开始进行必要的规划。。。
荷兰人早在导演和参与“郁金香泡沫”时练就的投机技术，很快就被运用到了北美新大陆。发生在这块处女地的第一次金融投机活动是针对当时原始的货币——贝壳串珠进行的投机，这次金融投机揭开了北美350年的金融史——同时也是350年的投机史的序幕。这些投机技术在以后的历史中被反复应用，投机者们沉溺其中，乐此不疲。  从郁金香泡沫开始讲投机，囤积贝壳让贝壳价值上涨获利。
荷兰人发明了最早的操纵股市的技术，例如卖空（short-selling，指卖出自己并不拥有的股票，希望在股价下跌后购回以赚取差价）、“洗盘”（bear raid，指内部人合谋卖空股票，直到其他股票拥有者恐慌并全部卖出自己的股票导致股价下跌，内部人得以低价购回股票以平仓来获利）、对敲（syndicate，指一群合谋者在他们之间对倒股票来操纵股价），以及逼空股票（corner，也称杀空或坐庄某一只股票，或囤积某一种商品，指个人或集团秘密买断某种股票或商品的全部流通供应量，逼迫任何需要购买这种股票或商品的其他买家不得不在被操纵的价位上购买）。  （这种总是期望有人会愿意出价更高的想法，长期以来被称为投资的博傻理论）  。这时候菲利普斯开始买进贝壳串珠，并囤积起来。实际上，他把贝壳串珠装在桶里埋在地下，以减少贝壳串珠的流通量。几周之内，他就控制了串珠市场，成功地抬高了价格。到1666年，3颗白串珠就相当于1个斯图弗。  控制市场上面的量，控制价格。
最常见的铸币是西班牙的里亚尔银币（Spanish real），经常被切成2块、4块、8块来找零钱。这就是为什么直到今天，纽约证券交易所还是以一美元的1/8为最小单位来报价，而不是1/10。  到18世纪90年代，尽管费城的发展速度远远低于纽约，但它依然是那时美国的金融中心。美国的第一家银行——北美银行（Bank of North America）是在费城成立的；美国的第一家证券交易所——费城证券交易所（Philadelphia Stock Exchange）在1790年成立。在此后的10年内，费城仍然是美国的首都，而华盛顿那时尚在建设之中，因此，汉密尔顿的中央银行——美国银行（Bank of the United States[35]）也于1791年在费城成立。  早期的时候，费城是金融中心，纽约还排不上号。
·资本市场的繁荣催生了第一批专业的证券经纪人，他们需要一个专用的交易场所；为了防止在门口偷听价格“搭便车”的场外交易发生，也为了防止经纪人们无休止地杀低交易佣金，他们签订了著名的《梧桐树协议》——这一向被认为是纽约交易所的源头，而本质上是一个卡特尔——价格同盟。  开始的时候证券交易是小部分人聚集起来做的一个事情，他们为了保证自己的佣金利益，搞了这个协议，很多年之后（似乎是19xx年）才放开佣金，那会都是固定佣金。
·在这一时期，有限责任制度——现代企业制度的基石得以奠定，美国各州通过了《普通公司法》，带动了新一轮的经济增长，从1792年到1817年，联邦税收在25年内增长了9倍。  公司法颁布之前企业都不能像人一样拥有自己的财产。
18世纪末期，经纪人这个概念的含义要比今天宽泛得多。这个词早在14世纪就从法语引入到英语中，它的法语原意是：把一桶酒分装成一杯一杯或一瓶一瓶后再卖出的人。在17世纪之前，这个词一直特指零售商和批发商，此后，它就完全被用来特指自己不直接参与生产的中介人。到这个时期，“经纪人”的含义逐渐演变为：将买方和卖方撮合在一起，并对促成的交易收取佣金的人  broker 这个词在计算机领域也有，做代理，分发这类事情的，叫做 broker。
美国银行股票（很快被简称为“BUS”）的交易在1791年春就已经开始了。这一年7月，该股票正式认购时，在一小时之内就全部卖光，随后股价一路攀升。这个新生国家的第一次大规模的股票公开发行（IPO）启动了它的第一轮牛市。  股票的含义才被特指为代表所有权的证券，而债券被特指为代表债权的证券  《梧桐树协议》。这被公认为是纽约证券交易所的最初起源，但本质上却是一个经纪人的卡特尔，纽约证券交易所的这一本质直到180多年后才得以改变。  ”杰斐逊一向痛恨投机者，此时几乎掩饰不住自己的兴奋，他算了一下，投机者损失总值达到了500万美元，这相当于当时纽约的房地产总值。他的结论是，股市恐慌所带来的损失跟自然灾害摧毁纽约所带来的损失是一样的。  股市恐慌带来的损失也会很大。带来失业，市场不景气，各种连锁反应。</description>
    </item>
    
    <item>
      <title>Blogs Weechat Official Accounts and Freedom</title>
      <link>https://wdicc.com/blogs-weechat-official-accounts-and-freedom/</link>
      <pubDate>Thu, 28 Mar 2019 11:18:37 +0800</pubDate>
      
      <guid>https://wdicc.com/blogs-weechat-official-accounts-and-freedom/</guid>
      <description>十几年前，还没有微博的时候，大家热衷于开 blog 写点自己想写的东西，出来了一大批 blog 平台，不管写多少内容有没有什么价值，很多人都会开一个自己的 blog。同时也有不少人自己搭建自己的 blog 平台，那会还有人卖空间专门搭 blog 用，提供一个虚拟主机，可以一键弄一个自己的 wordpress。
我最早的时候的 blog 是自己搭建的，后来也用过 wordpress，也去新浪开过博客。现在看开 blog 其实满足了用户的两个诉求，一个是写东西表达自己的想法，一个是社交。单纯的表达自己的想法可能也是一种发泄输出吧，写下来会觉得有了输出，之后会觉得告一个段落。至于社交，一般是几个好友会互相关注对方的 blog，比如当时的 msn space，qq 空间这些会直接在 im 工具里面提醒你。对于感兴趣的人不管是朋友还是陌生人，可以留个言什么的互相交流。以前在各个平台开的博客现在有的是平台死了文章没有了，有的是自己都忘记用什么账号开的了，找不到了。倒是自己搭的平台因为自己持续的在把数据保留下来，现在还有一些历史数据，现在回看这些内容感觉也挺好玩挺温馨的。
到了现在，blog 基本都死了，出现了微信公众号这个东西，我一直觉得微信公众号是一个反互联网的东西，他们想了很多办法来防止里面的内容被外部抓到，比如我自己发布的内容想在自己网站提供一个列表给大家看就不行，因为虽然提供了在 pc 浏览器看内容的方式，但是只能看单篇，想看其他的必须用手机扫了码之后在手机看，并没有提供 pc 的列表页。只能是发一篇把一篇文章地址加入到自己的列表里面。
内容格式支持 html，编辑器不好用还催生了一批辅助工具，从这些工具复制源码之后，确实可以有效果，但是因为微信实际并不能编辑源码，有时候遇到复制的奇葩的代码，会发现无论如何都编辑不好。而且关键是微信官方对待公众号和对待聊天功能一样，并没有多少兴趣去把这个东西做到极致，也可能是因为他们从 qq 那边看到，功能怎么样和用户用不用其实并不是那么的强相关吧，并不是提供了用户所有想要的功能用户就会用，这样反而增加了产品的复杂度可能得不偿失。
公众号还有一个问题是，他们天然倾向于满足用户的需求，用户需要低俗八卦那他就会想办法多制造这些内容，而且这些东西在那些人的圈子里面流窜，获得更多的用户。比如那些养生的东西，这能吃那不能吃的文章在中老年圈子里面就流传的很快。但是一篇反过来避谣的文章就流传不起来，因为这些人不会关注这样的公众号。造谣一时爽，避谣跑断腿。只是拿这样的一篇文章如何能说服对方呢？对方首先一个并没有看到多少人支持这个观点，另外一个可能会说好好我信你了，然后就完事了，也不会转发打自己的脸，不会觉得要对那些看了自己转发的文章的人负责。
微博上面相对好一点，在原微博上可以直接可以看到不同观点，反对的微博也可能会再次出现在自己的时间线也同样可以看到针对这个微博大家的观点，这也是一个学习的过程，反思自己之前为什么会没有在第一时间看到其他提出来的问题呢，自己也会持续提升自己的判断辨别能力。但是微博上面又会放大参与者的情绪，导致一些极端的情况，这就另说了。
今天还听了另外一个观点，可以一起聊聊。现在各种算法会依据你看的内容不停推荐类似的内容，比如你喜欢看猫，那就持续的推猫的内容，让你不停的看下去。最开始可能是今日头条开始这么做的吧，后面网易新闻也跟进了。我一直用的是网易新闻，期间试过看今日头条，发现里面内容质量不高之后就删掉了，直到某天网易新闻也开始做了类似的事情，新闻每次刷新都会给你推荐新的，导致没有看完的时候，就把网易新闻也删除了。换了即刻，现在发现即刻也可以乱推一些东西之后，取消关注了很多的频道，现在用的也不多了。
你喜欢看什么，就尽量多的给你推什么，这个算法有问题么？其实挺美好的，这样不就不用你来回自己去找想看的内容了吗？但是这样其实也会有几个问题，一可能会让你接触不到其他你没接触到但是有可能喜欢的东西，二可能会让人的思路变得极端。每天都环绕在一个没有争议的环境里面，慢慢的可能会失去辨别能力，也很更加不容易接受不同的东西。
说回那个观点，那个观点讲的就是比如看了一个宣扬极端观点的视频，他持续给你推荐这些视频的话，会不会容易把这个人变的很极端？按说是存在这种可能的，当然如果这个人自己确实对这个感兴趣那总也是会自己找这些信息看的，不过是这种推荐可能节约了他的时间。
标题为啥还提到了自由呢？微信我感觉就是不自由的，把大家圈进来之后就只能在这里面玩，决不允许有出去的机会。并且也没有意愿提供一个自由的环境。群里发一个链接，还需要先经过微信的审核，如果他们不想让你打开你就打不开，比如淘宝的链接就打不开。话说这个居然没有反垄断法来管理也是有意思。微博上面发的内容相对自由一点，但是微博的审查也比较厉害，当然这个是也有国家层面的事情，不多说了。</description>
    </item>
    
    <item>
      <title>Co. founders</title>
      <link>https://wdicc.com/co-founders/</link>
      <pubDate>Wed, 13 Feb 2019 18:14:39 +0800</pubDate>
      
      <guid>https://wdicc.com/co-founders/</guid>
      <description>和别人一起搞了一个公司，算是一个技术合伙人。目前参与技术团队的组建，产品团队的组建等。目前公司运行了大概 2 年不到，稍微总结一下。
需要什么样子的合伙人 开公司前应该需要先弄清楚自己需要什么样子的合伙人。一般来说都会找一个和自己能力互补的，比如自己搞技术的，找一个产品或者运营方向比较强的。这样大家分工协作，以最少的资金发挥最大效力。
但是这里其实有一个问题，怎么评价对方的能力。因为是补充自己不专业的部分，那自己一般并没有能力仔细考核对方的能力，怎么办？
国外公司招聘技术人员，会倾向于考核算法等基础能力，即使你工作年头再长，也不看你做的系统业务有多牛逼，只看你的基础技术能力如何，对一些底层协议了解情况等等。为什么呢？
我感觉因为我们做的事情事情通常有很大的不确定性，技术是为业务服务的，业务方向随市场情况走。技术这块来说，算法协议这些东西都是不变的，了解了原理，那不管是用什么语言，为什么业务服务，都可以随机应变，很快可以适应。
类似的，我们找合伙人实际上也不应该只考虑对方看着目前刚好符合需求，而更多的应该去看看这个人的过往业绩，是否在你不擅长的领域做了很多让你值得给出好评的成绩，同时也需要注意，是他做出来的，还是依赖公司的品牌做的。
另外也需要看看对方的团队组建能力，毕竟不可能单打独斗打天下，那必定会涉及到招聘，如果对方目前的团队战斗能力明显不行，那你也不要抱很大希望对方将来可以组建出来强大的团队。考核团队可能也简单，看看对方的团队的人都来自哪里，擅长做什么就好。
 总结下来似乎 2 点： 过往的业绩，擅长的业务方向，擅长的工作方式。 团队组建能力。  需要有亲自动手的决心 合伙开公司，公司是自己的，当然这个是基于一定的股份比例来的，可能至少超过 5% 吧，具体多少看你，简单说就是一个让你觉得这个公司我需要想尽办法让他维持下去的比例。如果你找合伙人，也至少应该给到合伙人让他觉得公司是他自己的这样一个比例的股份。
公司是自己的，那就需要有亲自动手的决心。基于别人的成果，有时候很容易做出来一些让自己觉得自己牛逼的成绩。比如在一个大公司里面，做一个产品很容易就可以获得几十万的流量，或者做一个系统的时候，有很多公司资源可以使用，让你相对轻松的搭建一个复杂系统。如果离开公司，自己有没有兴趣和能力从头做这些事情呢？必须要有，因为你不做就没人做了。
创业一般都是搞一个不太成熟的领域，这里面很多事情都需要去摸索，想要快速发展，必须要亲自动手才能快速得到反馈，快速知道自己是否应该调整方向适应市场。如果让其他人做，那经过反馈，指导，反馈，指导这样的多次循环可能才会发现是需要我们调整方向，而不是办事的人有问题。
实事求是，合伙人之间公开信息 合伙人之间信息共享，发挥集体的智慧。毕竟找合伙人的目的是为了补充自己的短处，那么就应该多利用合伙人的能力，以发挥最大的效力，合伙人之间应该公开所有信息，以便让大家清楚目前整个公司的目标和问题，能出力的多出力。
一定避免遇事只是自己发愁，还有各种刻意遮掩的情况，多发挥集体智慧。</description>
    </item>
    
    <item>
      <title>Zero to $1B: 8 Lessons Scaling a Startup</title>
      <link>https://wdicc.com/8-lessons-scaling-a-startup/</link>
      <pubDate>Tue, 22 Jan 2019 18:25:37 +0800</pubDate>
      
      <guid>https://wdicc.com/8-lessons-scaling-a-startup/</guid>
      <description>原文是这里 Zero to $1B: 8 Lessons Scaling a Startup，这里只是部分翻译 + 我自己的理解。
Lesson #1: 要谦虚的同时，保持自信  要相信你是最牛逼的，可以搞定一切问题。 也要够谦虚知道可能有不足，幼稚的地方，要听取别人的意见建议。 也要谦逊的知道你自己的技能不一定适合公司的各个阶段，还需要不断提升自己的能力。  Lesson #2: 可能会需要同时创立不止一个公司，可能是一系列公司  把你自己的领导能力看成是产品，多征求用户（也就是员工）的意见，严肃对待批评，但是不要当作是针对你自己的，对新的战略做做 A/B 测试。 雇佣一个教练（？）。 不管规模多大，每 6 个月给团队做一个 360 度的评测。 [http://paulgraham.com/identity.html][Keep your identity small]] 这个意译似乎是说：不要给自己贴过多的标签，这会让你更陷入很多的无意义的争论。  Lesson #3: 你的快乐和你创业公司的成功的关联性可能是 0.64  经常锻炼身体，保证充足的睡眠，开始做做冥想。 避免自娱自乐。比如某个月收益不错，就开始用这个推算我们未来三年怎么怎么样，某个月行情不行，就奔溃的不行。别着急想那么远，多看看眼前的事情吧。 开始募集资金的是，根据市场反馈及早做调整。我们 A 轮的时候，被 42 次拒绝之后，我们进行了重组，更改了我们的要价，然后就找到了一家对我们有信心的投资。  Lesson #4: 好的公司胜在产品创新和商业模式创新上  获取客户的模式是商业模式的竞争。 早期的创始人需要多花点时间想想商业模式创新和获取客户的策略。  Lesson #5: 企业文化是用来帮助你成功的一个自我实现的故事  如果要设计企业文化，那有几步参考 确定你们这个行业里面成功的公司具备的特征是啥。比如共享单车企业（需要速度）和做医疗的企业（需要严谨）就不一样。 确定什么样子的企业文化会带来那些特征。 持续基于那些企业文化招聘和管理你的团队。  Lesson #6: 有一个不合理的动机是有帮助的 这里作者讲了一个自己的事情，他当年在选择去斯坦福商学院还是创业的时候，想问问斯坦福那边是不是可以晚几年去，对方说你创业啥时候都可以，斯坦福可就这么一个机会。不过作者后面还是去创业了，现在牛逼的时候说每年都会拿出了那个信看看，激励自己。。。</description>
    </item>
    
    <item>
      <title>The Year in Sound</title>
      <link>https://wdicc.com/the-year-in-sound/</link>
      <pubDate>Sun, 13 Jan 2019 13:07:44 +0800</pubDate>
      
      <guid>https://wdicc.com/the-year-in-sound/</guid>
      <description>自从发现 NYTimes 的 The Daily 之后，听的比较多，2018 年底，他们有一期 The Year in Sound 对 2018 年的一个总结，听的时候觉得可以总结一下里面的事件。
 月份 Trump 和三胖在新加坡会面。前后还来回磨叽了几次。三胖同意解除核装置。后面三胖和南韩总统在边界还一起握手。 Robert Mueller 调查俄罗斯影响 2016 竞选。 fb 爆出来用户数据被一家公司 Cambridge Analytica 拿去可能影响了竞选，并且似乎 fb 自己知道这个事情。Mark Zuckerberg 被叫去听证会询问。后面 Sundar Pichai 因为给中国定制搜索引擎的事情也被叫去过。 月 14 号 Florida high school 17 人死于枪击案。学生对控枪的抗议。 月 4 号，居住在英国的前 Russian spy 和她女儿被人下毒。 移民政策的变更，分开孩子和大人，起诉大人，导致很多人孩子后面找不到了。后面把这个政策取消了。 Brett Kavanaugh 接替 Anthony Kennedy 成为大法官。Kavanaugh 还被一个博士爆出来说在高中时期（40年前）被试图性侵，开了听证会。 Trump 的律师 Micheal Cohen 被 Trump 开掉，以及后面反过来和 Mueller 配合指证 Trump。 Trump 和普京会面。 California 大火。 美国记者 Jamal Khashoggi 在沙特阿拉伯驻土耳其伊斯坦布尔的使馆里面被肢解。Trump 表示相信沙特王子不是他干的。 中美贸易战。 中期选举，民主党占了 house(似乎是众议院) 的多数。Nancy Pelosi 当选为 house 发言人。 Trump 年底嚷嚷要建墙要资金，议院不同意，直接把政府 shutdown 了，截至发稿还没谈妥。  还有一些应该没记录，可能会有遗漏。</description>
    </item>
    
    <item>
      <title>Iptv2</title>
      <link>https://wdicc.com/iptv2/</link>
      <pubDate>Thu, 10 Jan 2019 10:20:56 +0800</pubDate>
      
      <guid>https://wdicc.com/iptv2/</guid>
      <description>之前写过一篇关于 iptv 的帖子，里面用到了一个副路由，这样我家里其实就有两个路由器，这样用了比较长一段时间。
最近联通给换了一个光猫，很容易就可以 hack 进管理界面，就又折腾了一下 iptv 的事情。
iptv 和上网通道都是通过一根光纤进来的，通过不同的 vlan 区分数据。vlan 是二层的，收到这些数据之后如果有必要，可以通过 vlan id 来过滤出来，比如有的光猫会提供把 iptv 流量过滤到 4 口，其他上网流量过滤到光猫的其他口。我之前的猫就这样设置的，看 iptv 只能连接光猫的 4 口。如果光猫允许设置，那可以把 iptv 流量打上 tag 继续发到比如 1 口，这样 1 口就又有上网流量，又有 iptv 流量了，下一级路由就可以只通过这一条线来收两个流量了。
iptv 那个通道除了提供了组播数据（这个是具体的视频数据的来源）之外，还提供了一个只提供了必要的服务的互联网，比如提供了频道列表，各频道的节目表等等。
有的光猫可能会提供 pppoe 拨号功能和 wifi，不过一般没人用，因为性能差。所以一般我们会配置光猫做桥接，把数据透传下来，让下一级来拨号和提供 wifi。
（下面部分限于我自己的理解很有可能说错，欢迎指正）
iptv vlan 我看也提供了路由功能，也可以桥接透传。比如我之前的方式就是使用了光猫提供的路由功能，接了一个路由器，以光猫为上级路由器，然后会获取到一个内网的 ip。然后二级路由器上通过 udpxy 提供服务给内网用户用。
那这样的话，似乎可以直接在我的主路由上找一个网卡和光猫 iptv 口接起来，然后跑一个 dhcp 获取一下 ip 不就可以省掉副路由了么？ 1 不过我在 R6300v2 上尝试没成功 2。在新的软路由里面搞成功了。这里面也不需要跑 igmpproxy，我理解实际用的是上级光猫发过来的数据。
然后 igmpproxy 是怎么回事呢，我理解比如 iptv 是接到了路由器而不是光猫的时候，那么就需要路由器把光猫的那些数据转发下去，这个时候光猫需要通过桥接方式把数据给过来，然后需要把数据发到下级路由，这个时候还不能直接让这个数据在 lan 里面乱跑，否则会影响我们的网速，通过 igmpproxy 可以把上级光猫给过来的组播数据转发到某个端口，然后下级设备比如你把 iptv 接到这个端口，就可以通过那个端口获取这些 iptv 的组播数据了。这样 iptv 就不用接到光猫了，接到你的路由器就可以了。3</description>
    </item>
    
    <item>
      <title>Amap Work With Code Push</title>
      <link>https://wdicc.com/amap-work-with-code-push/</link>
      <pubDate>Sat, 05 Jan 2019 09:53:09 +0800</pubDate>
      
      <guid>https://wdicc.com/amap-work-with-code-push/</guid>
      <description>我们 app 用了高德地图和 codepush，iOS 里面之前用的高德地图 sdk 的 5.x 版本，最近想升级到最新的 6.6.0 发现和 codepush 出现了 symbol 的冲突，主要是两个函数 aes_decrypt_key128 和 aes_encrypt_key128 。
高德地图是不开源的，万幸我们有 codepush 的源码，所以思路是只需要把 codepush 里面冲突的函数改个名字就好了。
改代码很简单，主要是怎么和项目集成。我用的是 patch-package ，做法如下。
给 package.json 的 scripts 增加一个 postinstall
&amp;quot;scripts&amp;quot;: { &amp;quot;postinstall&amp;quot;: &amp;quot;patch-package&amp;quot; }  然后就是改 node_modules/react-native-code-push 下面的文件，改完之后，执行一下 yarn patch-package react-native-code-push 会生成一个类似 patches/react-native-code-push+5.5.1.patch 的文件，确认一下这个文件里面是不是包含了你修改的内容。
这就可以了，以后执行 yarn install 的时候会自动打这个 patch。
这个方式比 fork 一份对方的代码好一点，有时候有些代码发到 npm 的是编译之后的版本，fork 之后也不好用，除非你也发布一个。用 patch 的方式会好一点，安装的还是对方发布的。</description>
    </item>
    
    <item>
      <title>Android Packaging</title>
      <link>https://wdicc.com/android-packaging/</link>
      <pubDate>Sun, 02 Dec 2018 16:52:34 +0800</pubDate>
      
      <guid>https://wdicc.com/android-packaging/</guid>
      <description>国内市场因为 android 的发布渠道比较多，所以一般我们会想要追踪一下用户使用的包是从哪里下载安装的。
Android 打包支持 buildTypes ，一般这个会用来区分不同的环境，比如 dev，beta，prod 等，不同环境可能会有一些不同的设置，比如 dev 会打开更多的日志输出什么的。
 android{ buildTypes { debug { ... } release { ... } beta { ... } } }  还有一个支持是 productFlavors，一般用这个来区分不同的渠道，不同渠道也可以有一些不同的设置，类似上面的 buildTypes。
 android { productFlavors { xiaomi {} baidu {} wandoujia {} x360 {} } productFlavors.all { flavor -&amp;gt; flavor.manifestPlaceholders = [CHANNEL_ID: name] } }  配合 AndroidManifext.xml 文件的配置
 &amp;lt;meta-data android:name=&amp;quot;CHANNEL_ID&amp;quot; android:value=&amp;quot;${CHANNEL_ID}&amp;quot; /&amp;gt;  在代码里面取到这个，然后设置渠道。
这样就可以打渠道包了 ./gradlew assembleWandoujiaRelease 编译 wandoujia 这个渠道的 releases 包。这个方式有一个问题是，每一个渠道包都需要从头编译一次，一个渠道 10 分钟，那所有渠道下来，就可能需要一个小时了，关键是很多无用功。</description>
    </item>
    
    <item>
      <title>A* Search Algorithm</title>
      <link>https://wdicc.com/a-star-search-algorithm/</link>
      <pubDate>Sat, 24 Nov 2018 14:48:04 +0800</pubDate>
      
      <guid>https://wdicc.com/a-star-search-algorithm/</guid>
      <description>前段时间我们设想了一个需求，想帮助用户规划一下从 A - B 的航线。对于路径规划从来没弄过，研究了一下，基本都在提这个 A 星寻路算法。
 先贴几个文章： 简单的讲解的文章例如 https://www.jianshu.com/p/65282bd32391 这个详细一点的 https://blog.csdn.net/DinnerHowe/article/details/79380317  我写了一个简单的程序，这个程序没有做过任何的优化，只能说是解释了这个算法的逻辑而已，在终端里面可以可视化的把计算过程显示出来。效果可以看这里。
#!/usr/bin/python import sys import random RED = &#39;\033[31m&#39; GREEN = &#39;\033[32m&#39; GRAY = &#39;\033[35m&#39; NC = &#39;\033[0m&#39; class Point(object): x = 0 y = 0 close = False open = False start = False end = False wall = False H = 99 G = 99 parent = None def __init__(self, **kwargs): if &#39;x&#39; in kwargs: self.</description>
    </item>
    
    <item>
      <title>Phpbb Auth Plugin</title>
      <link>https://wdicc.com/phpbb-auth-plugin/</link>
      <pubDate>Sat, 17 Nov 2018 21:15:50 +0800</pubDate>
      
      <guid>https://wdicc.com/phpbb-auth-plugin/</guid>
      <description>这几天我们这里需要搞一个论坛，我搜了一些，选了 phpbb，这个毕竟年头比较久远，也支持 PostgreSQL。
我们自己本身有自己的会员逻辑，所以就需要把他的登陆和我们自己的结合，而 phpbb 也支持自己作 Auth Plugin。
 涉及到的文件有几个 includes/auth/auth_foo.php：这个是具体的 auth 逻辑代码的地方。 config/default/container/services_auth.yml：这个是注册这个 auth 逻辑的地方。 template 模板文件：这个我没涉及到，所以没去了解。  service 文件的配置：
auth.provider.skyreq: class: phpbb\auth\provider\foo arguments: - &#39;@dbal.conn&#39; - &#39;@config&#39; - &#39;@passwords.manager&#39; - &#39;@request&#39; - &#39;@user&#39; - &#39;@service_container&#39; - &#39;%core.root_path%&#39; - &#39;%core.php_ext%&#39; tags: - { name: auth.provider }  上面配置里面 arguments 指定的，是 auth_foo.php 的 constructor 接受的参数。可以需要什么配置什么，个数要对应。
配置这个之后，只需要在 auth_foo.php 里面实现具体的逻辑就可以了。
init_method 这个方法是在后台用户选中这个 auth 方法的时候执行的，比如你如果有一些配置的话就可以在这里验证。如果需要用户录入配置的话，还需要配合 template 文件，好提供录入的界面。我这里没有这个需求。
login_method 这个方法是在用户登陆的时候会调用。会传入用户名和密码两个参数。实现逻辑可以参考 auth_db 这个模块。phpbb 为了安全，对于管理员用户会有一个二次验证的过程，管理员的 session 过期时间也会短一些。所以我们必须要实现这个，否则一个管理员就无法访问后台了。我这里是完全复制的 auth_db 的逻辑，里面改动了一点增加了一个硬编码只允许几个我指定的用户登陆。然后验证也完全用的 phpbb 的密码逻辑。</description>
    </item>
    
    <item>
      <title>Fear, trust and JavaScript: When types and functional programming fail</title>
      <link>https://wdicc.com/fear-trust-and-javascript/</link>
      <pubDate>Thu, 01 Nov 2018 12:56:20 +0800</pubDate>
      
      <guid>https://wdicc.com/fear-trust-and-javascript/</guid>
      <description>翻译自 Fear, trust and JavaScript: When types and functional programming fail , 最早是 hacker news 看到的。
只是翻译大意。
作为开发人员，我们需要减少对代码执行失败的恐惧，增强对代码的信心。很多 javascript 开发人员从函数式编程语言和强类型语言里面借鉴思路来将信任交给工具和代码来减少恐惧。类似可选类型，函数转换，和只读化这些思想可以帮助写出更好的 javascript 代码。当把这些想法都加入到 javascript 里面，会有一些妥协，协作起来比较差，并且最终会导致将信任从开发人员交给代码和工具的想法失败。
举例来看看 javascript 里面是如何在两种观点下面处理数据的：理解数据的结构和修改数据。
Fear and the shape of data 在类似 javascript 的动态语言里面，很难知道你数据的结构。默认的方式是依赖公约(convention)。相信其它程序员和其它系统按照协议给你正确的数据。
fetchUser(id).then( user =&amp;gt; { // Got my user! }) // Later render(user.name) // He has a name  我一般管这种方式叫「假装这是你要的」。在高可信的环境下，这个会工作的挺好。
但是恐惧会悄悄的到来。代码的复杂度会增加。代码会是不同开发人员基于不同的公约(convention)开发的。你收到的数据来自于不可控的上游以及不稳定的格式。会开始看到空指针错误。对代码的信任会崩塌，对数据格式的疑问会引起焦虑而不是信任。
 这个数据里面到底有什么值？ 我可以删除里面的数据而不产生影响吗？ 我可以把这个数据传入这个函数吗？  例如下面这个。
fetchUser(id).then( user =&amp;gt; { // Got my user! if(!</description>
    </item>
    
    <item>
      <title>Typescript and Jest</title>
      <link>https://wdicc.com/typescript-and-jest/</link>
      <pubDate>Thu, 01 Nov 2018 11:59:29 +0800</pubDate>
      
      <guid>https://wdicc.com/typescript-and-jest/</guid>
      <description>最近在折腾 typescript，把很多项目改成了 ts 的。有一个老项目，改的过程中感觉各种不踏实，打算还是先写点测试用例，就折腾了一下 jest。各种坑。。。
首先需要加一个 tsconfig.json
{ &amp;quot;compilerOptions&amp;quot;: { &amp;quot;target&amp;quot;: &amp;quot;es2015&amp;quot;, &amp;quot;module&amp;quot;: &amp;quot;es2015&amp;quot;, &amp;quot;lib&amp;quot;: [ &amp;quot;es2015&amp;quot; ], &amp;quot;outDir&amp;quot;: &amp;quot;./lib&amp;quot;, &amp;quot;declaration&amp;quot;: true, &amp;quot;noEmit&amp;quot;: true, &amp;quot;moduleResolution&amp;quot;: &amp;quot;node&amp;quot;, &amp;quot;esModuleInterop&amp;quot;: true, &amp;quot;allowSyntheticDefaultImports&amp;quot;: true, /* Strict Type-checking */ &amp;quot;strict&amp;quot;: true, &amp;quot;strictNullChecks&amp;quot;: true, &amp;quot;noImplicitAny&amp;quot;: true, &amp;quot;noImplicitThis&amp;quot;: true, &amp;quot;alwaysStrict&amp;quot;: true, /* Additional Checks */ &amp;quot;noUnusedLocals&amp;quot;: true, /* Report errors on unused locals. */ &amp;quot;noUnusedParameters&amp;quot;: true, /* Report errors on unused parameters. */ &amp;quot;noImplicitReturns&amp;quot;: true, /* Report error when not all code paths in function return a value.</description>
    </item>
    
    <item>
      <title>Upgrade to React 16.3</title>
      <link>https://wdicc.com/upgrade-to-react-16.3/</link>
      <pubDate>Mon, 22 Oct 2018 16:21:30 +0800</pubDate>
      
      <guid>https://wdicc.com/upgrade-to-react-16.3/</guid>
      <description>随着 React native 升级，React 也升级到了 16.5 了。原来的改成新的生命周期了。
class ExampleComponent extends React.Component { static getDerivedStateFromProps(nextProps, prevState) { // Called after a component is instantiated or before it receives new props. // Return an object to update state in response to prop changes. // Return null to indicate no change to state. } UNSAFE_componentWillMount() { // New name for componentWillMount() // Indicates that this method can be unsafe for async rendering. // Prefer componentDidMount() instead.</description>
    </item>
    
    <item>
      <title>Cleanup Your Disk Space</title>
      <link>https://wdicc.com/cleanup-your-disk-space/</link>
      <pubDate>Fri, 12 Oct 2018 12:26:47 +0800</pubDate>
      
      <guid>https://wdicc.com/cleanup-your-disk-space/</guid>
      <description>200 多 G 的空间，说没就没。搞个开发真不容易。
清理 yarn npm 开发的 cache，这些有需要的会再次下载
yarn cache clean npm cache clean  清理 gradle android 开发的 cache，这些有需要的话 android-studio 会在生成
rm -rf ~/.gradle/  清理 xcode ios 开发的东西，这些清理掉了需要用的话 xcode 会再生成
rm -rf ~/Library/Developer/  清理 brew 安装的软件的旧版本，这个执行之后 python 可能会不正常，执行一下 pyenv rehash 之类的命令
brew cleanup  </description>
    </item>
    
    <item>
      <title>R.I.P Maomao</title>
      <link>https://wdicc.com/r.i.p-maomao/</link>
      <pubDate>Fri, 28 Sep 2018 10:33:30 +0800</pubDate>
      
      <guid>https://wdicc.com/r.i.p-maomao/</guid>
      <description>毛毛应该是 2004 年上半年我从一个人家里抱回来的，到现在 14 岁多一点。从 2013.12.29 发现得了糖尿病，到现在是 4 年多一点，等于是大概 10 岁左右的时候得的。
前面 10 年是无忧无虑欢乐的 10 年，猫基本什么都不用管，只有刚开始第一次长假出去玩的时候，拜托过朋友给中间来看看。后面出去玩基本就把两只猫都扔家里了，给他们弄足够的水和吃的，最长出去玩的时间得有 10 天，回来猫只是会比较粘人，其它基本还好。
自从毛毛病了之后，就和养了一个孩子一样，必须每天早晚 2 针胰岛素。参考上面的文章，通过自己学习，掌握了采血，通过稀释来配胰岛素等。所以开始还需要定期配好稀释好的胰岛素，一次大概配置 20 针左右，放到冰箱，然后每天 2 针，10 天左右就需要重新配置。配药的时候，需要注意量和不能有空气，每次和老婆就像吸毒人员一样，小心翼翼的配好。直到后面加了糖猫猫的群，发现了 bd 针，才开始不在自己稀释配药了。
毛毛病了之后，我们基本就很难出远门了，因为必须要回来打针。所以出去几次远门都拜托朋友、cc 妈妈等过来给定期打针。直到今年，才开始尝试给带着猫回家，去了一趟我们家，一趟 cc 家，整体猫虽然很害怕，不过也还好，没出什么问题。
这次本来打算带着他们去沈阳的，结果没想到毛毛出事了。都是我的问题，我知道猫可以活 10 到 20 年，我曾经无处次想过猫死的时候的情形，没想到昨天就这么来了。昨天一晚没有睡，我早上感觉浑身乏力，以为是饿的，去吃了早点才发现不是这个原因。下定决心给他安乐的是我，我可能太薄情了，看着他抽搐受不了。毛毛病了这几年，我们也还断断续续的去了很多次医院，也有几次病危，但是都挺过来了。
糖尿病猫做无碳水疗法需要喂高蛋白的猫粮，我们家没有条件给妞妞和毛毛分开喂食，只能一起吃。前段时间妞妞身体也不舒服过一次，去医院做 b 超，说是他的有一个肾萎缩的很厉害，建议我们喂老年猫粮，少喂高蛋白的。我也很发愁怎么搞。我和老婆两个北漂，父母多不在这里不能帮忙。
现在只剩妞妞一个了，打算还是带着他去沈阳，还有乌龟一起。要不一只猫在家估计很孤单也会有问题，妞妞是一个特别粘人的猫。妞妞比毛毛大一岁，今年 15 岁多一点，希望能健康活着。
毛毛病了之后，我就发现经过了童年成年到中年，也到了要开始有生离死别的时候了。当你喜爱的人一个一个都离开你的时候，为了什么活着？我和老婆没有孩子，当父母都百年之后我真不知道我会不会去选择提前结束。快乐的前半生即将或者已经过去了，后面怎么面对？
安息吧毛毛，我们爱你。</description>
    </item>
    
    <item>
      <title>Typescript for React Native</title>
      <link>https://wdicc.com/typescript-for-react-native/</link>
      <pubDate>Sun, 16 Sep 2018 16:36:17 +0800</pubDate>
      
      <guid>https://wdicc.com/typescript-for-react-native/</guid>
      <description>前几天研究 settimeout 的问题的时候，发现 react-native-background-timer 自己没有 typescript 的 type 文件，但是有人给写了一个 @types/react-native-background-timer，这个包算偏门了，都有人写了 type 文件，我感觉是时候试试看 typescript 了。
搜了一下，发现没有多少在 rn 里面使用 ts 的，有一些关于 react 的，又很奇怪，大都基于 webpack 的。后来找到一篇官方的 blog 上面的，然后结合自己的研究，找到了思路。我是基于已有项目来做的，那个 blog 是基于新项目，大同小异。
首先装几个包，这几个包里面， =typescript 提供 typescript 的编译器， react-native-typescript-transformer 提供了从 ts 代码到 js 代码的转换支持， @types 的两个包提供了 react 和 react-native 的 type 文件。
$ yarn add -D typescript react-native-typescript-transformer @types/react @types/react-native  在项目的根目录还需要准几个文件。 tsconfig.json，你的目录里面可能已经有一个 jsconfig.json 了，那个是给 eslint 用的。tsconfig.json 同时给 typescript 和 tslint 使用。
{ &amp;quot;compilerOptions&amp;quot;: { &amp;quot;target&amp;quot;: &amp;quot;es2015&amp;quot;, &amp;quot;module&amp;quot;: &amp;quot;es2015&amp;quot;, &amp;quot;lib&amp;quot;: [ &amp;quot;es2015&amp;quot; ], &amp;quot;jsx&amp;quot;: &amp;quot;react&amp;quot;, &amp;quot;noEmit&amp;quot;: true, &amp;quot;moduleResolution&amp;quot;: &amp;quot;node&amp;quot;, &amp;quot;strict&amp;quot;: true, &amp;quot;esModuleInterop&amp;quot;: true, &amp;quot;types&amp;quot;: [ &amp;quot;react&amp;quot;, &amp;quot;react-native&amp;quot; ], &amp;quot;allowSyntheticDefaultImports&amp;quot;: true }, &amp;quot;include&amp;quot;: [ &amp;quot;.</description>
    </item>
    
    <item>
      <title>Background Task in React Native</title>
      <link>https://wdicc.com/background-task-in-react-native/</link>
      <pubDate>Sat, 08 Sep 2018 16:06:18 +0800</pubDate>
      
      <guid>https://wdicc.com/background-task-in-react-native/</guid>
      <description>react-native 支持 setTimeout 和 setInterval 这些 js 的方法来设置 timer 执行一些任务。但是对于长时间执行的任务，比如你想每 1 分钟都执行一下网络请求看看是不是有新的数据，这个时候会有一个黄条警告和你说不要这么做。
我们有类似需求，就找到了 react-native-background-timer 这个包。这个用起来和 js 的 setTimeout 的方法一样，可以一直运行。
我们另外还使用了 websocket 来和服务器保持数据同步。这样就必须要保证有网络问题的时候，可以自动重连保证链接。我们找到了 reconnecting-websocket 这个包，他提供了自动重连功能。这个包是基于 js 写的，没有任何的 native 代码。我们用的过程中发现时不时会出现断开的情况，因为并不能稳定复现，我们一开始也没有太多时间研究这个问题，所以这个 bug 几乎是持续了几个月。另外，也主要是因为我们还有 pc 设备，也用了 websocket，但是那边表现就很稳定，所以基本可以确定是 android 的问题。
我们试过自己手动断网，和手动重启服务器的方式断开 websocket，然后发现他都会重连。出现 bug 的时候，都是比如放了一个晚上，第二天来了之后，发现断开了。或者有时候似乎又不会断，总之是不很好的稳定可以复现。
一开始怀疑是 android 进入省电模式之后，应用会出问题，把设备一直接着电源之后，似乎发现好像好了，但是实际上还是会出现断开的情况。后来给 app 增加了 REQUEST_IGNORE_BATTERY_OPTIMIZATIONS 权限，试图解决，发现也不行。
最近一个月总算有时间看看了，仔细研究了一下。给 app 增加了更多的 log，记录一下 websocket 的链接和断开的情况。发现一个情况，似乎整整 24h 的时候，会出现一个断开。断开之后有时候会连不上，有时候可以。因为是整整 24h，所以这个断开基本上可以肯定是 server 那边问题，但是断开不能重连依然是用户端这边的问题。
后来我们找到了 24h 断开的原因，我们 websocket server 用的是 channel redis，里面默认是 24h 会断开。这个案子破了，定期倒是没问题，现在就是为啥不会重连的问题了。
def __init__( self, hosts=None, prefix=&amp;quot;asgi:&amp;quot;, expiry=60, group_expiry=86400, capacity=100, channel_capacity=None, symmetric_encryption_keys=None, ):  通过分析 websocket 的日志，发现断开之后，执行重连的时候，reconnect-websocket 避免过度重连，会增加一个延时，调用 this.</description>
    </item>
    
    <item>
      <title>React Native Deeplink</title>
      <link>https://wdicc.com/react-native-deeplink/</link>
      <pubDate>Mon, 03 Sep 2018 18:00:56 +0800</pubDate>
      
      <guid>https://wdicc.com/react-native-deeplink/</guid>
      <description>App 一般都支持类似 coolflight://list 这样的链接，可以直接打开 app 并打开列表，这个就是 deeplink。
这个需要对 native 代码做一些修改，可以参考这里的修改，ios 和 android 都有写。这里有一个需要注意的是，对于 android 有一个配置是
 &amp;lt;data android:scheme=&amp;quot;mychat&amp;quot; android:host=&amp;quot;mychat&amp;quot; /&amp;gt;  这个里面配置 host 的话，后面使用的时候就需要类似 mychat://mychat/list 这样的方式了，就是多了一层 mychat。这样也会导致 ios 和 android 的链接不统一，我查了文档也没有查到没有设置 host 会有什么问题，我就去掉了，去掉之后，ios 和 android 的链接就统一了。都是 mychat://list
另外 android 还有一个需要注意的地方是，activity 的 launchmod 需要设置为 singleTask 要不会导致每次通过 deeplink 打开 app 都会新建一个，导致你有多个 js 在后台跑。
&amp;lt;activity android:name=&amp;quot;.MainActivity&amp;quot; android:launchMode=&amp;quot;singleTask&amp;quot;&amp;gt;  在 js 里面可以使用 Linking.openURL(url).catch(err =&amp;gt; console.error(&#39;An error occurred&#39;, err)) 打开一个 deeplink ，可以是别的 app 的，也可以是自己的。
然后就是在 js 里面处理对应的 deeplink 了。</description>
    </item>
    
    <item>
      <title>React Mobx</title>
      <link>https://wdicc.com/react-mobx/</link>
      <pubDate>Sun, 02 Sep 2018 19:18:16 +0800</pubDate>
      
      <guid>https://wdicc.com/react-mobx/</guid>
      <description>我们之前用的是 redux 来做的统一 store，最近一个新项目有同学用了 mobx，就了解了一下，刚开始看的时候，感觉比 redux 好啊？
mobx 的逻辑是自动收集 store 属性被哪些 dom 使用，然后在属性被改变的时候，自动更新 dom。这样的模式显然比 redux 的 action，reducer，selector 那一套简单多了。
给对应的组件加上 @observer 装饰器之后，store 改变就会自动重现渲染组件。store 可以用下面的模式给到组件
const store = new TodoList(); &amp;lt;TodoListView todoList={store} /&amp;gt;  也可以用 @inject 装饰器
@inject(store =&amp;gt; store) @observer class TodoListView { }  之后都通过 this.props 引用。
一切都很美好，直到我看到了这个，这里列了一些 mobx 的坑。比如有讲到，mobx 为了能监控到对 store 的依赖和修改，其实是把 store 属性做了修改，所以 store 有一个属性是一个 Map，那么实际得到的是一个和 ES6 Map api 类似的一个对象，但是并不是原生的 Map。比如有一个属性是 Object，你给加了一个 key，例如 store.object[&#39;a&#39;] = &#39;test&#39;，那么这个修改并不能被监视，具体看那个文档吧。
写 Javascript 基本就是从一个小坑爬出来掉到一个大坑里面。</description>
    </item>
    
    <item>
      <title>Android Custom</title>
      <link>https://wdicc.com/android-custom/</link>
      <pubDate>Sun, 02 Sep 2018 08:00:16 +0800</pubDate>
      
      <guid>https://wdicc.com/android-custom/</guid>
      <description>我们给用户的设备，有 android pad 和 pc。pc 系统我之前基于 porteus 定制了一个，勉强可以用。apad 的系统一直没搞好。
Android 系统必须要解锁之后才可以定制系统，否则没有 root 权限，system 分区的数据不能修改。
 Android 系统有四个重要的分区。 boot ，和 linux 的类似，里面有 kernel 和 ramdisk，ramdisk 应该是在启动之后会成为 / 分区 recovery ，恢复分区，如果想对系统分区做什么操作，可以使用这里的程序引导系统，这个时候允许你进行一些操作。默认的 recovery 只能 wipe 和刷系统。自定义的 recovery 比较厉害，可以支持备份啊啥的一堆事情，比如 twrp 还有图形界面。 system ，系统分区，系统程序都在这里，包括系统自带的一些 app 等等。正常情况对这个分区是不能修改的，系统分区都是只读的。 data ，数据分区，这个分区是给用户使用的。用户安装的一下 app 以及一些数据都在这里。wipe 的时候就是会清空这个分区的数据。大家熟悉的 sdcard 那个分区，其实数据也是在这里的。data 分区里面 app 只能读取自己的数据，无法访问别的 app 的。但是放在 /sdcard 分区的数据，大家都可以访问（当然，还得有 sdcard 的权限）  前三个分区都可以定制。首先需要解锁 bootloader，这个各个定制版都可能有区别，比如华为我记得还需要去他们网站获取一个解锁码，获取的时候会提示你解锁之后就不给保了。原生的 android 都是去开发者选项里面打开，然后在启动的时候进 bootloader，执行 fastboot oem unlock-go 。解锁的时候会自动 reset 系统，注意先备份数据。
解锁之后，就可以刷自己的 recovery 了。刷之前建议先备份一下 boot recovery system 分区，以方便自己回头可以刷回来。我用的是 twrp，其它的好像现在也么看到。这个得找和你的手机匹配的才行。具体方法是执行 fastboot boot twrpxxxxx.</description>
    </item>
    
    <item>
      <title>Boot Linux Through PXE</title>
      <link>https://wdicc.com/boot-linux-through-pxe/</link>
      <pubDate>Mon, 02 Jul 2018 16:47:31 +0800</pubDate>
      
      <guid>https://wdicc.com/boot-linux-through-pxe/</guid>
      <description>测试 porteus 的时候，每次都是做好 iso 之后写到一个 u 盘，然后用 u 盘启动看看效果，发现有点蛋疼，这浪费时间不说，我的 u 盘寿命估计也得少一截。就研究了一下 pxe 启动，这样每次改完之后通过 pxe 直接读取我改了之后的 iso 引导 linux 就好了。
我这看 pxe 启动主要需要做两个事情，一个是 dhcp 的时候广播 tftp 的信息，一个是通过 nfs 共享给那个系统需要读取的文件。nfs 共享也可以改用 http 等其他服务。
dnsmasq 广播 tftp 的信息，可以通过 dnsmasq 来做。dhcp 部分就不贴了，只贴 tftp 相关的。
tftp-root=/srv/pxe/boot dhcp-boot=/pxelinux.0 enable-tftp  网卡启动的时候会获取 /pxelinux.0 然后获取 /pxelinux.cfg/default （这个实际上有一个判断顺序，方便给不同的机器不同的配置）。然后根据这里面的配置，获取内核信息。然后加载内核。
nfs 加载内核之后还需要系统文件，这个时候貌似有几个选择，比如通过 http 发送。我这用的是 nfs。想要通过 nfs 发送，内核得能支持 nfs mount。各 linux 的做法貌似不太一样。
配置 nfs 的目录，在 /etc/exports 里面加入类似这样的信息。
/srv/pxe/porteus *(ro,fsid=0,no_subtree_check) /srv/pxe/storage *(rw,fsid=1,no_root_squash,no_subtree_check)  然后 exportfs -rv ，这样 nfs 设置好了。</description>
    </item>
    
    <item>
      <title>Install Porteus to HD</title>
      <link>https://wdicc.com/install-porteus-to-hd/</link>
      <pubDate>Mon, 02 Jul 2018 16:23:54 +0800</pubDate>
      
      <guid>https://wdicc.com/install-porteus-to-hd/</guid>
      <description>Porteus 是一个很好玩的系统，他基于 aufs 弄出来的一个「只读」系统，说是只读，实际上他也可以把修改保存到一个硬盘目录，然后启动的时候自动加载这些修改，这样就修改都还在。但是如果把这个目录删除，那么修改就都没有了，这就是所谓的只读。
我开始的需求是需要搞一个 linux，然后给用户使用，并且希望用户只能用浏览器，不能使用其他东西，因为我们提供的服务就是一个网页。不能使用其他东西是为了避免使用的时候导致系统奔溃什么的，还得派人花时间去维护。然后看到有人推荐 Kiosk，看了一下感觉这个东西太完美了，就是我想要的东西。然后就开始研究这个系统。研究的过程中发现了他是基于 Porteus 的，就开始看 porteus。
Kiosk 确实也不错，但是我使用的时候想要定制支持中文输入法，打印机等设备，然后发现他阉割加定制的太多了，导致我看了几天居然还没有找到他的入口在哪里，尝试想搞定输入法，费了很多劲。kiosk 使用的是 openbox + tint2 ，后面看了 porteus 之后，他支持 mate，kde 这些桌面，并且也直接就支持 scim，所以打算还是基于这个定制比较简单一点。
具体定制就不多说了，主要是定制好 iso 之后，怎么安装到硬盘。
其实也相当简单，只需要把 u 盘上面的内容复制到一个硬盘分区，然后安装一个 bootloader 就可以了。
安装 bootloader 的时候由于对这个东西不是特别熟悉，以及这么多年不搞 linux 之后又出来很多新的概念，所以走了一些弯路，一番学习之后，发现简单的很。可以参考这里。
然后就是需要弄一个 grub.cfg 就可以了。
set timeout=1 set superusers=root password_pbkdf2 root grub.pbkdf2.sha512.10000.xxxxxxxx password guest guest if [ x&amp;quot;$default&amp;quot; = xsaved ];then load_env; set default=&amp;quot;$saved_entry&amp;quot;; fi insmod vbe insmod efi_gop insmod efi_uga insmod font insmod part_gpt search --label --no-floppy --set kgzx KGZX set prefix=($kgzx)/boot/grub if loadfont $prefix/fonts/unicode.</description>
    </item>
    
    <item>
      <title>Compile Kernel Module</title>
      <link>https://wdicc.com/compile-kernel-module/</link>
      <pubDate>Mon, 02 Jul 2018 16:13:56 +0800</pubDate>
      
      <guid>https://wdicc.com/compile-kernel-module/</guid>
      <description>使用 porteus 的时候，发现网卡不支持，找了一下发现有内核驱动可以用，那就需要编译一下内核的模块。
这里有一个帖子写了如何编译内核，主要步骤是先给内核打 aufs 的补丁，然后就是正常的 make config &amp;&amp; make &amp;&amp; make modules_install 了。
我这只是编译一个网卡驱动，操作步骤大概如下，把内核解压放到 /mnt/sda1/kernel 下面，然后把网卡驱动代码放到 /mnt/sda1/kernel/linux-4.16.3/drivers/net/wireless/rtl8821ce 下面。
# cd /mnt/sda1/kernel/linux-4.16.3/ # modprobe configs &amp;amp;&amp;amp; zcat /proc/config.gz &amp;gt; .config # make oldconfig # make prepare # make modules_prepare # export srctree=/mnt/sda1/kernel/linux-4.16.3 # ln -s /mnt/sda1/kernel/linux-4.16.3 /usr/src/linux # cd drivers/net/wireless/rtl8821ce # make  然后在这个目录下面会产生一个 rtl8821ce.ko 的文件。
如果是遇到自己用的内核有一个模块没编译，那可以用下面的方式
# after make modules_prepare # make modules SUBDIRS=drivers/firmware/efi/  这样会在 drivers/firmware/efi/ 目录下面产生一个 xx.ko 之类的文件。</description>
    </item>
    
    <item>
      <title>Geodesy</title>
      <link>https://wdicc.com/geodesy/</link>
      <pubDate>Sun, 01 Jul 2018 08:10:05 +0800</pubDate>
      
      <guid>https://wdicc.com/geodesy/</guid>
      <description>坐标点之间的距离角度计算不能简单的用平面几何来算，得按照球面计算，PostgreSQL 提供了 gis 数据的计算支持，各种图形关系判断，距离计算等等。但是我们有时候也需要在 js 里面计算，开始的时候尝试自己按照公式写来着，写了一些发现太蛋疼了，因为只是单纯的看公式，缺少空间概念，算的对不对啥的都不知道。后来发现了这个 js 库，简直太贴心了。
 提供了我用过的几个功能 度数表示转换，小数点形式到度分秒形式的互转。在 utm.js 里面。 计算线的真北角。point1.bearingTo(point2)，真北角计算是和线的方向有关系的。 和当前点夹角是 x，距离是 y 的点，point1.destinationPoint(y, x)。 两点之间的距离，point1.distanceTo(point2)  然后顺便记录一些东西。
// 两条线的夹角的一半，普通角度 let angle = (360 + 180 + bearing1 - bearing2) % 360 // 360 保证只有正的 let halfAngle = angle &amp;gt; 180 ? (360 - angle)/2 : angle/2 // 只要锐角 // 计算两条线夹角中线的真北角 // left,right bearing 需要是真北角 let rightBearing = 90 + (bearing1 + bearing2)/2 let leftBearing = 180 + rightBearing // Math.</description>
    </item>
    
    <item>
      <title>UEFI Bootable Usb</title>
      <link>https://wdicc.com/uefi-bootable-usb/</link>
      <pubDate>Sat, 30 Jun 2018 07:30:58 +0800</pubDate>
      
      <guid>https://wdicc.com/uefi-bootable-usb/</guid>
      <description>UEFI shell UEFI firmware 应该会读取设备里面的分区，找到 ESP 然后再读里面的内容。我看到最简单的方式是把 u 盘格式化成 fat 然后建一个目录 /boot/efi 然后下载一个 uefi shell 把 .efi 文件放到这个目录 /boot/efi/shellx64.efi ，然后启动的时候就多了一个 uefi 菜单了，选择之后可以进入一个 uefi shell。
uefi shell 里面有几个命令可以用。
map map 可以列出来当前机器的磁盘情况，找到你的 esp 分区。
ls ls 可以列出来磁盘目录里面的内容，比如 ls fs0:\boot ，注意磁盘和目录之间用 : ，目录层级之间用 \ 。
bcfg 可以通过 bcfg boot dump -v 列出来当前所有的 efi 菜单，注意每个项目都有一个序号，后面会用到。
比如我想自己加一个菜单进去，那就找到最后那个的序号，然后执行 bcfg add 8 fs0:\boot\grub\grubx64.efi GRUB (fat 系统不区分大小写)，指向我自己通过 grub-install --efi-directory=/mnt/sda1/ 放到 esp 分区的 grub 的 efi ，这样启动的时候就多了一个 GRUB 的选项，通过这个选项就可以进入 linux，然后使用更方便的 efibootmgr 来编辑这个菜单了。</description>
    </item>
    
    <item>
      <title>Grub2 and UEFI</title>
      <link>https://wdicc.com/grub2-and-uefi/</link>
      <pubDate>Fri, 29 Jun 2018 20:03:54 +0800</pubDate>
      
      <guid>https://wdicc.com/grub2-and-uefi/</guid>
      <description>这几天搞 Linux 又学习了一些新的东西。
以前都是把 grub 装到 MBR，然后通过 grub 可以 chainloader 启动 windows。现在发现我装了之后并不能启动我的 windows 10 了，就只好研究了一下。
GPT 分区 以前都是 MBR(Master Boot Record) 形式的分区，主分区 4 个，如果想要建更多，需要建扩展分区，然后再在扩展分区里面建立逻辑分区。现在发现有了 GPT(GUID Partition Table) 分区。这个方式呢，比 MBR 方式有好处，支持更多分区，支持大于 2.2TB 容量的磁盘。
我看我的 windows 10 机器预装就是用的这个分区格式。
UEFI 系统 UEFI(Unified Extensible Firmware Interface) 是基于 BIOS 的 MBR 启动方式不同的东西，是基于单独的 EFI System Partition(ESP) 里面的数据启动的。里面的程序都需要和 UEFI firmware 的 bitness 一致，x86_64 啥的。
所以我的 windows 10 在 ESP 分区里面已经放了一个自己的起动器。Linux 启动之后，可以查看 /sys/firmware/efi 看看是不是有，有的话表示 kernel 支持 efi，且和 firmware 的 bitness 一致。</description>
    </item>
    
  </channel>
</rss>