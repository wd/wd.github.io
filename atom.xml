<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>wd and cc</title>
    <link>https://wdicc.com/</link>
    <description>Recent content on wd and cc</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Mon, 24 Jul 2017 20:02:00 +0800</lastBuildDate>
    
	<atom:link href="https://wdicc.com/atom.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>emacs as react native ide</title>
      <link>https://wdicc.com/emacs-as-react-native-ide/</link>
      <pubDate>Mon, 24 Jul 2017 20:02:00 +0800</pubDate>
      
      <guid>https://wdicc.com/emacs-as-react-native-ide/</guid>
      <description>最近又在写 react-native 了，对自己的环境又作了一番配置。记录一下。
web-mode 我主要用的 mode 是 web-mode。这个 mode 简直万能，能处理 html，jsx，js 等。具体配置如下。
(use-package web-mode :ensure t :config (add-to-list &#39;auto-mode-alist &#39;(&amp;quot;\\.html\\&#39;&amp;quot; . web-mode)) (add-to-list &#39;auto-mode-alist &#39;(&amp;quot;\\.js\\&#39;&amp;quot; . web-mode)) (add-to-list &#39;auto-mode-alist &#39;(&amp;quot;\\.ejs\\&#39;&amp;quot; . web-mode)) (setq web-mode-markup-indent-offset 4) (setq web-mode-css-indent-offset 4) (setq web-mode-code-indent-offset 4) (setq web-mode-content-types-alist &#39;((&amp;quot;jsx&amp;quot; . &amp;quot;.*\\.js\\&#39;&amp;quot;)) ) )  主要是那个 web-mode-content-types-alist 的配置，让 web-mode 处理 js 文件的时候，把 &amp;lt;&amp;gt; 代码段识别成 jsx。这样能把缩进处理好。
我还试过 rjsx-mode，这个用起来也可以，基于 js2-mdoe，js2-mode 有的一些用法都支持，并且 flycheck 都不用做多余的配置。但是主要问题是，jsx 的代码缩进有问题。
flycheck (use-package flycheck :ensure t :config (global-flycheck-mode t) (flycheck-add-mode &#39;javascript-eslint &#39;web-mode) )  把 web-mode 的 checker 设置为 javascript-eslint，如果你用别的就设置成对应的。配合用的 .</description>
    </item>
    
    <item>
      <title>Django middleware</title>
      <link>https://wdicc.com/django-middleware/</link>
      <pubDate>Wed, 05 Jul 2017 18:07:50 +0800</pubDate>
      
      <guid>https://wdicc.com/django-middleware/</guid>
      <description>Django 提供了 middleware 来让你 hack Request 和 Response。用的时候有几个问题需要注意一下。
__call__ 方法 __call__ 方法实际上就是最早收到 request 的地方，如果不关心 view，那么就可以在这里做你想要做的事情。比如认证用户啥的。这个实际上应该就是早期的 process_request 。
process_view 方法 process_view 方法会接收到 view_func 和其参数，如果想要针对这些东西处理，可以在这里动作。比如我们所有 api 请求的 POST 的 body 里面都是固定格式的 json 数据，我就在这里检查了 json 的格式，并把解析结果给到了 view_func。
如果不打算对 view_func 做什么事情，那就最好做完想做的事情，直接返回 None 就可以。否则处理完毕之后，返回一个 response 对象。
要注意的是，这里最好不要产生 exception，产生了会把逻辑跑到 Middleware 的 exception 逻辑里面。所以最好对自己的代码段加上 try-except 逻辑。
另外，这里可以对 view_func 做调用，直接返回 view_func 的结果或者处理之后的结果，只要保证是个 response 对象就可以了。也可以不做调用，返回 None ，后续 django 也会调用。要注意的是，如果你对 view_func 做了调用，那么在捕捉到错误的时候，except 里面应该也需要返回一个 response 对象，不能返回 None 了，否则 djangon 还会再次调用这个 view_func 。</description>
    </item>
    
    <item>
      <title>Emacs as python IDE</title>
      <link>https://wdicc.com/emacs-as-python-ide/</link>
      <pubDate>Fri, 30 Jun 2017 20:47:56 +0800</pubDate>
      
      <guid>https://wdicc.com/emacs-as-python-ide/</guid>
      <description>最近 python 写的比较多，比较了几个编辑器，最后还是留下了 emacs。
主要比较了 emacs 和 pycharm。pycharm 绝对是一个很强的 IDE，几乎可以补全任何东西，写代码各种提示。比如 Django 里面定义一个 model User 之后，就可以 User. 之后提示 objects ，这个是依据 metaclass 来补全的。另外还有比如写 User.objects.get(|) 的时候，光标在竖线那个位置，会提示 User 的字段，这个相当好用。这两个只是皮毛，实在是太好用了。
但是为什么还要用 emacs 呢？emacs 的编辑器功能太好用了。比如 &amp;lt; 到页首， &amp;gt; 到页尾， C-x b 切换 buffer，还有切换 frame，等等快捷键非常舒服，完全不用鼠标。不过也可能是我习惯了 emacs 的快捷键了。在 pycharm 里面时不时就不行，比如选择一段文字，纯键盘需要按 -&amp;gt; 配合才可以，那还不如用鼠标算了。
其实如果一上手就用 pycharm，那绝对会觉得很爽。
emacs 写 python 在原生的 python-mode 基础上有两个好用的选择，一个是 anaconda-mode，一个是 elpy。 anaconda-mode 相对来说比较简陋一点，但是补全什么的没问题，缺少重构功能。两个的工作模式都是会启动一个补全用的进程，然后通过 lisp 和这个进程交互获取补全信息。
anaconda-mode 遇到的问题和解决 anaconda-mode 我遇到一个问题，为了下载 emacs 的 package 方便，我设置了代理，这个代理导致 anaconda-mode 和补全进程交互的时候，连接不能断开，就会不停的新建连接，一会就打开文件数满了，可以参观这个 issue。主要是设置了 no_proxy 解决。</description>
    </item>
    
    <item>
      <title>Run ssserver on VPS</title>
      <link>https://wdicc.com/run-ssserver-on-vps/</link>
      <pubDate>Fri, 09 Jun 2017 10:55:44 +0800</pubDate>
      
      <guid>https://wdicc.com/run-ssserver-on-vps/</guid>
      <description>VPS 上面好早以前用过 docker 跑了一个 container 运行了一个 ssserver, 是从 debian 基本系统创建, 然后手动安装各种软件弄好的. 最近朋友升级了 docker, 那个工作有点问题了,就重新搞了一下, 发现现在好方便.
我用的是这里提供的 dockerfile https://github.com/EasyPi/docker-shadowsocks-libev, 他的例子里面使用了 docker-compose 来创建, 发现很简单, 不过遇到了一个问题, 说一下解决办法.
这个 docker 本地监听的端口是固定的 8388 不能修改, 例如 docker-compose.yml 里面
 server: image: easypi/shadowsocks-libev container_name: wd-ss ports: - &amp;quot;HOST_PORT:8388/tcp&amp;quot; - &amp;quot;HOST_PORT:8388/udp&amp;quot; environment: - METHOD=aes-256-cfb - PASSWORD=5ouMnqPyzseL restart: always  需要配置的是 HOST_PORT METHOD PASSWORD 这三个变量, 然后我还指定了 container_name 方便以后的操作, 不指定会自动产生一个.
启动服务之后,可以使用 docker logs wd-ss 来看 log, 类似于下面, 这个 docker 启用了 udp relay 和 tcp fast open, 差不多也就够了.</description>
    </item>
    
    <item>
      <title>Meetings and meetings</title>
      <link>https://wdicc.com/meetings-and-meetings/</link>
      <pubDate>Sat, 08 Apr 2017 15:16:49 +0800</pubDate>
      
      <guid>https://wdicc.com/meetings-and-meetings/</guid>
      <description>前几天海龙 在 twitter 的提了一个问题“这个世界上有喜欢开会的人吗？能和我说说理由吗？”。作为开了很多会的人，由不住想说两句。
 首先，高质量的会应该具备什么呢？我也没看过《罗伯特议事规则》这样的书（放在 kindle 里面好久了一直没看过，汗颜。。），就是自己按照自己参与的情况总结下： 会议前必要的沟通，好确认是不是需要你参加。当然也有一定可能性组织会议的人确认需要你参加而不做沟通（当然也不排除判断错误的时候 QAQ）。 组织会议的人做好前期调研，会议讨论的一些相关方案的基本情况应该需要比较了解。避免好容易召集齐人之后，发现要讨论的内容本身自己互相矛盾，或者需要参会的人没有通知等情况。 邮件通知与会人会议要沟通的内容，和希望达成的目标，让大家提前了解事情的原委。也给大家一个机会提前确认下是不是真的和自己有关系。 有了希望达成的目标，就应该会比较明确具体需要谁参与，比如想要一个明确的决定的时候，却约一个不能拍板的人来，这会议注定不能成功。 会议中有可以控制会议节奏的人主持。能适时的阻止一些无关话题，扯皮，控制会议节奏，避免开大长会和会上吵架。 会议中有人记录会议记录，结束后有人会把会议记录和结论(这个很重要，没有结论的会就是没必要开的会)发给所有人。  下面列几个我作为技术人员常见的一些烂会。
产品总监派一个刚入职几天业务都没摸清的人召集一帮干了好几年的工程师开会。这种情况下，产品经理大概率会被工程师各种怼，因为他不可能真的熟悉产品，工程师提到的很多可能的问题都不太可能圆满回答，最后会发现要讨论的问题各种依赖性，A 功能不确定的情况下，B 功能可能直接就不存在而没必要讨论了。最后会导致会议非常低效。这个时候所有人都会不爽，技术工程师会认为浪费他的时间，产品经理会认为这些人好难配合。其实锅应该是在产品总监头上。
跨部门的会议。很多时候莫名其妙就招呼你去开会，到了之后也不知道是讨论什么的，最后听半天发现貌似和自己一毛钱关系都没有，浪费几个小时。当然浪费的是你的时间，组织会议的人其实是有收获的，他明白这事情和你无关。
头脑风暴会议当作需求讨论会来开。有时候对方可能根本没有明确的想法，你当成最终需求讨论半天指出来其中各种问题，最后发现其实他们根本就确定怎么做呢。这种情况其实就是那个网传的“产品经理找你聊一天，他的需求有了，你的程序还没写”的情况。毕竟需求会的优先级会比头脑风暴要稍微高一点。
如果作为组织者，就是尽量做到前面提到的好的会议应该具备的条件，避免浪费别人时间。作为参与者，如果有能力，遇到有问题的会议，应该想办法协助会议组织者把会议变高效，提高效率的同时，自己也会节省不必要的时间，我经常这么干，毕竟年轻人不容易。。。。当然，我有时候不一定那么有耐心，遇到垃圾会有时候直接就走了，留他们继续浪费时间。
再回到海龙的问题，我的回答是有些人为了合理的浪费时间，是会喜欢开会的，因为这样会让别人觉得他的时间安排很充实，因为整天不在座位，在忙。不知道各位开会的时候有没有遇到一些人全部时间都是在刷手机，只是偶尔说一两句话？这些人就是我说的这种人。我如果遇到我没兴趣的会或者和我无关的会议，我会直接和组织的人申请离开，如果确实后面和我有关系，那麻烦到了时间点叫我（当然你也得保证下到时可以随叫随到，避免浪费其他参会人的时间等你），当然，呃…… 如果我碰巧也想合理的浪费一下时间。。。。
这些人一般都需要是 leader，至少有人在给他创造 GDP 的，否则一个手头很多工作要干的人，你让他开这种无意义的会他自己也不答应，否则其他工作完不成无法交代的。不过某种意义上讲，这些人也是有贡献的，至少能组织一些人贡献 GDP 就是贡献。
感觉跨职业跨部门的会比较容易产生垃圾会，因为看问题角度不一样，有时候会比较难互相理解。我们技术人员很多时候开会，都是找一块白板，画几个图，大家就都明白了，很快就能出决议，不能定的一般可能是需要 leader 拍板的。
同一个部门的会大家会接触比较多比较容易妥协，能接受自己多花点时间或者吃点小亏来完成一个事情。这其实也是所谓的拓展，团队活动，年会想要达到的目的，如果大家都很熟悉的情况下，就比较容易站在对方的角度想问题，遇到事情容易妥协。
上面提到的这些问题其实越大的公司问题越多，反而小公司比较少，因为头绪少，并且大家都比较熟悉的缘故。当然实在遇到一个比较弱的会议组织者，烂会也不可避免。</description>
    </item>
    
    <item>
      <title>Something about cruise tour</title>
      <link>https://wdicc.com/something-about-cruise-tour/</link>
      <pubDate>Mon, 20 Mar 2017 20:41:10 +0800</pubDate>
      
      <guid>https://wdicc.com/something-about-cruise-tour/</guid>
      <description>之前知道邮轮游一直没有体验过，据说是在上面各种滚来滚去看书，因为手机没有信号，没有网络。前几天体验了一把，总结一下。
一句话总结 这上面有你讨厌的所有因素，大妈，广场舞，广场卡拉 ok，小孩子，无序，占座，插队，甚至最后一天还目睹了两起吵架。
邮轮游玩什么 我参加的是歌诗达幸运号（Costa Fortun），邮轮上面估计 80% 都是各种大爷大妈，带着女儿外孙。你可以想象一下，平时最不喜欢的组合在这里最全了。
邮轮上面有免费的自助餐和一些特别的餐食，比如批萨，面条，猪排什么的。也有收费的餐食，当然你可以不去。酒和软饮都是收费的，开饭的时候有免费的白水给你喝，屋子里面是没有的。
邮轮上面一般有大量的娱乐设施，比如赌场，游戏机，泳池，桑拿，剧场等。还定期有各种娱乐活动，比如猜个字啊，跳个舞什么的。所以第一次去还是可以看个新鲜的，尤其可能还有一些漂亮的陪玩 mm，看着也还可以。游戏机赌场是收费的，恩。
此外剧场每天基本都会有一场大型的演出，30-40 分钟，可以让你打发时间。但是剧场虽然每天演出内容不一样，但是演员总是那一波，看多了其实也会腻味。
房间里面也有电视，不过我观察电视都是反复重播录下来的一些电视，然后有一个电影台还是只有那么几部反复重复播放，《x man 天启》我看了不下 10 遍。
小孩也有人给带着玩游戏，有专门的儿童俱乐部。还有健身房，健身房是我唯一对这次邮轮活动满意的地方，当然肯定不是对环境满意，毕竟里面充满了大爷大妈，满意的地方主要是在设备，设备真心不错。浴室和换衣间地板异常干净，比起我家楼下的奥力，简直天上地下。
邮轮一般有那么1，2天是下船，我们这次的安排很屎，景点很无聊，低接导游也只是对购物有兴趣，购物店虽然不贵，但是东西比较少，挺没意思的。
让人反感的几个瞬间 排队上邮轮的时候，过安检的时候就一条队排的特别粗，到了最后那变细互相挤着往前走。我们后面有个阿姨就各种急着往你前面走，我老婆发现之后就故意挤着不让，我看的笑死，呵呵。
第一天必须做逃生演习。有个大爷一家推着小车带着孩子，孩子可能没一会睡着了。而演习是需要所有人参加的，所以就不得不等比较慢的人。大爷就生气了，开始呵斥工作人员，「孩子都睡着了，啥时候开始」之类的，声音巨大。工作人员大都是外籍，估计也吓了一跳。最后结束的时候，大爷还过去指着那个工作人员不知道说了什么。
剧院演出，基本前三四排上面都是东西占座的。除非你提前半个小时到。另外就是各种小孩大声说话也没人管。有时候酒吧做游戏，工作人员都明确说了游戏可能比较激烈，让大家把小孩弄走，但是看着一个女的抱着小孩几次被劝离之后还是要上去玩，貌似还是上去让小孩参与。
昨天有个游戏，几个被淘汰的大妈，悄悄的跑回去继续参与，也有跑回去被发现之后赶走，再次跑回去的，当着一百来号人目睹就那么做，真的无语。
今天下船之前大家集中在一个地方等着，有个姥爷带着孙女玩气球。有个哥们玩心重，带了个面具就冲那小孩过去了，小孩吓的赶紧跑到了姥爷后面，那个哥们就走了。过了半分钟小孩反映过来开始哭，那姥爷就开始不爽了。后来他们全家，追着那小伙骂，最后把面具也抢过来了，还要护照说要以后有啥毛病要找他。纠缠了能有10分钟。
这只是记得起来的几个，反正年轻人真的不建议去邮轮了。如果是自己父母，倒是可以推荐去，他们应该喜欢。</description>
    </item>
    
    <item>
      <title>My way to keep fit</title>
      <link>https://wdicc.com/my-way-to-keep-fit/</link>
      <pubDate>Mon, 13 Mar 2017 15:19:30 +0800</pubDate>
      
      <guid>https://wdicc.com/my-way-to-keep-fit/</guid>
      <description>目前第一阶段减肥基本告一段落，后面目标是保持目前体重 6 个月。
先聊聊结果 2014 年 9 月份前，我的体重最高到 98kg，甚至有时候超过了 100kg。第一阶段减肥可能截止到 2016 年中，减到体重大概是 92kg。第二阶段开始于 2016 年 2 月底，截止到今天体重 80kg。整体算下来减掉 40 斤。
第一阶段 2014 年开始我发现一种比较简单的减肥方法，就是不吃或者少吃晚饭。
这个方法应该不一定对所有人适用。我估计应该只对 BMI(Body Mass Index, 身体质量指数，注意和体脂率不是一个东西)比较高的人有用吧。
我当时 BMI 是 98/1.77^2=31.28 是属于比较高的，坚持了上面的方法半年之后，大概最瘦的时候是 28，我查了是刚好脱离了肥胖那一档，进入了过重。
我当时所在的公司的上班时间是 10:00 - 19:00，但是经常出现 20:00 以后才从公司走的情况，这样我到家经常是 21:30 或者 22:00 以后。这个时候吃晚饭就太晚了，基本吃饭完了就睡觉了。并且，中午吃饭到这个时候，一般其实已经饿过劲了，那个时间反而没有那么饿了，我就慢慢开始晚上到家之后只吃几个水果。后来慢慢转为不吃东西，或者只吃很少的水果。有时候也会遇到快下班的时候非常饿，这个时候吃点小零食，也就可以了。这种方式减肥，早上和中午基本不控制自己，还是吃的比较好的。
上面说了，这个阶段减掉了大概 10 多斤。中午饮食基本不控制，晚上不吃，或者很少吃（一个月有那么一两次推不开的）。
第二阶段 大概是从今年 2 月底从日本回来，开始实施，方法是锻炼加节食。
锻炼的内容是 60 分钟椭圆机（我用的机器难度是 5，不同机器可能不一样），30 分钟运动后拉伸，30 分钟游泳。大概是每周 1，2，4，5 去，一周会休息三天。锻炼毕竟比较枯燥，所以需要中间休息一下调剂一下心情，如果你的体力耐力跟的上，可以不休息。
上面的强度下来，进度大概是一周 3kg。我的情况 3 月 25 是 88.6kg，5 月 2 是 81.7kg，5.5 是 80kg。为什么比较慢呢？在这两个月内，我参加了一趟邮轮游大概一周，去了一趟沈阳，大概一周，还去了一趟日本大概一周。所以如果坚持应该可以更快，但是快速减重我感觉应该可能会有副作用，所以我也基本也是控制减一点，保持几天这样子，不让这个减重太快。另外，这段时间我是全职减肥，所以没有工作上面的压力，可能速度相对快一点。</description>
    </item>
    
    <item>
      <title>Use org mode to publish blog</title>
      <link>https://wdicc.com/use-org-mode-to-publish-blog/</link>
      <pubDate>Sun, 12 Mar 2017 08:59:19 +0800</pubDate>
      
      <guid>https://wdicc.com/use-org-mode-to-publish-blog/</guid>
      <description>a test
啊哈哈哈哈，超棒唉。markdown 里面写代码都没有高亮，org 里面是可以把代码部分高亮的。 效果可以看 这里
Title1 title2  list1 list2 list3  import sys class Hugo(object): def __init__(self): pass hugo = Hugo() print(hugo) print(&amp;quot;just a test&amp;quot;)  </description>
    </item>
    
    <item>
      <title>Migrate blog to hugo</title>
      <link>https://wdicc.com/migrate-blog-to-hugo/</link>
      <pubDate>Sat, 11 Mar 2017 16:29:40 +0800</pubDate>
      
      <guid>https://wdicc.com/migrate-blog-to-hugo/</guid>
      <description>折腾了好几天，把 blog 从 hexo 迁移到了 hugo 上面。hexo 是使用 nodejs 写出来的，hugo 是使用的 go。主要基于下面几个原因吧。
 个人不太喜欢 nodejs 那一坨依赖。 hugo 也比 nodejs 速度快很多。 hugo 用起来比较简洁。  首先写了一个迁移工具 hexo2hugo。网上还有一个 nodejs 版本的迁移工具可以参考。其实就是简单的把头部信息处理一下就可以。我还有一些特殊需求，比如把老早以前的一些 html 格式的文档顺道处理一下格式，还有一些小的修正和兼容工作，所以自己写了一个。另外也主要是好久没有写代码了，熟悉下。。
把文档迁移过去之后，找了几个主题看了一下，发现没有很喜欢的，就本着蛋疼的原则，把原来用的主题也迁移过来了，这个花的时间比较长一点。主要还得熟悉 hugo 的模板语法，还得想办法适配 hugo 的体系。比如 hugo 里面没有 archive 一说，不过通过万能的 google 搜索到了一个解决办法，也勉强还好。
目前这个 blog 已经是由 hugo 产生了，和以前外观，访问地址完全一模一样，rss 地址都一样。我测试了 google 里面的搜索结果，是都可以跳转的。今天算是基本都迁移完毕了。
这几天没事也总想记录一点想法，但是无奈新本子上面的 hexo 挂了，又不想搞 nodejs 那一坨依赖，就折腾了这个事情。不过折腾完毕之后发现想记录的事情都忘记了，nnd。</description>
    </item>
    
    <item>
      <title>archives</title>
      <link>https://wdicc.com/archives/</link>
      <pubDate>Fri, 10 Mar 2017 18:11:10 +0800</pubDate>
      
      <guid>https://wdicc.com/archives/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Upgrade kernel to 4.9 for linode</title>
      <link>https://wdicc.com/upgrade-kernel-to-4-9-for-linode/</link>
      <pubDate>Mon, 16 Jan 2017 18:37:56 +0800</pubDate>
      
      <guid>https://wdicc.com/upgrade-kernel-to-4-9-for-linode/</guid>
      <description>bbr 那么牛逼，赶紧赶一个潮流。其实我之前用了 kcp，也是类似的东西，不过那个要求服务器端和客户端都需要跑 kcp 服务才可以。bbr 就不用了，只需要服务器配置好就可以了。
Linode 实际上已经提供了 4.9 的内核。打开 Dashboard，然后点击你使用的 profile 右侧的 edit，在出来的界面里面，Kernel 右侧的列表里面，有个 4.9 的选项，不过我测试这个内核并不能打开 bbr，不知道是怎么回事，有兴趣的可以试试看，要注意选对架构（就是 64 还是 32）。
所以还是需要自己装内核。debian 官方已经打包好了 kernel 4.9，访问 http://mirrors.kernel.org/debian/pool/main/l/linux/ ，然后找到适合自己的 linux-image-4.9，我的是 http://mirrors.kernel.org/debian/pool/main/l/linux/linux-image-4.9.0-1-amd64-unsigned_4.9.2-2_amd64.deb ，下载到 vps 上面。
然后执行 sudo dkpg -i ./linux-image-4.9.0-1-amd64-unsigned_4.9.2-2_amd64.deb，最后应该会提示一个错误，缺少依赖的包。这个时候执行 sudo apt-get -f install，会提示安装缺失的包。
然后，还需要安装 grub。看你的情况。就刚才 profile 编辑的页面里面，kernel 右侧的选项里面，你看看你的是 grub2 还是 pv-grub。
 grub2: 参考这个
$ sudo apt-get install grub2 $ sudo update-grub  pv-grub: 参考这个
$ sudo apt-get install grub $ sudo mkdir /boot/grub $ sudo update-grub   然后在 profile 编辑页面里面，kernel 右侧选择对应的 grub 选项，重启 vps 就可以了。如果启动失败了，就在这个选项里面，选择之前的选项重启就可以恢复。</description>
    </item>
    
    <item>
      <title>Python __new__</title>
      <link>https://wdicc.com/python-new/</link>
      <pubDate>Mon, 16 Jan 2017 15:47:59 +0800</pubDate>
      
      <guid>https://wdicc.com/python-new/</guid>
      <description>翻译一点 https://www.python.org/download/releases/2.2/descrintro/#__new__ 有些感觉还是挺生硬的，方便自己理解吧。
__new__ 的一些规则:
 __new__ 是一个静态方法。定义它的时候并不需要执行 __new__ = staticmethod(__new__)，因为它的名字就包含了这个含义（这个对于类构造方法来说是个特殊的函数） __new__ 的第一个参数，必须是一个类，其余的参数是留给构造方法的。 覆盖了基类的 __new__ 方法的类有可能会调用基类的 __new__ 方法。传递给基类的 __new__ 方法的第一个参数，应该是覆盖基类的 __new__ 方法的类，而不是基类，如果传递了基类，你得到的将是基类的示例。 除非你想要按照后面两条描述的方法来使用，否则 __new__ 方法必须要调用基类的 __new__ 方法，这个是创建你的对象的实例的唯一方法。子类的 __new__ 方法可以从两个方面影响产生的实例：传递不同的参数给基类的 __new__，以及修改基类产生的对象（例如初始化一些实例变量） __new__ 方法必须返回一个对象。并不一定必须返回一个新的对象，虽然通常都那么做。如果你返回一个已经存在的对象，依然会有对于 __init__ 构造函数的调用。如果你返回一个其他函数的对象，那个对象的 __init__ 也会被调用。如果忘记返回，python 会给你返回 None，你程序的调用方也许会觉得很奇怪。 对于不可变对象，__new__ 可以返回一个之前缓存的对象。对于一些比较小的 int, str, tuple 类型就是这么做的。这也是为什么他们的 __init__ 什么都没做：否则之前缓存的对象会被 init 很多次。（另外一个原因是本身页没有东西可以给 __init__ 初始化的了，__new__ 返回的就是一个已经初始化的对象）。 如果你想要给一个内置的不可变类型增加一些可变的状态（例如给 string 类型增加一个默认的转换方法），最好是在 __init__ 方法里面初始化可变状态，而不要在 __new__ 里面。 如果你想要修改构造方法的签名，一般需要覆盖 __new__ 和 __init__ 方法来接受心的签名。然而，大部分内置类型都会忽视自己不用的参数，尤其是不可变类型（int，long，float，complex，str，unicode，tuple）都有一个假的 __init__，而可变类型（dict，list，file，super，classmethod，staticmethd，property）有一个假的 __new__。内置类型 object 有假的 __init__ 和 __new__ （给其他对象继承）。内置类型 type 在很多方面都很特别，请参考 metaclasses。 （这条和 __new__ 没关系，但是页应该了解一下）如果新建一个 type 的子类，实例会自动给 __dict__ 和 __weakrefs__ 预留空间（ __dict__ 在你使用前不会初始化，所以你不需要担心创建的所有实例被一个空的字典所占用的空间）。如果不需要这个多余的空间，可以给你的类设置 __slots__ = []（更多信息可以参考 __slots__。 Factoid: __new__ 是一个静态方法，不是类方法。我开始的时候觉得他应该是一个类方法，and that&amp;rsquo;s why I added the classmethod primitive。不幸的是，对于一个类方法，在这种情况下面 upcalls 不工作，所以我只好把他设计成一个第一个参数是一个 class 的静态方法。讽刺的是，there are now no known uses for class methods in the Python distribution (other than in the test suite).</description>
    </item>
    
    <item>
      <title>Python inherit and super</title>
      <link>https://wdicc.com/python-inherit-and-super/</link>
      <pubDate>Mon, 16 Jan 2017 11:53:04 +0800</pubDate>
      
      <guid>https://wdicc.com/python-inherit-and-super/</guid>
      <description>又学习了一个 python 的继承。有很多帖子都有介绍，比如理解 Python super，python super()。
先看一个例子，这个是第一个文章里面的。
class Root(object): def __init__(self): print(&amp;quot;this is Root&amp;quot;) class B(Root): def __init__(self): print(&amp;quot;enter B&amp;quot;) super(B, self).__init__() print(&amp;quot;leave B&amp;quot;) class C(Root): def __init__(self): print(&amp;quot;enter C&amp;quot;) super(C, self).__init__() print(&amp;quot;leave C&amp;quot;) class D(C): def __init__(self): print(&amp;quot;enter D&amp;quot;) super(D, self).__init__() print(&amp;quot;leave D&amp;quot;) class E(D, B): def __init__(self): print(&amp;quot;enter E&amp;quot;) super(E, self).__init__() print(&amp;quot;leave E&amp;quot;) e = E() print(e.__class__.mro()) # results: # enter E # enter D # enter C # enter B # this is Root # leave B # leave C # leave D # leave E # [&amp;lt;class &#39;__main__.</description>
    </item>
    
    <item>
      <title>Python metaclass</title>
      <link>https://wdicc.com/python-metaclass/</link>
      <pubDate>Thu, 12 Jan 2017 18:26:22 +0800</pubDate>
      
      <guid>https://wdicc.com/python-metaclass/</guid>
      <description>又理解了一下 python 的 metaclass 可以做什么，尝试记录一下。
class Meta(type): register = [] def __new__(cls, class_name, parrent_class, params): print(&amp;quot;In meta new: {}, {}, {}, {}&amp;quot;.format(cls, class_name, parrent_class, params)) cls.register.append(class_name) params[&#39;test_prop&#39;] = True # return super(Meta, cls).__new__(cls, class_name, parrent_class, params) # return type.__new__(cls, class_name, parrent_class, params) # return super(Meta, cls).__new__(type, class_name, parrent_class, params) # return type.__new__(type, class_name, parrent_class, params) return type(class_name, parrent_class, params) def __init__(self, class_name, parrent_class, params): print(&amp;quot;In meta init: {}, {}, {}&amp;quot;.format(class_name, parrent_class, params)) super(Meta, self).</description>
    </item>
    
    <item>
      <title>Reinvent the wheel</title>
      <link>https://wdicc.com/reinvent-the-wheel/</link>
      <pubDate>Thu, 12 Jan 2017 16:16:20 +0800</pubDate>
      
      <guid>https://wdicc.com/reinvent-the-wheel/</guid>
      <description>Reinvent the wheel 估计技术人员都知道这个典故。
刚才突然想谈这个，是看到图拉鼎参加 weex 的聚会有感而发。我要是没理解错，这个应该是类似于 React native 的一套实现，我没有仔细看过他的实现，不过说他重复造轮子应该也不为过，毕竟，大家普遍赞成的是在已有的轮子上面添砖加瓦，而不是另起一套。
重复造轮子到底应该不应该支持？
之前我司来了一个发明了 avalon 框架的牛人，之后我看好像就在很多的推介这个，新人来了先学习这个。后来还有很多这种框架，新人来了都是先学习这些框架。
这个事情上面，我看有几个好处 * 发明的人可以在公司内部得到很高的地位，以及相应的奖励。不管好用不好用，推行一版，一波人升天。后人再升级一版，又一波人升天。 * 学会了使用这些框架的人，如果自己本身不太灵活，到了其他公司会发现无法干活，因为使用多了会有一个很深的烙印。这样离职起来就没那么方便。 * 比较好规范和控制公司内部的技术方向。
坏处 * 和最新的技术方向可能有割裂，因为并不一定能及时更新适应。 * 问题解决只能依赖内部的这些人来解决，这种东西想要推广出去毕竟还是难。 * 浪费人力做基础建设。
其实看起来，对于基层员工来看好处还是大于坏处的。毕竟如果老板不关心这个成本或者不清楚可以节约这个成本的话，那些好处还是实实在在的，牛逼有的吹。
在老板关心的方面，可能还有一个点，就是创新有时候是比较难的，但是所谓的微创新其实是简单一些，造轮子的时候，一般多少都会有一些微创新。如果搞的人确实有能力，避免一些原来设计里面的鸡肋冗余的部分，让新的设计更加轻快，其实也算是有好处。</description>
    </item>
    
    <item>
      <title>Beansdb merge tools</title>
      <link>https://wdicc.com/beansdb-merge-tools/</link>
      <pubDate>Mon, 26 Dec 2016 18:36:11 +0800</pubDate>
      
      <guid>https://wdicc.com/beansdb-merge-tools/</guid>
      <description>Beansdb 是豆瓣开源出来的一个高效的支持 memcached 协议的文件存储 db。按 key 查找的时候，会有索引定位到磁盘位置。不过貌似前段时间看到说他们搞了一个新的替代这个，我找了一下没找到链接。
使用 beansdb 的时候，有 2 个问题需要解决 * 冗余问题 * 数据过期删除问题
数据冗余问题 先说第一个问题。beansdb 本身不提供分布式 hash 逻辑，它就是个单机的程序。冗余需要你自己搞定，如果你使用标准的 memcache 协议，可以有多 server 的配置，读的时候其中一个失败会自动找下一个 server，写的时候就不会了，需要你自己写到多个 server。如果你所有的 server 都是一模一样的，那多写就可以了。如果不一样，你还需要考虑自己的 hash 策略。
豆瓣提供了一个 python 的客户端，这个客户端里面其实包含了 hash 策略。通过把 key 和 server 分桶来做 hash。摘一点代码如下
BEANSDBCFG = { &amp;quot;localhost:7901&amp;quot;: range(16), &amp;quot;localhost:7902&amp;quot;: range(16), &amp;quot;localhost:7903&amp;quot;: range(16), } db = Beansdb(BEANSDBCFG, 16)  上面定义了三个 server，每个包含 16 个桶（你可以根据你的需求比如定义第一个 server 只包含某些桶）。
def __init__(self, servers, buckets_count=16, N=3, W=1, R=1):  这里是定义写入数据的时候的逻辑，那个 buckets_count 是桶的数量，N 和 R 貌似没用。。。，W 是改动的时候要求成功的最小 server 数量，包括删除和写入的时候。</description>
    </item>
    
    <item>
      <title>Release some staff at github</title>
      <link>https://wdicc.com/release-some-staff-at-github/</link>
      <pubDate>Tue, 13 Dec 2016 17:00:31 +0800</pubDate>
      
      <guid>https://wdicc.com/release-some-staff-at-github/</guid>
      <description>把 blog 用到的模板整理了一下，放到了 https://github.com/wd/hexo-fabric ，这个最开始是 fork 别人的代码改的，后来发现原来那个人已经不用了，就整理一下，增加了一个 tag 支持，修改了一下字体和背景色，还有代码颜色等，都是一些小修改。同时也提交到了官方的 theme 库，不过 pull request 还没有通过。。
另外，还把之前写的一个给 ngx-lua 用的一个使用 mcrypt 加密解密的库 https://github.com/wd/lua-resty-mcrypt ，整理出来单独弄了一个模块。代码其实非常简单，这个也能看出来 ngx_lua 里面使用 ffi 调用 C 模块开发多舒服，不过因为 C 知识有限，可能还是会有一些问题，不过至少自己测试是 ok 的，也在线上跑了好久，只能遇到有问题的再说了。这个同时也提交到了春哥的 opm 仓库，那个倒没有审核，提交就被索引了，使用的话应该可以用 opm 命令直接安装。</description>
    </item>
    
    <item>
      <title>Bloat and Query Speed in PostgreSQL</title>
      <link>https://wdicc.com/bloat-and-query-speed-in-postgresql/</link>
      <pubDate>Fri, 09 Dec 2016 12:12:21 +0800</pubDate>
      
      <guid>https://wdicc.com/bloat-and-query-speed-in-postgresql/</guid>
      <description>内容反义自 https://www.citusdata.com/blog/2016/11/04/autovacuum-not-the-enemy/
pg 的 mvcc 会导致表索引的 bloat 就不多说了。说一下不合理处理这种 bloat 害处是啥。
首先肯定是会浪费空间。然后也会影响查询速度。表和索引存储的时候都是 8kB 一个 page，如果一个查询一些行，数据库会加载这些 pages 到内存。一个 page 里面的 dead rows 越多，在加载的时候就越浪费 I/O。例如全表扫描会加载所有的 dead rows。
Bloat 还会导致热门的查询会一下塞满内存。会导致相同的 live rows 需要更多 pages。This causes swapping and makes certain query plans and algorithms ineligible for execution.
还有一个影响是，pg 的系统表也会有可能 bloat，因为他们也是表。导致这个的一种情况是频繁的创建和删除临时表。这个进一步会导致一些管理命令执行变慢，甚至比如 \d 这种命令。
索引也有可能会 bloat。索引是 tuple 标识和数据之间的一个映射。这些标识指向的是某个 page 里面的 offset。每个 tuple 都是一个独立的对象，需要自己的索引条目。更新一行的时候总是会创建这行的新的索引条目。
索引的 bloat 的影响比 table 小一点。索引里面指向 dead tuple 的可以直接标记为 dead. 这会使得索引膨胀，但是不会导致不必要的堆查找。同时更新堆中的 tuples 不影响已经索引的列，使用一种叫做 HOT 的技术来把指向 dead tuples 的指针指向新的。这允许查询可以通过这些指针复用旧的索引条目。(Also updates to tuples in the heap that do not affect the indexed column(s) use a technique called HOT to provide pointers from the dead tuple to its replacement.</description>
    </item>
    
    <item>
      <title>Full page write in PostgreSQL</title>
      <link>https://wdicc.com/full-page-write-in-postgresql/</link>
      <pubDate>Thu, 08 Dec 2016 18:02:14 +0800</pubDate>
      
      <guid>https://wdicc.com/full-page-write-in-postgresql/</guid>
      <description>读了一篇文章，简单翻译总结下。
Partial Writes / Torn Pages pg 默认是 8kB 一个 page。linux 文件系统一般是 4kB（x86 里面最大是 4kB)，老设备驱动一般是 512B 一个扇区，新的设备有些支持 4kB 或者 8kB。
当 pg 写入一个 page 8kB 的时候，系统的底层会拆分小一点块，这里涉及到写入的原子性。8kB 的 pg page，会被文件系统拆分成 4kB 的块，然后拆分成 512B 扇区大小。这个时候如果系统崩溃（比如停电，内核 bug）会发生什么？
即使系统的存储有针对这种情况的设计（比如 SSD 自带电容器，RAID 控制器自带电池），内核那块也是会拆分成 4kB 的 page，所以还是有一定可能性，pg 写了 8kB，但是只有部分写入成功。
这个时候你可能意识到这就是为啥我们要有事务日志（WAL）。所以当系统崩溃重启之后，数据库会读取 WAL（从最后一次 checkpoint），然后重新写入一遍，以保证数据文件是完整的。
恢复的时候，在修改一个 page 之前，还是会读取一下。
在 checkpoint 之后第一次修改一个 page 的时候，会把整个 page 写入 WAL。这是为了保证在恢复的时候，能保证这些被修改的 page 能完全恢复到他原有的样子。
写放大 如果打开 Full page write，很显然会导致 WAL 文件增加，因为就算修改一个字节，也会导致 8kB page 的写入。因为 Full page write 只发生在 checkpoint 之后的第一次写入，所以减少 checkpoint 的发生频率是可以减少写入的。</description>
    </item>
    
    <item>
      <title>使用 pgrepup 跨版本升级 pg</title>
      <link>https://wdicc.com/use-pgrepup-to-upgrade-your-postgres/</link>
      <pubDate>Thu, 08 Dec 2016 11:55:33 +0800</pubDate>
      
      <guid>https://wdicc.com/use-pgrepup-to-upgrade-your-postgres/</guid>
      <description>pgrepup 其实是一个支持 pg 跨版本复制的工具。而 pg 大版本升级需要停机是个比较郁闷的事情，如果能通过这个解决就实在太好了。下面测试了一下。
安装 需要安装 pgrepup 和 pglogical。
安装 pgrepup pgrepup 官方说是支持 python &amp;gt;= 2.7 的版本，我自己测试的结果，python 3.5 里面执行有点问题，需要修改几个地方。但是在 python 2.7 里面，不需要做任何修改，所以建议使用 python 2.7。安装很简单，执行 pip install pgprepup 就可以了。
安装 pglogical 需要给你的 pg 安装这个扩展。高版本的和低版本的都需要安装。
安装也很简单，下载源码，执行 PATH=/opt/pg96/bin:$PATH make USE_PGXS=1 install 就好了。如果是给 pg95 装，那就把路径改成 pg95。
可以参考这里。
配置 配置 db 先给几个 db 定义一下角色。db1 假设为 9.5 版本，db2 假设为 9.6 版本。
pgrepup 允许 db1, db2 和执行 pgrepup 所在的机器分别在不同的机器，也可以在相同的机器，看机器情况。
对于 db，最小配置的 postgres.conf 修改如下，我测试的时候两个 db 在一台机器上面，只需要修改 port 不一样就可以了。</description>
    </item>
    
  </channel>
</rss>