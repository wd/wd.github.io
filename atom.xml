<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>wd and cc</title>
    <link>https://wdicc.com/atom/index.xml</link>
    <description>Recent content on wd and cc</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Mon, 20 Mar 2017 20:41:10 +0800</lastBuildDate>
    <atom:link href="https://wdicc.com/atom/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Something about cruise tour</title>
      <link>https://wdicc.com/Something-about-cruise-tour/</link>
      <pubDate>Mon, 20 Mar 2017 20:41:10 +0800</pubDate>
      
      <guid>https://wdicc.com/Something-about-cruise-tour/</guid>
      <description>&lt;p&gt;之前知道邮轮游一直没有体验过，据说是在上面各种滚来滚去看书，因为手机没有信号，没有网络。前几天体验了一把，总结一下。&lt;/p&gt;

&lt;h2 id=&#34;一句话总结&#34;&gt;一句话总结&lt;/h2&gt;

&lt;p&gt;这上面有你讨厌的所有因素，大妈，广场舞，广场卡拉 ok，小孩子，无序，占座，插队，甚至最后一天还目睹了两起吵架。&lt;/p&gt;

&lt;h2 id=&#34;邮轮游玩什么&#34;&gt;邮轮游玩什么&lt;/h2&gt;

&lt;p&gt;我参加的是歌诗达幸运号（Costa Fortun），邮轮上面估计 80% 都是各种大爷大妈，带着女儿外孙。你可以想象一下，平时最不喜欢的组合在这里最全了。&lt;/p&gt;

&lt;p&gt;邮轮上面有免费的自助餐和一些特别的餐食，比如批萨，面条，猪排什么的。也有收费的餐食，当然你可以不去。酒和软饮都是收费的，开饭的时候有免费的白水给你喝，屋子里面是没有的。&lt;/p&gt;

&lt;p&gt;邮轮上面一般有大量的娱乐设施，比如赌场，游戏机，泳池，桑拿，剧场等。还定期有各种娱乐活动，比如猜个字啊，跳个舞什么的。所以第一次去还是可以看个新鲜的，尤其可能还有一些漂亮的陪玩 mm，看着也还可以。游戏机赌场是收费的，恩。&lt;/p&gt;

&lt;p&gt;此外剧场每天基本都会有一场大型的演出，30-40 分钟，可以让你打发时间。但是剧场虽然每天演出内容不一样，但是演员总是那一波，看多了其实也会腻味。&lt;/p&gt;

&lt;p&gt;房间里面也有电视，不过我观察电视都是反复重播录下来的一些电视，然后有一个电影台还是只有那么几部反复重复播放，《x man 天启》我看了不下 10 遍。&lt;/p&gt;

&lt;p&gt;小孩也有人给带着玩游戏，有专门的儿童俱乐部。还有健身房，健身房是我唯一对这次邮轮活动满意的地方，当然肯定不是对环境满意，毕竟里面充满了大爷大妈，满意的地方主要是在设备，设备真心不错。浴室和换衣间地板异常干净，比起我家楼下的奥力，简直天上地下。&lt;/p&gt;

&lt;p&gt;邮轮一般有那么1，2天是下船，我们这次的安排很屎，景点很无聊，低接导游也只是对购物有兴趣，购物店虽然不贵，但是东西比较少，挺没意思的。&lt;/p&gt;

&lt;h2 id=&#34;让人反感的几个瞬间&#34;&gt;让人反感的几个瞬间&lt;/h2&gt;

&lt;p&gt;排队上邮轮的时候，过安检的时候就一条队排的特别粗，到了最后那变细互相挤着往前走。我们后面有个阿姨就各种急着往你前面走，我老婆发现之后就故意挤着不让，我看的笑死，呵呵。&lt;/p&gt;

&lt;p&gt;第一天必须做逃生演习。有个大爷一家推着小车带着孩子，孩子可能没一会睡着了。而演习是需要所有人参加的，所以就不得不等比较慢的人。大爷就生气了，开始呵斥工作人员，「孩子都睡着了，啥时候开始」之类的，声音巨大。工作人员大都是外籍，估计也吓了一跳。最后结束的时候，大爷还过去指着那个工作人员不知道说了什么。&lt;/p&gt;

&lt;p&gt;剧院演出，基本前三四排上面都是东西占座的。除非你提前半个小时到。另外就是各种小孩大声说话也没人管。有时候酒吧做游戏，工作人员都明确说了游戏可能比较激烈，让大家把小孩弄走，但是看着一个女的抱着小孩几次被劝离之后还是要上去玩，貌似还是上去让小孩参与。&lt;/p&gt;

&lt;p&gt;昨天有个游戏，几个被淘汰的大妈，悄悄的跑回去继续参与，也有跑回去被发现之后赶走，再次跑回去的，当着一百来号人目睹就那么做，真的无语。&lt;/p&gt;

&lt;p&gt;今天下船之前大家集中在一个地方等着，有个姥爷带着孙女玩气球。有个哥们玩心重，带了个面具就冲那小孩过去了，小孩吓的赶紧跑到了姥爷后面，那个哥们就走了。过了半分钟小孩反映过来开始哭，那姥爷就开始不爽了。后来他们全家，追着那小伙骂，最后把面具也抢过来了，还要护照说要以后有啥毛病要找他。纠缠了能有10分钟。&lt;/p&gt;

&lt;p&gt;这只是记得起来的几个，反正年轻人真的不建议去邮轮了。如果是自己父母，倒是可以推荐去，他们应该喜欢。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>My way to keep fit</title>
      <link>https://wdicc.com/My-way-to-keep-fit/</link>
      <pubDate>Mon, 13 Mar 2017 15:19:30 +0800</pubDate>
      
      <guid>https://wdicc.com/My-way-to-keep-fit/</guid>
      <description>&lt;h1 id=&#34;最简单的减肥方法&#34;&gt;最简单的减肥方法&lt;/h1&gt;

&lt;p&gt;前年开始我发现一种比较简单的减肥方法，就是不吃或者少吃晚饭。&lt;/p&gt;

&lt;p&gt;这个方法应该不一定对所有人适用。我估计应该只对 BMI(Body Mass Index, 身体质量指数，注意和体脂率不是一个东西)比较高的人有用吧。&lt;/p&gt;

&lt;p&gt;我当时 BMI 是 &lt;code&gt;98/1.77^2=31.28&lt;/code&gt; 是属于比较高的，坚持了上面的方法半年之后，大概最瘦的时候是 28，我查了是刚好脱离了肥胖那一档，进入了过重。&lt;/p&gt;

&lt;h1 id=&#34;自己最近总结的一些健身方法&#34;&gt;自己最近总结的一些健身方法&lt;/h1&gt;

&lt;p&gt;按照一些理论，在有氧运动一定时间 T 之后，保持一定的心率 HR 继续运动，就会开始消耗脂肪。所谓的 &lt;a href=&#34;https://www.douban.com/note/228079030/&#34; title=&#34;fat burning zone&#34;&gt;fat burning zone&lt;/a&gt; (搜索到的，仅供参考)。&lt;/p&gt;

&lt;p&gt;对于 T，我看有的说是 20 分钟，有的是 40 分钟。我一般的做法是持续运动 40-50 分钟，不超过一小时。&lt;/p&gt;

&lt;p&gt;对于心率，先看下面的公式&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
MHR(最大心率) = 220 - age
MHR = 206 - (0.88 x age)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上面是最大心率，有多种算法最后应该结果大致有个范围，然后你的减脂的 HR 范围就是 &lt;code&gt;MHR x (0.7 到 0.8)&lt;/code&gt; 之间。我算出来我的是大概 130-140.&lt;/p&gt;

&lt;h2 id=&#34;跑步机-vs-椭圆机-vs-动感单车&#34;&gt;跑步机 vs 椭圆机 vs 动感单车&lt;/h2&gt;

&lt;p&gt;我自己家里买了一台动感单车，实际实践过之后，用这个有几个缺陷&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;自己练没有动感。在操课房里面教练会带着不停的变换速度，动作，一方面让你觉得没那么无聊，另一方面也是能增加运动量。&lt;/li&gt;
&lt;li&gt;自己练容易损坏脚踝和膝盖。我自己在家练的时候，基本就是站上面运动 30+ 分钟，脚一直在单车上面脚尖踩着，练完之后脚会疼痛。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;我其实挺喜欢在外面跑步，尤其早上，但是因为体重大，好几次都是跑一周之后双腿膝盖会开始疼痛，只好作罢。健身房里面的跑步机冲击比路面跑步小，可以试试看。&lt;/p&gt;

&lt;p&gt;最近尝试了跑步机上面跑，坚持 2 周之后，还是出现了一只腿的膝盖疼痛，只好暂停。开始尝试椭圆机。&lt;/p&gt;

&lt;p&gt;跑步机上面跑强度比椭圆机肯定强很多，跑步机上面在一个不快的速度下面，我持续跑 15 分钟之后，心率就会达到 150，其实已经有点高了。&lt;/p&gt;

&lt;p&gt;跑步机的几个问题&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;容易心率过快&lt;/li&gt;
&lt;li&gt;不方便听音乐看片子分散注意力&lt;/li&gt;
&lt;li&gt;不容易不间断坚持跑 30 - 40 分钟&lt;/li&gt;
&lt;li&gt;膝盖损伤&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;最后发现椭圆机实在是很不错&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;运动速度慢，不妨碍你看片子听音乐(这个非常重要，否则坚持50分钟很难)&lt;/li&gt;
&lt;li&gt;速度恒定，也就是心率恒定，你只需要选择一个适合你的减脂的心率的难度就可以了&lt;/li&gt;
&lt;li&gt;对膝盖冲击比较小&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;目前正在体验椭圆机中。&lt;/p&gt;

&lt;h2 id=&#34;力量训练&#34;&gt;力量训练&lt;/h2&gt;

&lt;p&gt;这块目前还比较盲目，只是知道运动完毕之后应该需要进行适当的力量训练，还在摸索。&lt;/p&gt;

&lt;h2 id=&#34;饮食注意&#34;&gt;饮食注意&lt;/h2&gt;

&lt;p&gt;我本身血压高，所以需要低盐。然后减脂的话，一般的讲法是不要吃或者少吃和糖类有关系的食物，比如糖，西瓜这些，以及很容易转换为糖类的食物，比如谷物，大米这些。可以吃肉类（瘦肉或者白肉，比如鸡肉鱼肉）。&lt;/p&gt;

&lt;p&gt;我以前基本没做过几个青菜的饭。目前还在摸索中。&lt;/p&gt;

&lt;p&gt;白水煮了就能接受的：西兰花，菜花&lt;/p&gt;

&lt;p&gt;水煮之后需要稍微加点盐的：油菜，蘑菇，小白菜&lt;/p&gt;

&lt;p&gt;不知道怎么吃好的：芹菜&lt;/p&gt;

&lt;p&gt;芹菜不知道怎么吃好，放了盐感觉也不太好吃，不知道那里做的不对。其他的食材还在持续尝试中。&lt;/p&gt;

&lt;p&gt;之前看了一本书，里面讲到几个低盐的方法，就是比如放入火腿肠等本身自带咸味的食材，或者往酸的方向走。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Use org mode to publish blog</title>
      <link>https://wdicc.com/Use-org-mode-to-publish-blog/</link>
      <pubDate>Sun, 12 Mar 2017 08:59:19 +0800</pubDate>
      
      <guid>https://wdicc.com/Use-org-mode-to-publish-blog/</guid>
      <description>&lt;p&gt;a test&lt;/p&gt;

&lt;p&gt;啊哈哈哈哈，超棒唉。markdown 里面写代码都没有高亮，org 里面是可以把代码部分高亮的。&lt;/p&gt;

&lt;p&gt;效果可以看 &lt;a href=&#34;https://goo.gl/photos/E8p1WX34rfAQn31v9&#34; title=&#34;这里&#34;&gt;这里&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;title1&#34;&gt;Title1&lt;/h2&gt;

&lt;h3 id=&#34;title2&#34;&gt;title2&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;list1&lt;/li&gt;
&lt;li&gt;list2&lt;/li&gt;
&lt;li&gt;list3&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;
import sys

class Hugo(object):
    def __init__(self):
        pass

hugo = Hugo()
print(hugo)
print(&amp;quot;just a test&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Migrate blog to hugo</title>
      <link>https://wdicc.com/Migrate-blog-to-hugo/</link>
      <pubDate>Sat, 11 Mar 2017 16:29:40 +0800</pubDate>
      
      <guid>https://wdicc.com/Migrate-blog-to-hugo/</guid>
      <description>&lt;p&gt;折腾了好几天，把 blog 从 hexo 迁移到了 &lt;a href=&#34;http://gohugo.io/&#34;&gt;hugo&lt;/a&gt; 上面。hexo 是使用 nodejs 写出来的，hugo 是使用的 go。主要基于下面几个原因吧。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;个人不太喜欢 nodejs 那一坨依赖。&lt;/li&gt;
&lt;li&gt;hugo 也比 nodejs 速度快很多。&lt;/li&gt;
&lt;li&gt;hugo 用起来比较简洁。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;首先写了一个迁移工具 &lt;a href=&#34;https://github.com/wd/hexo2hugo&#34;&gt;hexo2hugo&lt;/a&gt;。网上还有一个 nodejs 版本的&lt;a href=&#34;http://nodejh.com/post/Migrate-to-Hugo-from-Hexo/&#34;&gt;迁移工具&lt;/a&gt;可以参考。其实就是简单的把头部信息处理一下就可以。我还有一些特殊需求，比如把老早以前的一些 html 格式的文档顺道处理一下格式，还有一些小的修正和兼容工作，所以自己写了一个。另外也主要是好久没有写代码了，熟悉下。。&lt;/p&gt;

&lt;p&gt;把文档迁移过去之后，找了几个主题看了一下，发现没有很喜欢的，就本着蛋疼的原则，把原来用的主题也&lt;a href=&#34;https://github.com/wd/hugo-fabric&#34;&gt;迁移过来了&lt;/a&gt;，这个花的时间比较长一点。主要还得熟悉 hugo 的模板语法，还得想办法适配 hugo 的体系。比如 hugo 里面没有 archive 一说，不过通过万能的 google 搜索到了一个解决办法，也勉强还好。&lt;/p&gt;

&lt;p&gt;目前这个 blog 已经是由 hugo 产生了，和以前外观，访问地址完全一模一样，rss 地址都一样。我测试了 google 里面的搜索结果，是都可以跳转的。今天算是基本都迁移完毕了。&lt;/p&gt;

&lt;p&gt;这几天没事也总想记录一点想法，但是无奈新本子上面的 hexo 挂了，又不想搞 nodejs 那一坨依赖，就折腾了这个事情。不过折腾完毕之后发现想记录的事情都忘记了，nnd。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>archives</title>
      <link>https://wdicc.com/archives/</link>
      <pubDate>Fri, 10 Mar 2017 18:11:10 +0800</pubDate>
      
      <guid>https://wdicc.com/archives/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Upgrade kernel to 4.9 for linode</title>
      <link>https://wdicc.com/Upgrade-kernel-to-4-9-for-linode/</link>
      <pubDate>Mon, 16 Jan 2017 18:37:56 +0800</pubDate>
      
      <guid>https://wdicc.com/Upgrade-kernel-to-4-9-for-linode/</guid>
      <description>&lt;p&gt;bbr 那么牛逼，赶紧赶一个潮流。其实我之前用了 kcp，也是类似的东西，不过那个要求服务器端和客户端都需要跑 kcp 服务才可以。bbr 就不用了，只需要服务器配置好就可以了。&lt;/p&gt;

&lt;p&gt;Linode 实际上已经提供了 4.9 的内核。打开 &lt;code&gt;Dashboard&lt;/code&gt;，然后点击你使用的 profile 右侧的 edit，在出来的界面里面，Kernel 右侧的列表里面，有个 4.9 的选项，不过我测试这个内核并不能打开 bbr，不知道是怎么回事，有兴趣的可以试试看，要注意选对架构（就是 64 还是 32）。&lt;/p&gt;

&lt;p&gt;所以还是需要自己装内核。debian 官方已经打包好了 kernel 4.9，访问 &lt;a href=&#34;http://mirrors.kernel.org/debian/pool/main/l/linux/&#34;&gt;http://mirrors.kernel.org/debian/pool/main/l/linux/&lt;/a&gt; ，然后找到适合自己的 linux-image-4.9，我的是 &lt;a href=&#34;http://mirrors.kernel.org/debian/pool/main/l/linux/linux-image-4.9.0-1-amd64-unsigned_4.9.2-2_amd64.deb&#34;&gt;http://mirrors.kernel.org/debian/pool/main/l/linux/linux-image-4.9.0-1-amd64-unsigned_4.9.2-2_amd64.deb&lt;/a&gt; ，下载到 vps 上面。&lt;/p&gt;

&lt;p&gt;然后执行 &lt;code&gt;sudo dkpg -i ./linux-image-4.9.0-1-amd64-unsigned_4.9.2-2_amd64.deb&lt;/code&gt;，最后应该会提示一个错误，缺少依赖的包。这个时候执行 &lt;code&gt;sudo apt-get -f install&lt;/code&gt;，会提示安装缺失的包。&lt;/p&gt;

&lt;p&gt;然后，还需要安装 &lt;code&gt;grub&lt;/code&gt;。看你的情况。就刚才 profile 编辑的页面里面，kernel 右侧的选项里面，你看看你的是 &lt;code&gt;grub2&lt;/code&gt; 还是 &lt;code&gt;pv-grub&lt;/code&gt;。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;grub2&lt;/code&gt;: 参考&lt;a href=&#34;https://www.linode.com/docs/tools-reference/custom-kernels-distros/run-a-distribution-supplied-kernel-with-kvm&#34;&gt;这个&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo apt-get install grub2
$ sudo update-grub
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;pv-grub&lt;/code&gt;: 参考&lt;a href=&#34;https://www.linode.com/docs/tools-reference/custom-kernels-distros/run-a-distributionsupplied-kernel-with-pvgrub&#34;&gt;这个&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo apt-get install grub
$ sudo mkdir /boot/grub
$ sudo update-grub
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;然后在 profile 编辑页面里面，kernel 右侧选择对应的 grub 选项，重启 vps 就可以了。如果启动失败了，就在这个选项里面，选择之前的选项重启就可以恢复。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Python __new__</title>
      <link>https://wdicc.com/Python-new/</link>
      <pubDate>Mon, 16 Jan 2017 15:47:59 +0800</pubDate>
      
      <guid>https://wdicc.com/Python-new/</guid>
      <description>&lt;p&gt;翻译一点 &lt;a href=&#34;https://www.python.org/download/releases/2.2/descrintro/#__new__&#34;&gt;https://www.python.org/download/releases/2.2/descrintro/#__new__&lt;/a&gt; 有些感觉还是挺生硬的，方便自己理解吧。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;__new__&lt;/code&gt; 的一些规则:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;__new__&lt;/code&gt; 是一个静态方法。定义它的时候并不需要执行 &lt;code&gt;__new__ = staticmethod(__new__)&lt;/code&gt;，因为它的名字就包含了这个含义（这个对于类构造方法来说是个特殊的函数）&lt;/li&gt;
&lt;li&gt;&lt;code&gt;__new__&lt;/code&gt; 的第一个参数，必须是一个类，其余的参数是留给构造方法的。&lt;/li&gt;
&lt;li&gt;覆盖了基类的 &lt;code&gt;__new__&lt;/code&gt; 方法的类有可能会调用基类的 &lt;code&gt;__new__&lt;/code&gt; 方法。传递给基类的 &lt;code&gt;__new__&lt;/code&gt; 方法的第一个参数，应该是覆盖基类的 &lt;code&gt;__new__&lt;/code&gt; 方法的类，而不是基类，如果传递了基类，你得到的将是基类的示例。&lt;/li&gt;
&lt;li&gt;除非你想要按照后面两条描述的方法来使用，否则 &lt;code&gt;__new__&lt;/code&gt; 方法必须要调用基类的 &lt;code&gt;__new__&lt;/code&gt; 方法，这个是创建你的对象的实例的唯一方法。子类的 &lt;code&gt;__new__&lt;/code&gt; 方法可以从两个方面影响产生的实例：传递不同的参数给基类的 &lt;code&gt;__new__&lt;/code&gt;，以及修改基类产生的对象（例如初始化一些实例变量）&lt;/li&gt;
&lt;li&gt;&lt;code&gt;__new__&lt;/code&gt; 方法必须返回一个对象。并不一定必须返回一个新的对象，虽然通常都那么做。如果你返回一个已经存在的对象，依然会有对于 &lt;code&gt;__init__&lt;/code&gt; 构造函数的调用。如果你返回一个其他函数的对象，那个对象的 &lt;code&gt;__init__&lt;/code&gt; 也会被调用。如果忘记返回，python 会给你返回 None，你程序的调用方也许会觉得很奇怪。&lt;/li&gt;
&lt;li&gt;对于不可变对象，&lt;code&gt;__new__&lt;/code&gt; 可以返回一个之前缓存的对象。对于一些比较小的 int, str, tuple 类型就是这么做的。这也是为什么他们的 &lt;code&gt;__init__&lt;/code&gt; 什么都没做：否则之前缓存的对象会被 init 很多次。（另外一个原因是本身页没有东西可以给 &lt;code&gt;__init__&lt;/code&gt; 初始化的了，&lt;code&gt;__new__&lt;/code&gt; 返回的就是一个已经初始化的对象）。&lt;/li&gt;
&lt;li&gt;如果你想要给一个内置的不可变类型增加一些可变的状态（例如给 string 类型增加一个默认的转换方法），最好是在 &lt;code&gt;__init__&lt;/code&gt; 方法里面初始化可变状态，而不要在 &lt;code&gt;__new__&lt;/code&gt; 里面。&lt;/li&gt;
&lt;li&gt;如果你想要修改构造方法的签名，一般需要覆盖 &lt;code&gt;__new__&lt;/code&gt; 和 &lt;code&gt;__init__&lt;/code&gt; 方法来接受心的签名。然而，大部分内置类型都会忽视自己不用的参数，尤其是不可变类型（int，long，float，complex，str，unicode，tuple）都有一个假的 &lt;code&gt;__init__&lt;/code&gt;，而可变类型（dict，list，file，super，classmethod，staticmethd，property）有一个假的 &lt;code&gt;__new__&lt;/code&gt;。内置类型 &lt;code&gt;object&lt;/code&gt; 有假的 &lt;code&gt;__init__&lt;/code&gt; 和 &lt;code&gt;__new__&lt;/code&gt; （给其他对象继承）。内置类型 &lt;code&gt;type&lt;/code&gt; 在很多方面都很特别，请参考 metaclasses。&lt;/li&gt;
&lt;li&gt;（这条和 &lt;code&gt;__new__&lt;/code&gt; 没关系，但是页应该了解一下）如果新建一个 &lt;code&gt;type&lt;/code&gt; 的子类，实例会自动给 &lt;code&gt;__dict__&lt;/code&gt; 和 &lt;code&gt;__weakrefs__&lt;/code&gt; 预留空间（ &lt;code&gt;__dict__&lt;/code&gt; 在你使用前不会初始化，所以你不需要担心创建的所有实例被一个空的字典所占用的空间）。如果不需要这个多余的空间，可以给你的类设置 &lt;code&gt;__slots__ = []&lt;/code&gt;（更多信息可以参考 &lt;code&gt;__slots__&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;Factoid: &lt;code&gt;__new__&lt;/code&gt; 是一个静态方法，不是类方法。我开始的时候觉得他应该是一个类方法，and that&amp;rsquo;s why I added the classmethod primitive。不幸的是，对于一个类方法，在这种情况下面 upcalls 不工作，所以我只好把他设计成一个第一个参数是一个 class 的静态方法。讽刺的是，there are now no known uses for class methods in the Python distribution (other than in the test suite). I might even get rid of classmethod in a future release if no good use for it can be found!&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Python inherit and super</title>
      <link>https://wdicc.com/Python-inherit-and-super/</link>
      <pubDate>Mon, 16 Jan 2017 11:53:04 +0800</pubDate>
      
      <guid>https://wdicc.com/Python-inherit-and-super/</guid>
      <description>&lt;p&gt;又学习了一个 python 的继承。有很多帖子都有介绍，比如&lt;a href=&#34;https://laike9m.com/blog/li-jie-python-super,70/&#34;&gt;理解 Python super&lt;/a&gt;，&lt;a href=&#34;http://www.cnblogs.com/lovemo1314/archive/2011/05/03/2035005.html&#34;&gt;python super()&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;先看一个例子，这个是第一个文章里面的。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class Root(object):
    def __init__(self):
        print(&amp;quot;this is Root&amp;quot;)


class B(Root):
    def __init__(self):
        print(&amp;quot;enter B&amp;quot;)
        super(B, self).__init__()
        print(&amp;quot;leave B&amp;quot;)


class C(Root):
    def __init__(self):
        print(&amp;quot;enter C&amp;quot;)
        super(C, self).__init__()
        print(&amp;quot;leave C&amp;quot;)


class D(C):
    def __init__(self):
        print(&amp;quot;enter D&amp;quot;)
        super(D, self).__init__()
        print(&amp;quot;leave D&amp;quot;)


class E(D, B):
    def __init__(self):
        print(&amp;quot;enter E&amp;quot;)
        super(E, self).__init__()
        print(&amp;quot;leave E&amp;quot;)

e = E()
print(e.__class__.mro())

# results:
# enter E
# enter D
# enter C
# enter B
# this is Root
# leave B
# leave C
# leave D
# leave E
# [&amp;lt;class &#39;__main__.E&#39;&amp;gt;, &amp;lt;class &#39;__main__.D&#39;&amp;gt;, &amp;lt;class &#39;__main__.C&#39;&amp;gt;, &amp;lt;class &#39;__main__.B&#39;&amp;gt;, &amp;lt;class &#39;__main__.Root&#39;&amp;gt;, &amp;lt;class &#39;object&#39;&amp;gt;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;没有什么问题，所有的类都做了初始化，很完美。接着再看一个例子，这个例子其实是上面第二篇文章里面的。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class A(object):
    def __init__(self):
        print(&amp;quot;enter A&amp;quot;)
        print(&amp;quot;leave A&amp;quot;)


class B(object):
    def __init__(self):
        print(&amp;quot;enter B&amp;quot;)
        print(&amp;quot;leave B&amp;quot;)


class C(A):
    def __init__(self):
        print(&amp;quot;enter C&amp;quot;)
        super(C, self).__init__()
        print(&amp;quot;leave C&amp;quot;)


class D(A):
    def __init__(self):
        print(&amp;quot;enter D&amp;quot;)
        super(D, self).__init__()
        print(&amp;quot;leave D&amp;quot;)


class E(B, C):
    def __init__(self):
        print(&amp;quot;enter E&amp;quot;)
        super(E, self).__init__()
        print(&amp;quot;leave E&amp;quot;)


class F(E, D):
    def __init__(self):
        print(&amp;quot;enter F&amp;quot;)
        super(F, self).__init__()
        print(&amp;quot;leave F&amp;quot;)


f = F()
print(f.__class__.mro())

# results:
# enter F
# enter E
# enter B
# leave B
# leave E
# leave F
# [&amp;lt;class &#39;__main__.F&#39;&amp;gt;, &amp;lt;class &#39;__main__.E&#39;&amp;gt;, &amp;lt;class &#39;__main__.B&#39;&amp;gt;, &amp;lt;class &#39;__main__.C&#39;&amp;gt;, &amp;lt;class &#39;__main__.D&#39;&amp;gt;, &amp;lt;class &#39;__main__.A&#39;&amp;gt;, &amp;lt;class &#39;object&#39;&amp;gt;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我发现和文章里面贴的结果不一样，里面缺少对 C，D，A 的初始化。琢磨半天才弄明白，主要原因就是，&lt;code&gt;A&lt;/code&gt;，&lt;code&gt;B&lt;/code&gt; 其实也是继承自 &lt;code&gt;object&lt;/code&gt;，然而我们并没有调用 &lt;code&gt;super&lt;/code&gt; 来初始化，所以只需要加上就可以了。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class A(object):
    def __init__(self):
        print(&amp;quot;enter A&amp;quot;)
        super(A, self).__init__()
        print(&amp;quot;leave A&amp;quot;)


class B(object):
    def __init__(self):
        print(&amp;quot;enter B&amp;quot;)
        super(B, self).__init__()
        print(&amp;quot;leave B&amp;quot;)


class C(A):
    def __init__(self):
        print(&amp;quot;enter C&amp;quot;)
        super(C, self).__init__()
        print(&amp;quot;leave C&amp;quot;)


class D(A):
    def __init__(self):
        print(&amp;quot;enter D&amp;quot;)
        super(D, self).__init__()
        print(&amp;quot;leave D&amp;quot;)


class E(B, C):
    def __init__(self):
        print(&amp;quot;enter E&amp;quot;)
        super(E, self).__init__()
        print(&amp;quot;leave E&amp;quot;)


class F(E, D):
    def __init__(self):
        print(&amp;quot;enter F&amp;quot;)
        super(F, self).__init__()
        print(&amp;quot;leave F&amp;quot;)


f = F()
print(f.__class__.mro())

# results:
# enter F
# enter E
# enter B
# enter C
# enter D
# enter A
# leave A
# leave D
# leave C
# leave B
# leave E
# leave F
# [&amp;lt;class &#39;__main__.F&#39;&amp;gt;, &amp;lt;class &#39;__main__.E&#39;&amp;gt;, &amp;lt;class &#39;__main__.B&#39;&amp;gt;, &amp;lt;class &#39;__main__.C&#39;&amp;gt;, &amp;lt;class &#39;__main__.D&#39;&amp;gt;, &amp;lt;class &#39;__main__.A&#39;&amp;gt;, &amp;lt;class &#39;object&#39;&amp;gt;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这样就完美了。目测这个会是一个隐藏的坑。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Python metaclass</title>
      <link>https://wdicc.com/Python-metaclass/</link>
      <pubDate>Thu, 12 Jan 2017 18:26:22 +0800</pubDate>
      
      <guid>https://wdicc.com/Python-metaclass/</guid>
      <description>&lt;p&gt;又理解了一下 python 的 metaclass 可以做什么，尝试记录一下。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class Meta(type):
    register = []

    def __new__(cls, class_name, parrent_class, params):
        print(&amp;quot;In meta new: {}, {}, {}, {}&amp;quot;.format(cls, class_name, parrent_class, params))
        cls.register.append(class_name)
        params[&#39;test_prop&#39;] = True
        # return super(Meta, cls).__new__(cls, class_name, parrent_class, params)
        # return type.__new__(cls, class_name, parrent_class, params)
        # return super(Meta, cls).__new__(type, class_name, parrent_class, params)
        # return type.__new__(type, class_name, parrent_class, params)
        return type(class_name, parrent_class, params)

    def __init__(self, class_name, parrent_class, params):
        print(&amp;quot;In meta init: {}, {}, {}&amp;quot;.format(class_name, parrent_class, params))
        super(Meta, self).__init__(class_name, parrent_class, params)


class A(object, metaclass=Meta):
    pass

print(&amp;quot;register: {}&amp;quot;.format(Meta.register))
print(&amp;quot;prop: {}&amp;quot;.format(A.test_prop))
print(&amp;quot;register: {}&amp;quot;.format(A.register))  # Error

# outputs:
# In meta new: &amp;lt;class &#39;__main__.Meta&#39;&amp;gt;, A, (&amp;lt;class &#39;object&#39;&amp;gt;,), {&#39;__module__&#39;: &#39;__main__&#39;, &#39;__qualname__&#39;: &#39;A&#39;}
# In meta init: A, (&amp;lt;class &#39;object&#39;&amp;gt;,), {&#39;__module__&#39;: &#39;__main__&#39;, &#39;__qualname__&#39;: &#39;A&#39;}
# register: [&#39;A&#39;]
# prop: True
# AttributeError: type object &#39;A&#39; has no attribute &#39;register&#39;

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看到，在构造 &lt;code&gt;A&lt;/code&gt; 的时候，&lt;code&gt;Meta&lt;/code&gt; 这个类里面，&lt;code&gt;__new__&lt;/code&gt; 和 &lt;code&gt;__init__&lt;/code&gt; 都会被调用到。上面代码往 &lt;code&gt;A&lt;/code&gt; 里面塞了一个属性。&lt;/p&gt;

&lt;p&gt;在 &lt;code&gt;__new__&lt;/code&gt; 里面，有几个注释，可以去掉注释看看不同的效果。目前还有点疑惑，传给 &lt;code&gt;__new__&lt;/code&gt; 第一个参数到底是什么。另外，开始对 &lt;code&gt;super&lt;/code&gt; 也有点疑惑了，还在学习。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Reinvent the wheel</title>
      <link>https://wdicc.com/Reinvent-the-wheel/</link>
      <pubDate>Thu, 12 Jan 2017 16:16:20 +0800</pubDate>
      
      <guid>https://wdicc.com/Reinvent-the-wheel/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Reinventing_the_wheel&#34;&gt;Reinvent the wheel&lt;/a&gt; 估计技术人员都知道这个典故。&lt;/p&gt;

&lt;p&gt;刚才突然想谈这个，是看到图拉鼎参加 &lt;a href=&#34;https://weex-project.io/&#34;&gt;weex&lt;/a&gt; 的聚会有感而发。我要是没理解错，这个应该是类似于 React native 的一套实现，我没有仔细看过他的实现，不过说他重复造轮子应该也不为过，毕竟，大家普遍赞成的是在已有的轮子上面添砖加瓦，而不是另起一套。&lt;/p&gt;

&lt;p&gt;重复造轮子到底应该不应该支持？&lt;/p&gt;

&lt;p&gt;之前我司来了一个发明了 avalon 框架的牛人，之后我看好像就在很多的推介这个，新人来了先学习这个。后来还有很多这种框架，新人来了都是先学习这些框架。&lt;/p&gt;

&lt;p&gt;这个事情上面，我看有几个好处
* 发明的人可以在公司内部得到很高的地位，以及相应的奖励。不管好用不好用，推行一版，一波人升天。后人再升级一版，又一波人升天。
* 学会了使用这些框架的人，如果自己本身不太灵活，到了其他公司会发现无法干活，因为使用多了会有一个很深的烙印。这样离职起来就没那么方便。
* 比较好规范和控制公司内部的技术方向。&lt;/p&gt;

&lt;p&gt;坏处
* 和最新的技术方向可能有割裂，因为并不一定能及时更新适应。
* 问题解决只能依赖内部的这些人来解决，这种东西想要推广出去毕竟还是难。
* 浪费人力做基础建设。&lt;/p&gt;

&lt;p&gt;其实看起来，对于基层员工来看好处还是大于坏处的。毕竟如果老板不关心这个成本或者不清楚可以节约这个成本的话，那些好处还是实实在在的，牛逼有的吹。&lt;/p&gt;

&lt;p&gt;在老板关心的方面，可能还有一个点，就是创新有时候是比较难的，但是所谓的微创新其实是简单一些，造轮子的时候，一般多少都会有一些微创新。如果搞的人确实有能力，避免一些原来设计里面的鸡肋冗余的部分，让新的设计更加轻快，其实也算是有好处。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Beansdb merge tools</title>
      <link>https://wdicc.com/Beansdb-merge-tools/</link>
      <pubDate>Mon, 26 Dec 2016 18:36:11 +0800</pubDate>
      
      <guid>https://wdicc.com/Beansdb-merge-tools/</guid>
      <description>

&lt;p&gt;Beansdb 是豆瓣开源出来的一个高效的支持 memcached 协议的文件存储 db。按 key 查找的时候，会有索引定位到磁盘位置。不过貌似前段时间看到说他们搞了一个新的替代这个，我找了一下没找到链接。&lt;/p&gt;

&lt;p&gt;使用 beansdb 的时候，有 2 个问题需要解决
* 冗余问题
* 数据过期删除问题&lt;/p&gt;

&lt;h2 id=&#34;数据冗余问题&#34;&gt;数据冗余问题&lt;/h2&gt;

&lt;p&gt;先说第一个问题。beansdb 本身不提供分布式 hash 逻辑，它就是个单机的程序。冗余需要你自己搞定，如果你使用标准的 memcache 协议，可以有多 server 的配置，读的时候其中一个失败会自动找下一个 server，写的时候就不会了，需要你自己写到多个 server。如果你所有的 server 都是一模一样的，那多写就可以了。如果不一样，你还需要考虑自己的 hash 策略。&lt;/p&gt;

&lt;p&gt;豆瓣提供了一个 python 的&lt;a href=&#34;https://github.com/douban/beansdb/blob/master/python/dbclient.py&#34;&gt;客户端&lt;/a&gt;，这个客户端里面其实包含了 hash 策略。通过把 key 和 server 分桶来做 hash。摘一点代码如下&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;BEANSDBCFG = {
    &amp;quot;localhost:7901&amp;quot;: range(16),
    &amp;quot;localhost:7902&amp;quot;: range(16),
    &amp;quot;localhost:7903&amp;quot;: range(16),
}

db = Beansdb(BEANSDBCFG, 16)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上面定义了三个 server，每个包含 16 个桶（你可以根据你的需求比如定义第一个 server 只包含某些桶）。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def __init__(self, servers, buckets_count=16, N=3, W=1, R=1):
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里是定义写入数据的时候的逻辑，那个 &lt;code&gt;buckets_count&lt;/code&gt; 是桶的数量，&lt;code&gt;N&lt;/code&gt; 和 &lt;code&gt;R&lt;/code&gt; 貌似没用。。。，&lt;code&gt;W&lt;/code&gt; 是改动的时候要求成功的最小 server 数量，包括删除和写入的时候。&lt;/p&gt;

&lt;p&gt;读取的时候，会循环从包含这个 key 的桶的 server 列表里面循环读取，这里还有一个「自愈」的逻辑，循环读取直到遇到一个成功的 server，会同时把前面失败的 server 都写入一份数据。&lt;/p&gt;

&lt;p&gt;这样下来基本就解决了读写分布式和故障恢复的逻辑了，非常巧妙。&lt;/p&gt;

&lt;p&gt;其实针对这个问题，豆瓣还开源了个 &lt;a href=&#34;https://github.com/douban/beanseye&#34;&gt;beanseye&lt;/a&gt;，具体功能没有仔细研究，不过应该是上面需要客户端处理的事情都不需要考虑了。&lt;/p&gt;

&lt;p&gt;我们开始用的时候，不知道有 beanseye，我的场景是在 perl 环境下面使用，把 python 的客户端翻译了一个 perl 的版本出来。[1] 有兴趣可以看看。&lt;/p&gt;

&lt;h2 id=&#34;数据过期删除问题&#34;&gt;数据过期删除问题&lt;/h2&gt;

&lt;p&gt;beansdb 设计之初写入用的是 append 模式，就是说，遇到删除也是写入一条新的记录，并不会返回去修改原来的数据，所以能达到合理的 IO 速度。如果场景是大量不会删除的小文件，那么 beansdb 使用起来非常合适。&lt;/p&gt;

&lt;p&gt;如果有数据过期或者删除的需求，就需要想办法处理这些数据了，否则的话，beandb 的数据文件里面会慢慢的有大量的无用数据，浪费磁盘空间。&lt;/p&gt;

&lt;p&gt;这个删除过期数据的过程，我看豆瓣叫做 merge。思路其实就是把所有数据遍历一次，把有效的数据写入一个新的 data 文件，然后旧的删掉，就可以了。beansdb 的数据文件有 2 种，一种是 &lt;code&gt;xxx.data&lt;/code&gt;，这种文件是数据文件，另外一种是 &lt;code&gt;xxx.hint.qlz&lt;/code&gt; 这种是索引文件。&lt;/p&gt;

&lt;p&gt;针对这个需求，我写了两版程序，第一版就是单纯的解读一下数据文件，把其中的数据的信息读出来，主要是版本号和创建时间，然后根据版本号只写入高版本的，根据创建时间把过期的数据丢弃。生成新的 data 文件之后，要删除 hint 文件，启动的时候会自动产生 hint 文件。然后在 beansdb 的机器上面定期跑这个脚本就好了，注意跑之前应该先关闭 beansdb。&lt;/p&gt;

&lt;p&gt;第一个版本的程序只是解读了每个块的数据头，程序用起来也勉强还行，但是主要问题是，每次启动都需要重新产生 hint 文件，导致启动到提供服务很慢，所以就有了第二版程序。第二版包含了第一版的全部功能，还提供了按照文件大小来定义删除时限的功能。&lt;/p&gt;

&lt;p&gt;第二个版本程序基本把 data 和 hint 文件产生的逻辑都用 perl 实现了（不过还没有经过太多测试）。下面简单讲讲逻辑。&lt;/p&gt;

&lt;h3 id=&#34;data-文件&#34;&gt;data 文件&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;‌typedef struct data_record
{
    char *value;
    union
    {
        bool free_value;    // free value or not
        uint32_t crc;
    };
    int32_t tstamp;
    int32_t flag;
    int32_t version;
    uint32_t ksz;
    uint32_t vsz;
    char key[0];
‌} DataRecord;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;数据文件里面，每个 key 对应的数据的长度是 &lt;code&gt;4*6 + key_size + value_size + padding&lt;/code&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;read($fh, my $header, 4*6);
my ( $crc, $tstamp, $flag, $ver, $ksz, $vsz ) = unpack(&#39;I i i i I I&#39;, $header);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;头部是 24 个字节，依次包括校验数据，写入时间戳，标记位，版本号，key 的长度，value 的长度。上面 &lt;code&gt;unpack&lt;/code&gt; 方法第一个参数里面的含义，可以参考&lt;a href=&#34;http://perldoc.perl.org/functions/pack.html&#34;&gt;perl 的文档&lt;/a&gt;。每个 4 字节，32bit 整数。&lt;/p&gt;

&lt;p&gt;然后是读取 &lt;code&gt;$ksz&lt;/code&gt; 的长度的 key，读取 &lt;code&gt;$vsz&lt;/code&gt; 长度 value。如果 &lt;code&gt;$flag&lt;/code&gt; 标记表明 value 有压缩，压缩用的是 QLZ 算法，真实的值需要用 qlz 解压缩之后才能得到。&lt;/p&gt;

&lt;p&gt;最后是 padding 部分，整个数据长度需要是 256 的整数倍。不足的部分，会写入 &lt;code&gt;\0&lt;/code&gt; 做 padding。&lt;/p&gt;

&lt;p&gt;merge 的过程不关心 value 的真实值，所以不需要解压缩，把读取到的原样写回去就可以了。另外就是 merge 的时候遇到同一个 key 多个 version 出现的时候，只保留大的那个就可以了。这样操作之后 data 文件会变小。&lt;/p&gt;

&lt;h3 id=&#34;hint-文件&#34;&gt;hint 文件&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;‌typedef struct hint_record
{
    uint32_t ksize:8;
    uint32_t pos:24;
    int32_t version;
    uint16_t hash;
    char key[NAME_IN_RECORD]; // allign
‌} HintRecord;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;hint 文件比 data 文件稍微复杂一点，每一条记录是 &lt;code&gt;key_size + data_pos + ver + hash + key + padding&lt;/code&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;my ( $ksz, $datapos, $ver, $hash ) = unpack(&amp;quot;B8 B24 i B16&amp;quot;, $header);

$ksz = unpack(&amp;quot;I&amp;quot;, pack(&amp;quot;B32&amp;quot;, $ksz));
$datapos = unpack(&amp;quot;I&amp;quot;, pack(&amp;quot;B32&amp;quot;, $datapos));
$datapos = $datapos &amp;lt;&amp;lt; 8;
$hash = unpack(&amp;quot;I&amp;quot;, pack(&amp;quot;B32&amp;quot;, $hash));
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;头部的 10 个字节如上面代码，第一个 8 bit 是 key 的长度，接下来 24 个 bit 是这个 key 对应数据在 data 文件里面的位置。然后是 4 字节版本，16 bit 的 hash。&lt;/p&gt;

&lt;p&gt;padding 和上面 data 里面的逻辑一样，按照 256 的倍数补全。&lt;/p&gt;

&lt;p&gt;hint 文件结尾有个 &lt;code&gt;.qlz&lt;/code&gt;，表示整个 hint 里面的数据是压缩的，所以在处理前需要先解压缩一下。（不过我看到我代码里面在读取 hint 的时候，是全部数据解压，写入的时候，是按照 record 压缩的，很奇怪）。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Release some staff at github</title>
      <link>https://wdicc.com/release-some-staff-at-github/</link>
      <pubDate>Tue, 13 Dec 2016 17:00:31 +0800</pubDate>
      
      <guid>https://wdicc.com/release-some-staff-at-github/</guid>
      <description>&lt;p&gt;把 blog 用到的模板整理了一下，放到了 &lt;a href=&#34;https://github.com/wd/hexo-fabric&#34;&gt;https://github.com/wd/hexo-fabric&lt;/a&gt; ，这个最开始是 fork 别人的代码改的，后来发现原来那个人已经不用了，就整理一下，增加了一个 tag 支持，修改了一下字体和背景色，还有代码颜色等，都是一些小修改。同时也提交到了官方的 theme 库，不过 pull request 还没有通过。。&lt;/p&gt;

&lt;p&gt;另外，还把之前写的一个给 ngx-lua 用的一个使用 mcrypt 加密解密的库 &lt;a href=&#34;https://github.com/wd/lua-resty-mcrypt&#34;&gt;https://github.com/wd/lua-resty-mcrypt&lt;/a&gt; ，整理出来单独弄了一个模块。代码其实非常简单，这个也能看出来 ngx_lua 里面使用 ffi 调用 C 模块开发多舒服，不过因为 C 知识有限，可能还是会有一些问题，不过至少自己测试是 ok 的，也在线上跑了好久，只能遇到有问题的再说了。这个同时也提交到了春哥的 opm 仓库，那个倒没有审核，提交就被索引了，使用的话应该可以用 opm 命令直接安装。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Bloat and Query Speed in PostgreSQL</title>
      <link>https://wdicc.com/Bloat-and-Query-Speed-in-PostgreSQL/</link>
      <pubDate>Fri, 09 Dec 2016 12:12:21 +0800</pubDate>
      
      <guid>https://wdicc.com/Bloat-and-Query-Speed-in-PostgreSQL/</guid>
      <description>&lt;p&gt;内容反义自 &lt;a href=&#34;https://www.citusdata.com/blog/2016/11/04/autovacuum-not-the-enemy/&#34;&gt;https://www.citusdata.com/blog/2016/11/04/autovacuum-not-the-enemy/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;pg 的 mvcc 会导致表索引的 bloat 就不多说了。说一下不合理处理这种 bloat 害处是啥。&lt;/p&gt;

&lt;p&gt;首先肯定是会浪费空间。然后也会影响查询速度。表和索引存储的时候都是 8kB 一个 page，如果一个查询一些行，数据库会加载这些 pages 到内存。一个 page 里面的 dead rows 越多，在加载的时候就越浪费 I/O。例如全表扫描会加载所有的 dead rows。&lt;/p&gt;

&lt;p&gt;Bloat 还会导致热门的查询会一下塞满内存。会导致相同的 live rows 需要更多 pages。This causes swapping and makes certain query plans and algorithms ineligible for execution.&lt;/p&gt;

&lt;p&gt;还有一个影响是，pg 的系统表也会有可能 bloat，因为他们也是表。导致这个的一种情况是频繁的创建和删除临时表。这个进一步会导致一些管理命令执行变慢，甚至比如 &lt;code&gt;\d&lt;/code&gt; 这种命令。&lt;/p&gt;

&lt;p&gt;索引也有可能会 bloat。索引是 tuple 标识和数据之间的一个映射。这些标识指向的是某个 page 里面的 offset。每个 tuple 都是一个独立的对象，需要自己的索引条目。更新一行的时候总是会创建这行的新的索引条目。&lt;/p&gt;

&lt;p&gt;索引的 bloat 的影响比 table 小一点。索引里面指向 dead tuple 的可以直接标记为 dead. 这会使得索引膨胀，但是不会导致不必要的堆查找。同时更新堆中的 tuples 不影响已经索引的列，使用一种叫做 HOT 的技术来把指向 dead tuples 的指针指向新的。这允许查询可以通过这些指针复用旧的索引条目。(Also updates to tuples in the heap that do not affect the indexed column(s) use a technique called HOT to provide pointers from the dead tuple to its replacement. This allows queries to reuses old index entries by following pointers across the heap.) (没太看明白.)&lt;/p&gt;

&lt;p&gt;索引 bloat 的问题还是应该需要重视。例如 btree 索引是由二叉树组成()。叶子节点包含值和 tuple 标识（应该是指在 data file 的 offset）。随机更新因为会重用 page，所以可以保持 btree 维持一个良好的形状。但是，如果是单侧更新，会导致大量的空页。&lt;/p&gt;

&lt;p&gt;The size considerations of index bloat are still significant. For instance a btree index consists of binary tree of pages (the same sized pages as you find holding tuples in the heap). The leaf node pages contain values and tuple identifiers. Uniform random table updates tend to keep a btree index in pretty good shape because it can reuse pages. However lopsided inserts/updates affecting one side of the tree while preserving a few straggling entries can lead to lots of mostly empty pages.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Full page write in PostgreSQL</title>
      <link>https://wdicc.com/Full-page-write-in-PostgreSQL/</link>
      <pubDate>Thu, 08 Dec 2016 18:02:14 +0800</pubDate>
      
      <guid>https://wdicc.com/Full-page-write-in-PostgreSQL/</guid>
      <description>

&lt;p&gt;读了一篇&lt;a href=&#34;http://blog.2ndquadrant.com/on-the-impact-of-full-page-writes/&#34;&gt;文章&lt;/a&gt;，简单翻译总结下。&lt;/p&gt;

&lt;h2 id=&#34;partial-writes-torn-pages&#34;&gt;Partial Writes / Torn Pages&lt;/h2&gt;

&lt;p&gt;pg 默认是 8kB 一个 page。linux 文件系统一般是 4kB（x86 里面最大是 4kB)，老设备驱动一般是 512B 一个扇区，新的设备有些支持 4kB 或者 8kB。&lt;/p&gt;

&lt;p&gt;当 pg 写入一个 page 8kB 的时候，系统的底层会拆分小一点块，这里涉及到写入的原子性。8kB 的 pg page，会被文件系统拆分成 4kB 的块，然后拆分成 512B 扇区大小。这个时候如果系统崩溃（比如停电，内核 bug）会发生什么？&lt;/p&gt;

&lt;p&gt;即使系统的存储有针对这种情况的设计（比如 SSD 自带电容器，RAID 控制器自带电池），内核那块也是会拆分成 4kB 的 page，所以还是有一定可能性，pg 写了 8kB，但是只有部分写入成功。&lt;/p&gt;

&lt;p&gt;这个时候你可能意识到这就是为啥我们要有事务日志（WAL）。所以当系统崩溃重启之后，数据库会读取 WAL（从最后一次 checkpoint），然后重新写入一遍，以保证数据文件是完整的。&lt;/p&gt;

&lt;p&gt;恢复的时候，在修改一个 page 之前，还是会读取一下。&lt;/p&gt;

&lt;p&gt;在 checkpoint 之后第一次修改一个 page 的时候，会把整个 page 写入 WAL。这是为了保证在恢复的时候，能保证这些被修改的 page 能完全恢复到他原有的样子。&lt;/p&gt;

&lt;h2 id=&#34;写放大&#34;&gt;写放大&lt;/h2&gt;

&lt;p&gt;如果打开 Full page write，很显然会导致 WAL 文件增加，因为就算修改一个字节，也会导致 8kB page 的写入。因为 Full page write 只发生在 checkpoint 之后的第一次写入，所以减少 checkpoint 的发生频率是可以减少写入的。&lt;/p&gt;

&lt;h2 id=&#34;uuid-vs-bigserial-主键&#34;&gt;UUID vs BIGSERIAL 主键&lt;/h2&gt;

&lt;p&gt;比较了一下使用 UUID 或者 bigserial 做主键对写入的影响。可以看原链接的图，会发现在 INSERT 语句的情况下 UUID 产生的 WAL 文件量比较多。主要原因是 Btree 索引的情况下，bigserial 是顺序的维护这个索引，UUID 是无顺序的，会导致维护索引产生的数据量不同。&lt;/p&gt;

&lt;p&gt;如果是使用 UPDATE 随机修改，那么会发现产生的 WAL 数量就差不多了。&lt;/p&gt;

&lt;h2 id=&#34;8kb-and-4kb-pages&#34;&gt;8kB and 4kB pages&lt;/h2&gt;

&lt;p&gt;如果减小 pg 的 page 的大小，可以减小 WAL 数量。从 8kB 减小到 4kB，上面 UUID 那个例子，可以减少大概 35% 的量。&lt;/p&gt;

&lt;h2 id=&#34;需要-full-page-write-吗&#34;&gt;需要 full-page write 吗？&lt;/h2&gt;

&lt;p&gt;首先，这个参数是 2005 年 pg 8.1 引入的，那么现代的文件系统是不是已经不用操心部分写入的情况了？作者尝试了一些测试没有测试出来部分写入的情况，当然这不表示不会存在。但是就算是存在，数据的一致性校验也会是有效的保护（虽然并不能修复这个问题，但是至少能让你知道有坏的 page）&lt;/p&gt;

&lt;p&gt;其次，现在很多系统都依赖于流式同步，并不会等着有问题的服务器在有硬件问题的时候重启，并且花费很多时间恢复，一般都直接切换到热备服务器上面了。这个时候部分写就不是什么问题了。但是如果我们都推荐这么做，那么「我也不知道为啥数据损坏了，我只是设置了 full_page_writes=off」这种会是 DBA 死前最常见的言论了。(类似于「这种蛇我之前在 reddit 看见过，无毒的」)&lt;/p&gt;

&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;

&lt;p&gt;对于 full-page write 你没法直接优化。大部分情况下，full-page write 都是发生在 checkpoint 之后，直到下一次 checkpoint。所以调整 checkpoint 的发生频率不要太频繁很重要。&lt;/p&gt;

&lt;p&gt;有些应用层的操作，可能会导致对表或者索引的随机写入的增加，例如上面的 UUID 的值就是随机的，会让简单的 INSERT 也会导致索引的随机 update。使用 Bigserial 做主键(让 UUID 做替代键)可以减少写放大。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>使用 pgrepup 跨版本升级 pg</title>
      <link>https://wdicc.com/use-pgrepup-to-upgrade-your-postgres/</link>
      <pubDate>Thu, 08 Dec 2016 11:55:33 +0800</pubDate>
      
      <guid>https://wdicc.com/use-pgrepup-to-upgrade-your-postgres/</guid>
      <description>

&lt;p&gt;&lt;a href=&#34;http://gasparin.net/2016/11/pgrepup-upgrade-postgresql-using-logical-replication/&#34;&gt;pgrepup&lt;/a&gt; 其实是一个支持 pg 跨版本复制的工具。而 pg 大版本升级需要停机是个比较郁闷的事情，如果能通过这个解决就实在太好了。下面测试了一下。&lt;/p&gt;

&lt;h2 id=&#34;安装&#34;&gt;安装&lt;/h2&gt;

&lt;p&gt;需要安装 &lt;code&gt;pgrepup&lt;/code&gt; 和 &lt;code&gt;pglogical&lt;/code&gt;。&lt;/p&gt;

&lt;h3 id=&#34;安装-pgrepup&#34;&gt;安装 pgrepup&lt;/h3&gt;

&lt;p&gt;pgrepup 官方说是支持 python &amp;gt;= 2.7 的版本，我自己测试的结果，python 3.5 里面执行有点问题，需要修改几个地方。但是在 python 2.7 里面，不需要做任何修改，所以建议使用 python 2.7。安装很简单，执行 &lt;code&gt;pip install pgprepup&lt;/code&gt; 就可以了。&lt;/p&gt;

&lt;h3 id=&#34;安装-pglogical&#34;&gt;安装 pglogical&lt;/h3&gt;

&lt;p&gt;需要给你的 pg 安装这个扩展。高版本的和低版本的都需要安装。&lt;/p&gt;

&lt;p&gt;安装也很简单，下载源码，执行 &lt;code&gt;PATH=/opt/pg96/bin:$PATH make USE_PGXS=1 install&lt;/code&gt; 就好了。如果是给 pg95 装，那就把路径改成 pg95。&lt;/p&gt;

&lt;p&gt;可以参考&lt;a href=&#34;https://2ndquadrant.com/it/resources/pglogical/pglogical-installation-instructions/&#34;&gt;这里&lt;/a&gt;。&lt;/p&gt;

&lt;h2 id=&#34;配置&#34;&gt;配置&lt;/h2&gt;

&lt;h3 id=&#34;配置-db&#34;&gt;配置 db&lt;/h3&gt;

&lt;p&gt;先给几个 db 定义一下角色。db1 假设为 9.5 版本，db2 假设为 9.6 版本。&lt;/p&gt;

&lt;p&gt;pgrepup 允许 db1, db2 和执行 pgrepup 所在的机器分别在不同的机器，也可以在相同的机器，看机器情况。&lt;/p&gt;

&lt;p&gt;对于 db，最小配置的 postgres.conf 修改如下，我测试的时候两个 db 在一台机器上面，只需要修改 port 不一样就可以了。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;listen_addresses = &#39;*&#39;          # what IP address(es) to listen on;
port = 5495
wal_level = logical # minimal, archive, hot_standby, or logical
max_wal_senders = 3             # max number of walsender processes
max_replication_slots = 3       # max number of replication slots
shared_preload_libraries = &#39;pglogical&#39;          # (change requires restart)

## 下面几个参数不是必须设置的
logging_collector = on          # Enable capturing of stderr and csvlog
log_filename = &#39;postgresql-%Y-%m-%d.log&#39;        # log file name pattern,
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;pg_hba.conf 如下，修改其中的 client_ip 和 db_ip 为对应的真实 ip。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;host all all client_ip/32 md5
host replication pgrepup_replication db_ip/32 md5
host all pgrepup_replication db_ip/32 md5
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;配置好之后，启动 db1 和 db2 看看是不是可以正常连接。&lt;/p&gt;

&lt;p&gt;还需要建立用户。如果已经存在一个 super 的用户，那也可以直接用那个用户，没有的话，就建一个。db1 和 db2 都需要建立，可以是不同的用户。&lt;/p&gt;

&lt;h4 id=&#34;hint&#34;&gt;hint&lt;/h4&gt;

&lt;p&gt;当然，如果我们在生产环境里面做这个事情，那肯定会是 db1 已经是一个存在的 db，只需要增加原来没有的配置就好了。db2 会是一个全新的 db，使用 initdb 初始化，之后配置上面的配置项（当然，如果是将来要给生产用，那应该是复制 db1 的配置文件过来，修改端口就可以了，其他都一样）。&lt;/p&gt;

&lt;h3 id=&#34;配置-pgrepup&#34;&gt;配置 pgrepup&lt;/h3&gt;

&lt;p&gt;执行一下 &lt;code&gt;pgrepup config&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;❯❯❯ pgrepup config
Pgrepup 0.3.7
Create a new pgrepup config
Configuration filename [~/.pgrepup] ./pgrepup.config
Security
Do you want to encrypt database credentials using a password? [Y/n] n
Folder where pgrepup store temporary dumps and pgpass file [/tmp] ./tmp
Source Database configuration
Ip address or Dns name: db_ip
Port: 5495
Connect Database: [template1]
Username: wd
Password:
Destination Database configuration
Ip address or Dns name: db_ip
Port: 5496
Connect Database: [template1]
Username: wd
Password:
Configuration saved to ./pgrepup.config.
You can now use the check command to verify setup of source and destination databases
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;之后会产生一个配置文件 pgrepup.config，有修改的话，可以打开再次编辑。&lt;/p&gt;

&lt;p&gt;之后，可以执行一下 &lt;code&gt;pgrepup check&lt;/code&gt; 来检查一下&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;❯❯❯ pgrepup -c pgrepup.config check
Pgrepup 0.3.7
Global checkings...
 &amp;gt;  Folder ./tmp exists and is writable ..........................................OK
Checking Source...
 &amp;gt;  Connection PostgreSQL connection to db_ip:5495 with user wd OK
 &amp;gt;  pglogical installation .......................................................KO

    Hint: Install docs at https://2ndquadrant.com/it/resources/pglogical/pglogical-installation-instructions/

 &amp;gt;  Needed wal_level setting .....................................................OK
 &amp;gt;  Needed max_worker_processes setting ..........................................OK
 &amp;gt;  Needed max_replication_slots setting .........................................OK
 &amp;gt;  Needed max_wal_senders setting ...............................................OK
 &amp;gt;  pg_hba.conf settings .........................................................KO
    Hint: Add the following lines to /home/wd/data95/pg_hba.conf:
        host replication pgrepup_replication db_ip/32 md5
        host all pgrepup_replication db_ip/32 md5
    After adding the lines, remember to reload postgreSQL
 &amp;gt;  Local pg_dumpall version .....................................................OK
 &amp;gt;  Source cluster tables without primary keys
 &amp;gt;      template1 ................................................................OK
 &amp;gt;      testdb
 &amp;gt;          public.t1 ............................................................OK
 &amp;gt;      postgres .................................................................OK
Checking Destination...
 &amp;gt;  Connection PostgreSQL connection to db_ip:5496 with user wd OK
 &amp;gt;  pglogical installation .......................................................KO

    Hint: Install docs at https://2ndquadrant.com/it/resources/pglogical/pglogical-installation-instructions/

 &amp;gt;  Needed wal_level setting .....................................................KO
    Hint: Set wal_level to logical
 &amp;gt;  Needed max_worker_processes setting ..........................................OK
 &amp;gt;  Needed max_replication_slots setting .........................................KO
    Hint: Increase max_replication_slots to 3
 &amp;gt;  Needed max_wal_senders setting ...............................................OK
 &amp;gt;  pg_hba.conf settings .........................................................KO
    Hint: Add the following lines to /home/wd/data96/pg_hba.conf:
        host replication pgrepup_replication db_ip/32 md5
        host all pgrepup_replication db_ip/32 md5
    After adding the lines, remember to reload postgreSQL
 &amp;gt;  Local pg_dumpall version .....................................................OK
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上面是我第一次执行 check 的结果，可以看到很多红色的 &lt;code&gt;KO&lt;/code&gt;，有些下面还有 hint 提示告诉你怎么修复，针对红色的信息进行修复就好了。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;❯❯❯ pgrepup -c pgrepup.config check
Pgrepup 0.3.7
Global checkings...
 &amp;gt;  Folder ./tmp exists and is writable ..........................................OK
Checking Source...
 &amp;gt;  Connection PostgreSQL connection to db_ip:5495 with user wd ...OK
 &amp;gt;  pglogical installation .......................................................OK
 &amp;gt;  Needed wal_level setting .....................................................OK
 &amp;gt;  Needed max_worker_processes setting ..........................................OK
 &amp;gt;  Needed max_replication_slots setting .........................................OK
 &amp;gt;  Needed max_wal_senders setting ...............................................OK
 &amp;gt;  pg_hba.conf settings .........................................................OK
 &amp;gt;  Local pg_dumpall version .....................................................OK
 &amp;gt;  Source cluster tables without primary keys
 &amp;gt;      template1 ................................................................OK
 &amp;gt;      testdb
 &amp;gt;          public.t1 ............................................................OK
 &amp;gt;      postgres .................................................................OK
Checking Destination...
 &amp;gt;  Connection PostgreSQL connection to db_ip:5496 with user wd ...OK
 &amp;gt;  pglogical installation .......................................................OK
 &amp;gt;  Needed wal_level setting .....................................................OK
 &amp;gt;  Needed max_worker_processes setting ..........................................OK
 &amp;gt;  Needed max_replication_slots setting .........................................OK
 &amp;gt;  Needed max_wal_senders setting ...............................................OK
 &amp;gt;  pg_hba.conf settings .........................................................OK
 &amp;gt;  Local pg_dumpall version .....................................................OK
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上面是我修复之后执行的结果。其中会提示会被同步的 db（上面是 template1, testdb, postgres）。之后执行 setup&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;❯❯❯ pgrepup -c pgrepup.config setup
Pgrepup 0.3.7
Check if there are active subscriptions in Destination nodes .....................OK
Global tasks
 &amp;gt;  Remove nodes from Destination cluster
 &amp;gt;      postgres .................................................................OK
 &amp;gt;      template1 ................................................................OK
 &amp;gt;      testdb ...................................................................OK
 &amp;gt;  Create temp pgpass file ......................................................OK
 &amp;gt;  Drop pg_logical extension in all databases of Source cluster
 &amp;gt;      template1 ................................................................OK
 &amp;gt;      postgres .................................................................OK
 &amp;gt;      testdb ...................................................................OK
 &amp;gt;  Drop pg_logical extension in all databases of Destination cluster
 &amp;gt;      postgres .................................................................OK
 &amp;gt;      template1 ................................................................OK
 &amp;gt;      testdb ...................................................................OK
Setup Source
 &amp;gt;  Create user for replication ..................................................OK
 &amp;gt;  Dump globals and schema of all databases .....................................OK
 &amp;gt;  Setup pglogical replication sets on Source node name
 &amp;gt;      template1 ................................................................OK
 &amp;gt;      postgres .................................................................OK
 &amp;gt;      testdb ...................................................................OK
Setup Destination
 &amp;gt;  Create and import source globals and schema ..................................OK
 &amp;gt;  Setup pglogical Destination node name
 &amp;gt;      postgres .................................................................OK
 &amp;gt;      testdb ...................................................................OK
 &amp;gt;      template1 ................................................................OK
Cleaning up
 &amp;gt;  Remove temporary pgpass file .................................................OK
 &amp;gt;  Remove other temporary files .................................................OK
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后执行 start&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;❯❯❯ pgrepup -c pgrepup.config start
Pgrepup 0.3.7
Start replication and upgrade
 &amp;gt;  postgres .................................................................OK
 &amp;gt;  template1 ................................................................OK
 &amp;gt;  testdb ...................................................................OK
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以通过 status 看同步状态&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;❯❯❯ pgrepup -c pgrepup.config status
Pgrepup 0.3.7
Configuration
 &amp;gt;  Source database cluster ......................................................OK
 &amp;gt;  Destination database cluster .................................................OK
Pglogical setup
 &amp;gt;  Source database cluster
 &amp;gt;      template1 ................................................................OK
 &amp;gt;      postgres .................................................................OK
 &amp;gt;      testdb ...................................................................OK
 &amp;gt;  Destination database cluster
 &amp;gt;      postgres .................................................................OK
 &amp;gt;      testdb ...................................................................OK
 &amp;gt;      template1 ................................................................OK
Replication status
 &amp;gt;  Database postgres
 &amp;gt;      Replication status ..............................................replicating
 &amp;gt;  Database testdb
 &amp;gt;      Replication status ..............................................replicating
 &amp;gt;  Database template1
 &amp;gt;      Replication status ..............................................replicating
 &amp;gt;  Xlog difference (bytes) ...................................................57816
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看到三个 db 都在同步。这个时候在 db1 上面插入数据，能在 db2 上面看到会同步过去。&lt;/p&gt;

&lt;p&gt;状态有三种情况
* initializing: pglogical 正在 copy 数据
* replication: 同步状态
* down: 同步断开了，需要检查日志修复&lt;/p&gt;

&lt;h2 id=&#34;需要注意的问题&#34;&gt;需要注意的问题&lt;/h2&gt;

&lt;h3 id=&#34;db-里面的表都需要有主键&#34;&gt;db 里面的表都需要有主键&lt;/h3&gt;

&lt;p&gt;如果存在没有主键的表，执行 check 的时候会看到下面的信息&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; &amp;gt;  Source cluster tables without primary keys
 &amp;gt;      template1 ................................................................OK
 &amp;gt;      testdb
 &amp;gt;          public.t2 ............................................................KO
    Hint: Add a primary key or unique index or use the pgrepup fix command
 &amp;gt;          public.t1 ............................................................OK
 &amp;gt;      postgres .................................................................OK
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果不解决就执行 setup，会提示下面的信息&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Setup Source ........................................Skipped, configuration problems
Setup Destination
 &amp;gt;  Create and import source globals and schema .............................Skipped
 &amp;gt;  Setup pglogical Destination node name
 &amp;gt;      postgres .................................................................OK
 &amp;gt;      template1 ................................................................OK
 &amp;gt;      testdb ...................................................................OK
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以自己创建一个主键重新 check，也可以执行 fix 来修复，然后再次执行 setup。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; ❯❯❯ pgrepup -c pgrepup.config fix
Pgrepup 0.3.7
Find Source cluster&#39;s databases with tables without primary key/unique index...
 &amp;gt;  template1 ....................................................................OK
 &amp;gt;  postgres .....................................................................OK
 &amp;gt;  testdb
 &amp;gt;      Found public.t2 without primary key ................Added __pgrepup_id field
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;通过 fix 加的主键，在 uninstall 的时候会被删除。&lt;/p&gt;

&lt;h3 id=&#34;replication-status-down&#34;&gt;Replication status .. down&lt;/h3&gt;

&lt;p&gt;有时候会遇到有的 db 的状态是好的，有的 db 是 down 的情况&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Replication status
 &amp;gt;  Database postgres
 &amp;gt;      Replication status ..............................................replicating
 &amp;gt;  Database testdb
 &amp;gt;      Replication status .....................................................down
 &amp;gt;  Database template1
 &amp;gt;      Replication status ..............................................replicating
 &amp;gt;  Xlog difference (bytes) ..................................................614096
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在同步状态下面，如果给某个 db 加一个没有主键的表，就会导致同步断掉。修复方法是先 stop，然后执行 check，按照提示修复，然后执行 setup，然后 start 就可以了。&lt;/p&gt;

&lt;h3 id=&#34;官方列出来的几个问题&#34;&gt;官方列出来的几个问题&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;DDL 命令。不会同步 DDL 命令，可以在 db1 试试看 &lt;code&gt;pglogical.replicate_ddl_command&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;seq 序列。执行 stop 命令的时候，会在目标 db 的 seq 上面加 1000。&lt;/li&gt;
&lt;li&gt;有大量的 db。执行 start 命令之后，pglogical 会每个 db 启动一个 worker 来同步数据，要是 db 比较多会导致比较高的负载。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;因为这个是基于 pglogical 的，所以还需要关注 pglogical 列出来的一些&lt;a href=&#34;https://2ndquadrant.com/it/resources/pglogical/pglogical-docs/&#34;&gt;限制&lt;/a&gt; 第 4 部分 Limitations and Restrictions。
* 4.1 Superuser is required
* 4.2 UNLOGGED and TEMPORARY not replicated
* 4.3 One database at a time
* 4.4 PRIMARY KEY or REPLICA IDENTITY required
* 4.5 Only one unique index/constraint/PK
* 4.6 DDL
* 4.7 No replication queue flush
* 4.8 FOREIGN KEYS
* 4.9 TRUNCATE
* 4.10 Sequences
* 4.11 Triggers
* 4.12 PostgreSQL Version differences
* 4.13 Doesn&amp;rsquo;t replicate DDL&lt;/p&gt;

&lt;h3 id=&#34;pgrepup-uninstall&#34;&gt;pgrepup uninstall&lt;/h3&gt;

&lt;p&gt;uninstall 会清理 pgrepup 创建的一些信息，比如安装的 pglogical 扩展，创建用来同步的用户，和通过 fix 命令添加的 seq。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;❯❯❯ pgrepup -c pgrepup.config uninstall
Pgrepup 0.3.7
Check active subscriptions in Destination nodes
 &amp;gt;  template1 ...............................................................Stopped
 &amp;gt;  testdb ..................................................................Stopped
 &amp;gt;  postgres ................................................................Stopped
Uninstall operations
 &amp;gt;  Remove nodes from Destination cluster
 &amp;gt;      postgres .................................................................OK
 &amp;gt;      testdb ...................................................................OK
 &amp;gt;      template1 ................................................................OK
 &amp;gt;  Drop pg_logical extension in all databases
 &amp;gt;      Source
 &amp;gt;          template1 ............................................................OK
 &amp;gt;          postgres .............................................................OK
 &amp;gt;          testdb ...............................................................OK
 &amp;gt;      Destination
 &amp;gt;          postgres .............................................................OK
 &amp;gt;          testdb ...............................................................OK
 &amp;gt;          template1 ............................................................OK
 &amp;gt;  Drop user for replication ....................................................OK
 &amp;gt;  Drop unique fields added by fix command
 &amp;gt;          template1
 &amp;gt;          postgres
 &amp;gt;          testdb
 &amp;gt;              public.t1 ........................................................OK
 &amp;gt;              public.t2 ........................................................OK
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;升级&#34;&gt;升级&lt;/h2&gt;

&lt;p&gt;如果前面配置好了同步状态，那剩下的事情就简单了。
* 停止应用链接 db1
* 确保 db1 已经没有任何链接
* 使用 &lt;code&gt;pgrepup stop&lt;/code&gt; 停止 replication
* 修改应用链接到 db2
* 启动应用
* 剩下的就是处理掉停止的 db1&lt;/p&gt;

&lt;h2 id=&#34;参考文档&#34;&gt;参考文档&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://qiita.com/yteraoka/items/e82e4d28f6a23915d190&#34;&gt;http://qiita.com/yteraoka/items/e82e4d28f6a23915d190&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Built in sharding in PostgreSQL</title>
      <link>https://wdicc.com/Built-in-sharding-in-PostgreSQL/</link>
      <pubDate>Wed, 07 Dec 2016 16:54:59 +0800</pubDate>
      
      <guid>https://wdicc.com/Built-in-sharding-in-PostgreSQL/</guid>
      <description>

&lt;p&gt;PostgreSQL 内建 sharding 支持，粗略翻译自 &lt;a href=&#34;https://wiki.postgresql.org/wiki/Built-in_Sharding&#34;&gt;https://wiki.postgresql.org/wiki/Built-in_Sharding&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;内建支持 sharding 最大的挑战是，如何用最小的代码修改实现。大部分社区的 sharding 修改支持都修改了很多 PostgreSQL 的代码，这也导致这些不能被 Postgres 社区那些不需要 sharding 的人接受。有了 FDW 之后，就有了在有限代码修改情况下实现内建 sharding 支持的可能。&lt;/p&gt;

&lt;p&gt;基于 FDW 的这种 sharding 设计，是基于 NTT 开发的 Postgres-XC，大概已经有 10 年了。Postgres-XL 是基于这个设计的一种更加灵活的实现。&lt;/p&gt;

&lt;h2 id=&#34;enhance-existing-features&#34;&gt;Enhance Existing Features&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;已完成？提升 FDW 的基础设计和 postgres_fdw。特别的，好的性能要求合理的把一些操作推送到子节点(foreign shards)。在 Postgres 9.6 中，join, sort, update, delete 都可以推送到字节点了。聚合的 pushdown 将在 Postgres 10 中支持。FDW 表已经可以作为继承表出现。&lt;/li&gt;
&lt;li&gt;提升分区支持有效提升 existence of shards。幸运的是，单节点的分区支持也需要重构才能提升性能和更多优化。例如，executor-based partition pruning.&lt;/li&gt;
&lt;li&gt;给 FDW 请求增加并行支持。这样能允许节点并行执行，这个可能会通过多个异步的链接来实现。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;new-subsystems&#34;&gt;New Subsystems&lt;/h2&gt;

&lt;p&gt;还需要开发一些子系统：
* 允许表可以复制到所有节点，以允许更多的 join pushdown。这个可以通过 trigger 或者逻辑复制来完成。
* 实现一个子模块，以使用新的分区系统表来提交符合提交的查询的 FDW 查询。
* 实现一个子模块收集 FDW 查询的结果返回给用户。
* 实现全局事务管理器以便更加高效的允许子节点原子的提交事务。这个可能会通过 prepared 的事务来实现，还有某种在 crash 之后清理那些 preapared 的事务的事务管理器。例如 XA。
* 实现全局快照管理器，以允许子节点可以看到一致性的快照。（是不是 serialisable 事务模式会避免跨节点快照冲突？pg_export_snapshot() 或者 hot_standby_feedback 是不是会有帮助？) 多节点的备份的一致性也需要这个支持。
* 实现支持 create, manage, report on shards 这些用户 API。&lt;/p&gt;

&lt;h2 id=&#34;use-cases&#34;&gt;Use Cases&lt;/h2&gt;

&lt;p&gt;有四种可能的用户案例和不同的需求:
* 跨节点在只读节点上面执行只读聚合查询，例如数据仓库
  这种是最简单的场景，不需要全局事务管理，全局快照管理，并且因为聚合，所以子节点返回的数据量也是最小的。
* 跨节点在只读节点上面执行只读非聚合查询
  这种会给调度节点压力，需要收集和处理很多子节点返回的数据。这种也能看到 FDW 传输机制等级。
* 跨节点在可读写节点执行只读查询
  这个需要全局快照管理来保证子节点返回数据的一致性
* 跨节点执行读写查询
  这个需要全局快照管理器和全局事务管理器&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>申请 google voice</title>
      <link>https://wdicc.com/registration-about-google-voice/</link>
      <pubDate>Mon, 14 Nov 2016 16:02:30 +0800</pubDate>
      
      <guid>https://wdicc.com/registration-about-google-voice/</guid>
      <description>&lt;p&gt;昨天晚上突然想申请一个 google voice 帐号。有了之后就可以作为国外的号码使用了，可以打电话收短信，想想好像还有点用。比如我就可以用他注册一个微博帐号用来关联一些无聊的服务了。。。&lt;/p&gt;

&lt;p&gt;申请的过程网上很多，不细说了。主要注意下面几点。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;需要美国 ip 打开 &lt;a href=&#34;https://www.google.com/voice&#34;&gt;https://www.google.com/voice&lt;/a&gt; ，否则会跳转到一个帮助页面。这个从网上搜一些免费的代理就可以了。我是搜索到了一些 ss 帐号，然后配合 surge 来做的。&lt;/li&gt;
&lt;li&gt;需要一个能接电话的美国号码来接受 google voice 的验证电话。这个我是通过 &lt;a href=&#34;http://textnow.com&#34;&gt;http://textnow.com&lt;/a&gt; 来做的。登录 textnow.com 注册一个免费的帐号，其中有一步是需要输入一个美国区号，这个要注意，我第一次注册的时候，输入的是 213 (洛杉矶地区的)，然后就不行，后来又申请了一个 517 的就可以。所以最好搜索一下别人申请成功的区号有哪些，另外还好就是只要有不同的邮箱，就可以多次注册来换号码，如果遇到不行的，可以换个邮箱重新注册一下。&lt;/li&gt;
&lt;li&gt;在 google voice 里面填入电话之后。google voice 会打电话给那个号码。我用 textnow 的 ios 客户端接的电话（建议不要用他们的 web，他们的 web 必须要你的浏览器支持 flash 才行，很恶心），我遇到的情况下，前几次接到的电话没有对方的声音，自己尝试直接输入号码也不行。后来多试几次就好了。&lt;/li&gt;
&lt;li&gt;后面就是选号了。选好号码之后，点提交一般都会遇到一个错误，「There was an error with your request. Please try again」, 遇到这个是正常的。需要你多次点击那个按钮提交，有人用按键精灵点了几个小时搞定了。我这是打开 chrome 的 dev tools，然后看 network 里面发的请求，每次点击都会有一个 post 请求，在上面按右键，选择 「copy as curl」，然后在命令行写一个简单的程序，&lt;code&gt;while true; do 这里把复制的内容贴过来 ;sleep 1.5s; done&lt;/code&gt;，复制到命令行，不停的重试就可以了，直到收到邮件说你的号码开通了。要注意的是命令行也得设置代理，一般是通过 export。&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>新与旧</title>
      <link>https://wdicc.com/new-and-old/</link>
      <pubDate>Sun, 13 Nov 2016 13:39:18 +0800</pubDate>
      
      <guid>https://wdicc.com/new-and-old/</guid>
      <description>&lt;p&gt;北京有个古北水镇，运营上据说是杭州乌镇的那拨人。乌镇没去过，去过古北水镇。在一片山里面，长城下面，一群建筑。里面还开了一些模仿古代的商店，比如酒家，染坊这些可以参观。&lt;/p&gt;

&lt;p&gt;这个地方离北京大概是 2 个多小时的车程（全程高速不怎么堵车的情况下）。周末过去之后会发现停车场停满了车，还有好多旅游车，水镇上面也人山人海。&lt;/p&gt;

&lt;p&gt;这里面的建筑都是后期开发商人工开辟的。景区里面的酒店基本都是1k起，并且还得提前预约。据说夜景很漂亮，不过我没看过。&lt;/p&gt;

&lt;p&gt;北京是个古老的城市，如果城区里面的历史建筑都留着，现在可够你转几个月的，光就绕着北京城墙走一圈，估计一天都不一定可以。曾经在西安的城墙上面走过一圈，感觉还不错，我记得还收了门票的。&lt;/p&gt;

&lt;p&gt;北京有个南锣鼓巷，过去转你会发现并没有什么能让你理解回味京味的东西，卖的也是羊肉串奶茶这些，排好长的队买一串拿着边吃边走完了，其实可能也挺没意思的。&lt;/p&gt;

&lt;p&gt;都说台湾是中华传统保持比较好的地方。去了台北第一印象就是，破房子挺多的。那边房子是私产，所以拆迁很难。然后个人又不一定有能力翻盖，所以就有破烂的房子。给我们开车的台湾人还说去过北京，说羡慕那边的高楼大厦，到处都很新，很时髦的样子。&lt;/p&gt;

&lt;p&gt;台湾有很多夜市，去过几个，有的比较商业化的，你会发现周边也都是高楼了。有的就是普通的，真的是一条路白天行车，晚上就堵起来开始摆摊。我记得某个夜市里面有个摊位，说是开了好多年了，现在物价高，不得已只好比早年涨了几毛钱。看着都震惊了，涨几毛钱还废什么话，况且本身人家卖的也不贵，都是良心价。&lt;/p&gt;

&lt;p&gt;地价涨没那么快，可能各种基础花费都会比较稳定，否则地价涨了房租涨了，那物价必定会涨。所以10年前我在北京长椿街那上班的时候，一份盖饭，大概是 7，8 块钱。到了现在，估计是翻一倍。另外这种店还越来越少，因为卫生条件，房租这些要求导致价格底了不好赚钱。&lt;/p&gt;

&lt;p&gt;台湾夜市里面也经常能碰见那种几十年的老店，那真的是几十年一直在做那个生意。几十年价格也没有变化太多。想起来前门的那个面馆前段时间关门了，没有办法，涨价没法涨，收入基本不变的情况下，地价变化太大，只好关门了。&lt;/p&gt;

&lt;p&gt;就目前这个房地产的情况，北京还能有多少真正的老字号，有多少真正的老街，估计基本不会有了。后面估计会有更加多人工的景区了，费用估计还不能便宜了。&lt;/p&gt;

&lt;p&gt;想起来凤凰古城了，大家不愿意拆，那就某天一把火烧了，这下都同意了吧，这可是天意。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>python 的 decorator 学习</title>
      <link>https://wdicc.com/decorator-in-python/</link>
      <pubDate>Fri, 21 Oct 2016 18:50:59 +0800</pubDate>
      
      <guid>https://wdicc.com/decorator-in-python/</guid>
      <description>&lt;p&gt;最近学习了一下 python 的 decorator（装饰器），看的是这篇，&lt;a href=&#34;http://coolshell.cn/articles/11265.html&#34;&gt;Python修饰器的函数式编程&lt;/a&gt;， 觉得挺有意思的，写点东西记录一下。&lt;/p&gt;

&lt;p&gt;装饰器简单讲就是返回一个函数的函数/类。看个简单的例子。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#!/usr/bin/python
# -*- coding: utf-8 -*-


def dec1(fn):
    print(&#39;inside dec1&#39;)

    def wrapper():
        print(&#39;inside wrapper&#39;)
        return fn()
    return wrapper


@dec1
def f1():
    print(&#39;inside f1&#39;)

if __name__ == &#39;__main__&#39;:
    print(&#39;begin exec&#39;)
    f1()
    print(&#39;end exec&#39;)

# 执行结果:
# inside dec1
# begin exec
# inside wrapper
# inside f1
# end exec
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;看上面例子能看到，装饰器生效有 2 个步骤，第一个是装饰，第二个是执行。上面装饰器的效果，和下面的代码的效果是一样。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#!/usr/bin/python
# -*- coding: utf-8 -*-


def dec1(fn):
    print(&#39;inside dec1&#39;)

    def wrapper():
        print(&#39;inside wrapper&#39;)
        return fn()
    return wrapper


# @dec1
def f1():
    print(&#39;inside f1&#39;)

if __name__ == &#39;__main__&#39;:
    print(&#39;begin exec&#39;)
    dec1(f1)()
    print(&#39;end exec&#39;)

# 执行结果:
# begin exec
# inside dec1
# inside wrapper
# inside f1
# end exec
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看到除了 「begin/end exec」，其他部分执行结果是一样的。所以理解装饰器，就把 &lt;code&gt;@dec1&lt;/code&gt; 换成 &lt;code&gt;dec1(fn)()&lt;/code&gt; 这么理解就可以了。&lt;/p&gt;

&lt;p&gt;有时候会看到类也可以作为装饰器使用。其实理解起来也类似。举个例子。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#!/usr/bin/python
# -*- coding: utf-8 -*-


class dec1(object):
    def __init__(self, fn):
        print(&#39;inside dec1&#39;)
        self.fn = fn

    def __call__(self):
        print(&#39;inside wrapper&#39;)
        return self.fn()


@dec1
def f1():
    print(&#39;inside f1&#39;)

if __name__ == &#39;__main__&#39;:
    print(&#39;begin exec&#39;)
    f1()
    print(&#39;end exec&#39;)

# 执行结果:
# inside dec1
# begin exec
# inside wrapper
# inside f1
# end exec
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里和上面类似，把 &lt;code&gt;@dec1&lt;/code&gt; 理解成 &lt;code&gt;dec1(fn)()&lt;/code&gt;，不过是这里的 &lt;code&gt;dec1&lt;/code&gt; 是个类，那么 &lt;code&gt;dec1(fn)&lt;/code&gt; 其实是调用的 &lt;code&gt;dec1.__init__(fn)&lt;/code&gt;，那么后续的 &lt;code&gt;dec1(fn)()&lt;/code&gt; 就是调用产生的对象的 &lt;code&gt;dec1.__call__()&lt;/code&gt; 了。&lt;/p&gt;

&lt;p&gt;有时候还能看到加了参数的装饰器。加了参数的是怎么回事呢。再看下面的例子。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#!/usr/bin/python
# -*- coding: utf-8 -*-


def dec1(name):
    print(&#39;inside dec1&#39;)

    def real_dec1(fn):
        def wrapper():
            print(&#39;inside wrapper&#39;)
            return fn()
        return wrapper
    return real_dec1


@dec1(name=&#39;1&#39;)
def f1():
    print(&#39;inside f1&#39;)

if __name__ == &#39;__main__&#39;:
    print(&#39;begin exec&#39;)
    f1()
    print(&#39;end exec&#39;)

# 执行结果:
# inside dec1
# begin exec
# inside wrapper
# inside f1
# end exec
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;看懂了没有，就是多了个嵌套而已。遇到加了参数的，那就是把之前的没有参数的部分返回回来就可以了。等价的例子就不贴了，这个等价于 &lt;code&gt;dec1(name=&#39;1&#39;)(fn)()&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;如果是类装饰器，并且有参数，那等价于 &lt;code&gt;dec1(name=&#39;1&#39;)(fn)()&lt;/code&gt;，其中 &lt;code&gt;__init__(self, name)&lt;/code&gt; 先处理第一层参数，然后 &lt;code&gt;__call__(fn)&lt;/code&gt; 处理第二层，然后需要在 &lt;code&gt;__call__&lt;/code&gt; 里面再定义一个 wrapper 返回。&lt;/p&gt;

&lt;p&gt;说明白没有？呵呵。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>cookie 的一点研究</title>
      <link>https://wdicc.com/about-http-cookie/</link>
      <pubDate>Fri, 16 Sep 2016 08:59:09 +0800</pubDate>
      
      <guid>https://wdicc.com/about-http-cookie/</guid>
      <description>&lt;p&gt;这几天搞了一下 python 里面 cookie 相关的东西。我的目的是想要尝试用 python 登录某个网站，并且保持登录状态直到过期。因为 http 协议是无状态的，所以一般来讲，网站想要用户保持登录，那么网站在用户登录之后，必须要和用户端协商好怎么来证明这个用户已经登录过了。&lt;/p&gt;

&lt;p&gt;用户端如果使用浏览器，那么网站就可以利用浏览器对 cookie 的支持来让用户在不知情的情况下，让网站在用户登录后发的一个 token 在用户后续的请求里面都包含上。&lt;/p&gt;

&lt;p&gt;用户端如果不是浏览器，比如是个 python 程序，那么网站可以和用户协商每次请求里面都包含某个下发的 token（当然，甚至要求客户端每次请求都带着用户名密码也是可行的）。&lt;/p&gt;

&lt;p&gt;但是如果网站本身只是给浏览器用户准备的，那么通过用程序来「模拟」浏览器行为，把必要的 token 保存并在后续的请求里面都带上，也是可行的。&lt;/p&gt;

&lt;p&gt;python 里面，发送 http 请求可以简单的使用 &lt;code&gt;urllib.request.urlopen(url)&lt;/code&gt;，但是如果想要定制一下请求，比如修改一些 header 信息，那么就得使用 &lt;code&gt;urllib.request.Request&lt;/code&gt; 这个 class 先构造一个 Request 对象，然后传递给 urlopen 了。&lt;/p&gt;

&lt;p&gt;如果要处理 cookie，那就需要使用 &lt;code&gt;http.cookiejar.CookieJar&lt;/code&gt; 了，有了 Cookiejar 对象，就可以把网站下发的 cookie 保存到这个变量里面，然后在必要的时候，可以返回给服务器端了。如果想要保存到文件，那么可以使用 &lt;code&gt;http.cookiejar.LWPCookieJar&lt;/code&gt; 或者 &lt;code&gt;http.cookiejar.MozillaCookieJar&lt;/code&gt;，也可以基于 &lt;code&gt;http.cookiejar.FileCookieJar&lt;/code&gt; 自己实现一个子类，来用自己的办法保存和加载 cookie，比如保存到数据库什么的，这样就可以多台机器之间共享 cookie 了。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;urlopen&lt;/code&gt; 本身不支持自定义 cookiejar 逻辑，得使用 &lt;code&gt;opener = build_opener(HTTPCookieProcessor(cookiejar=Cookiejar对象))&lt;/code&gt; 来先构造一个自定义的 openner, 然后使用 &lt;code&gt;opener(Request对象)&lt;/code&gt; 来发送请求。&lt;/p&gt;

&lt;p&gt;如果不定义自己的 cookie policy，那么会使用默认的 &lt;code&gt;http.cookiejar.DefaultCookiePolicy&lt;/code&gt;，也可以自己基于 &lt;code&gt;http.cookiejar.CookiePolicy&lt;/code&gt; 实现自己的逻辑。只需要 override &lt;code&gt;set_ok&lt;/code&gt; 和 &lt;code&gt;return_ok&lt;/code&gt; 这两个方法就可以。&lt;/p&gt;

&lt;p&gt;http cookie 其实有很多属性，比如 domain, expire, path 等常见属性，也有 httponly, secure 等几个不常见的。这些属性都是浏览器处理的。就是说，浏览器把 cookie 返回给服务器端的时候，如果 domain 不匹配，或者已经过了 expire 时间等等一些不符合浏览器制定的 cookie 逻辑的时候，浏览器就不会把 cookie 发送给服务器端。就比如，服务器产生 cookie 的时候，声明了 domain=a.com，那么如果是来自于 b.com 的请求，浏览器是根本不会给他发送这个 cookie。再比如，服务器端产生 cookie 的时候，声明了 1 天后过期，那么 1 天之后，浏览器也不会再给服务器端发这个 cookie 了。&lt;/p&gt;

&lt;p&gt;但是如果是我们自己实现客户端模拟浏览器的时候，其实我们是可以耍流氓的，可以制定自己的 cookie 逻辑，也就是上面提到的 cookie policy。比如我可以简单的在 &lt;code&gt;return_ok&lt;/code&gt; 这个方法里面 &lt;code&gt;return True&lt;/code&gt;，在任何情况下都把所有的 cookie 返回给服务器，这样服务器端如果不提前想明白，它是一点都不知道的。&lt;/p&gt;

&lt;p&gt;所谓提前想明白就是想明白是不是需要针对这种情况做处理。如果本身我们系统也没有那么严格要求，那么不处理也可以。但是如果是某个比如金融系统，那么是必须要考虑的。否则如果完全依赖 cookie 的话，如果我通过某些手段弄到了用户的 cookie，那么我就可以骗过服务器端，让他认为我就是那个用户。&lt;/p&gt;

&lt;p&gt;我想了一下，貌似被盗窃 cookie 这种事情服务器端不太好防范，但是可以做的是防止浏览器耍流氓。比如我们把 cookie 加密，并里面增加一个发送 cookie 的时间。收到客户端发过来的 cookie 之后，我们解密看看时间有没有过期，这样就可以在服务器端让 cookie 失效了。&lt;/p&gt;

&lt;p&gt;另外，也可以考虑使用 session。session 是把一些用户的状态保存在服务器端。但是 session 实际上也是依赖 cookie 的，因为前面说了 http 协议无状态，就算可以把用户状态保存在服务器端，但是总还是得识别用户才可以。那个识别的 cookie 就是所谓的 session cookie，其实就是某个用户的唯一标识。&lt;/p&gt;

&lt;p&gt;对于 session cookie 被窃，好像也没有太好的办法，无非也是想办法比对之前用户的一些状态信息，比如 ip 和现在的信息是不是一致，不一致可以认为有被窃的怀疑，这个时候让用户再次验证用户信息，这都不能 100% 保证，但是至少会增加窃贼的成本。&lt;/p&gt;

&lt;p&gt;上面说到这些，都可以自己测试一下，测试也并不一定需要搭一个服务器端配合，以及使用复杂的抓包专鉴，其实使用 &lt;code&gt;nc&lt;/code&gt; 就可以。&lt;/p&gt;

&lt;p&gt;使用 &lt;code&gt;nc -l 9999&lt;/code&gt; 就可以启动一个监听在 9999 端口的 socket 服务器。之后使用 python 或者 curl 之类的程序请求，就能立刻看到请求发送过来的 http 信息，这个对于学习 http 协议其实也很方便。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ nc -l 9999
GET / HTTP/1.1
Accept-Encoding: identity
Connection: close
Cookie: QN2=test; QN1=ClbaCVfZF5lfszBALzTIAg==
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6)  AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.116 Safari/537.36
Host: localhost:9999

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;收到的上面这个请求，可以看到发送过来了 2 个 cookie。&lt;/p&gt;

&lt;p&gt;如果还想测试数据返回的情况，那么可以写一个 &lt;code&gt;test.resp&lt;/code&gt; 文件，内容如下&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat test.resp
HTTP/1.1 200 OK
Date: Sun, 18 Oct 2009 08:56:53 GMT
Server: Apache/2.2.14 (Win32)
Last-Modified: Sat, 20 Nov 2004 07:16:26 GMT
ETag: &amp;quot;10000000565a5-2c-3e94b66c2e680&amp;quot;
Set-Cookie: QN1=ClbaCVfZF5lfszBALzTIAg==; expires=Thu, 31-Dec-37 23:55:55 GMT; path=/
Set-Cookie: QN2=test; expires=Thu, 31-Dec-37 23:55:55 GMT; path=/; secure; httponly
Accept-Ranges: bytes
Content-Length: 44
Connection: close
Content-Type: text/html
X-Pad: avoid browser bug

&amp;lt;html&amp;gt;&amp;lt;body&amp;gt;&amp;lt;h1&amp;gt;It works!&amp;lt;/h1&amp;gt;&amp;lt;/body&amp;gt;&amp;lt;/html&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后使用 &lt;code&gt;nc -l 9999 &amp;lt; test.resp&lt;/code&gt; 命令启动服务，客户端来请求的时候，就会返回上面 &lt;code&gt;test.resp&lt;/code&gt; 里面的内容。&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>